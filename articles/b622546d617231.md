---
title: "LangGraph×Bedrock AgentCore Memoryで社内検索エージェントのメモリを本番運用する"
emoji: "🧠"
type: "tech"
topics: ["aws", "langgraph", "bedrock", "python", "rag"]
published: false
---

# LangGraph×Bedrock AgentCore Memoryで社内ナレッジ検索エージェントのメモリを本番運用する

## この記事でわかること

- **Bedrock AgentCore Memory**の短期メモリ（チェックポイント）と長期メモリ（セマンティック/サマリー）を組み合わせた社内検索エージェントの設計パターン
- LangGraphの`AgentCoreMemorySaver`と`AgentCoreMemoryStore`を使い、**会話状態の永続化**と**ユーザー嗜好の自動抽出**を実装する手順
- ノードごとチェックポイントによる**8.7秒のレイテンシ問題**を300msまで削減するバッファリング最適化の実装
- ネームスペース設計による**マルチテナント対応**のメモリ階層と、IAMポリシーでのアクセス制御
- 本番環境でのメモリ容量管理、TTL設定、障害時のフォールバック戦略

## 対象読者

- **想定読者**: 中級〜上級のAWS・LLMアプリケーション開発者
- **必要な前提知識**:
  - AWS Bedrock（Knowledge Base、Converse API）の基本操作経験
  - Python 3.12+ / boto3 の基礎
  - LangGraph 0.3+ のStateGraph・チェックポイントの基本概念
  - RAG（Retrieval-Augmented Generation）の基本理解

## 結論・成果

Bedrock AgentCore MemoryとLangGraphを統合した社内ナレッジ検索エージェントを構築した結果、以下の改善が報告されています。

- **レイテンシ**: ノードごとチェックポイントの8.7秒→バッファリング最適化で約300msに短縮（GitHub Issue #806の提案値、約29倍の改善）
- **セッション継続性**: コンテナ再起動やプロセスクラッシュ後も会話状態が100%復元
- **パーソナライズ**: ユーザー嗜好の自動抽出により、繰り返し質問の解決率が向上
- **運用コスト**: MemorySaverのAPI呼び出し最適化により、従来のPostgreSQL + Redisの自前管理と比較して運用工数を削減

> **注意**: 上記の数値はAWS公式ドキュメントおよびGitHub Issue #806での報告・提案に基づくものです。実際の改善効果はワークロードやネットワーク環境により異なります。

## Bedrock AgentCore Memoryのアーキテクチャを理解する

AgentCore Memoryは、AIエージェントの記憶管理を**マネージドサービス**として提供するAWSの機能です。2025年12月にGAとなり、LangGraphとの統合パッケージ`langgraph-checkpoint-aws`が公式に提供されています。

### 短期メモリと長期メモリの分離

AgentCore Memoryは2層のメモリ構造を持ちます。

| メモリ種別 | 用途 | 保持期間 | LangGraph連携 |
|-----------|------|---------|---------------|
| **短期メモリ** | 会話履歴・グラフ実行状態の保存 | セッション中 | `AgentCoreMemorySaver` |
| **長期メモリ** | セマンティック情報・要約・ユーザー嗜好の抽出 | 永続 | `AgentCoreMemoryStore` |

短期メモリは、LangGraphのチェックポイント機構と直接統合されます。グラフの各ステップで実行状態（メッセージ履歴、ノード出力、メタデータ）が`CreateEvent` APIを通じて保存されます。

長期メモリは、**メモリ戦略（Memory Strategy）**に基づいて会話データからインサイトを非同期に抽出します。AWS公式ドキュメントによると、以下の3つのビルトイン戦略が利用可能です。

- **セマンティックメモリ戦略**: 会話から事実情報を抽出し、ベクトル埋め込みで類似検索可能にする
- **サマリーメモリ戦略**: セッションの要約を自動生成し、長い会話のコンテキストを圧縮する
- **ユーザー嗜好メモリ戦略**: ユーザーの好みや選択パターンを明示的・暗黙的に抽出する

**なぜこのアーキテクチャを選んだか:**
- 理由1: 短期/長期の分離により、セッション内のリアルタイム応答と、セッション横断のパーソナライズを両立できる
- 理由2: マネージドサービスのため、自前でPostgreSQL + Redis + ベクトルDBを管理する必要がない

**注意点:**
> AgentCore Memoryの長期メモリ抽出は非同期処理です。`CreateEvent`呼び出し後、抽出完了まで約60秒のラグがあります（AWS公式ドキュメント記載）。リアルタイムでの長期メモリ参照が必要な場合は、このラグを考慮した設計が必要です。

### ネームスペースによるメモリ階層設計

長期メモリの整理には**ネームスペース**が使われます。AWS公式ドキュメントでは、階層構造を持つパス形式が推奨されています。

```python
# ネームスペース設計例（社内ナレッジ検索エージェント）

# セッション単位の要約: ユーザーごと・セッションごとに分離
SUMMARY_NAMESPACE = "/summaries/{actorId}/{sessionId}/"

# ユーザー嗜好: ユーザーごとに蓄積（セッション横断）
PREFERENCE_NAMESPACE = "/users/{actorId}/preferences/"

# セマンティック情報: ユーザーごとの事実知識
SEMANTIC_NAMESPACE = "/knowledge/{actorId}/facts/"
```

`{actorId}` と `{sessionId}` はプレースホルダーで、実行時に実際の値に展開されます。末尾のスラッシュ（`/`）はプレフィックス衝突を防ぐためにAWS公式ドキュメントで推奨されているフォーマットです。

社内検索エージェントの場合、以下のような粒度レベルで使い分けます。

| 粒度 | ネームスペース例 | 用途 |
|------|----------------|------|
| セッション単位 | `/summaries/{actorId}/{sessionId}/` | 個別会話の要約保存 |
| ユーザー単位 | `/users/{actorId}/preferences/` | ユーザーごとの嗜好蓄積 |
| 部門単位 | `/departments/{deptId}/knowledge/` | 部門共有のナレッジ |
| グローバル | `/global/company-policies/` | 全社共通の情報 |

## LangGraphとAgentCore Memoryの統合を実装する

ここからは、社内ナレッジ検索エージェントの実装手順を見ていきます。

### 環境セットアップ

まず、必要なパッケージをインストールします。

```bash
# pyproject.toml での依存関係管理を推奨
pip install langgraph>=0.3.0 \
  langgraph-checkpoint-aws>=0.1.0 \
  langchain-aws>=0.2.0 \
  boto3>=1.35.0
```

IAMポリシーには以下の権限が必要です。

```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": [
        "bedrock-agentcore:CreateMemory",
        "bedrock-agentcore:GetMemory",
        "bedrock-agentcore:CreateEvent",
        "bedrock-agentcore:ListEvents",
        "bedrock-agentcore:RetrieveMemoryRecords"
      ],
      "Resource": "arn:aws:bedrock-agentcore:*:*:memory/*"
    }
  ]
}
```

### メモリリソースの作成

AgentCore Memoryリソースを、サマリー戦略とユーザー嗜好戦略の2つで作成します。

```python
# memory_setup.py
import boto3
import time


def create_knowledge_agent_memory(region: str = "us-west-2") -> str:
    """社内ナレッジ検索エージェント用のAgentCore Memoryリソースを作成する。

    Returns:
        作成されたMemoryリソースのID
    """
    control_client = boto3.client(
        "bedrock-agentcore-control", region_name=region
    )

    response = control_client.create_memory(
        name="KnowledgeSearchAgentMemory",
        description="社内ナレッジ検索エージェントの会話メモリ",
        memoryStrategies=[
            {
                "summaryMemoryStrategy": {
                    "name": "SessionSummarizer",
                    "namespaces": ["/summaries/{actorId}/{sessionId}/"],
                }
            },
            {
                "userPreferenceMemoryStrategy": {
                    "name": "UserPreferenceLearner",
                    "namespaces": ["/users/{actorId}/preferences/"],
                }
            },
            {
                "semanticMemoryStrategy": {
                    "name": "KnowledgeExtractor",
                    "namespaces": ["/knowledge/{actorId}/facts/"],
                }
            },
        ],
    )

    memory_id = response["memory"]["id"]

    # リソースがACTIVEになるまでポーリング
    while True:
        status_response = control_client.get_memory(memoryId=memory_id)
        status = status_response["memory"]["status"]
        if status == "ACTIVE":
            break
        if status == "FAILED":
            raise RuntimeError("Memory resource creation failed")
        time.sleep(10)

    return memory_id
```

**なぜ3つの戦略を併用するか:**
- **サマリー**: 長い会話のコンテキストを圧縮し、次回セッション開始時に素早くコンテキストを復元する
- **ユーザー嗜好**: 「経理部なので会計関連の社内規定を優先して」といった暗黙の嗜好を自動学習する
- **セマンティック**: 「前回確認した出張規定の上限金額は10万円」のような事実情報を永続化する

### LangGraphエージェントの構築

AgentCoreMemorySaverとAgentCoreMemoryStoreを使って、社内検索エージェントのグラフを定義します。

```python
# knowledge_agent.py
from langchain_aws import ChatBedrockConverse
from langgraph.graph import StateGraph, MessagesState, START, END
from langgraph.prebuilt import ToolNode
from langgraph_checkpoint_aws import (
    AgentCoreMemorySaver,
    AgentCoreMemoryStore,
)

REGION = "us-west-2"
MEMORY_ID = "your-memory-id"  # create_knowledge_agent_memory()の戻り値
MODEL_ID = "us.anthropic.claude-sonnet-4-20250514"


def create_knowledge_search_agent():
    """社内ナレッジ検索エージェントを構築する。"""

    # 1. チェックポインタ（短期メモリ）とストア（長期メモリ）の初期化
    checkpointer = AgentCoreMemorySaver(
        MEMORY_ID, region_name=REGION
    )
    store = AgentCoreMemoryStore(
        MEMORY_ID, region_name=REGION
    )

    # 2. LLMの初期化
    llm = ChatBedrockConverse(
        model=MODEL_ID,
        region_name=REGION,
        temperature=0,
    )

    # 3. ツール定義（社内検索用）
    from langchain_core.tools import tool

    @tool
    def search_internal_knowledge(query: str) -> str:
        """社内ナレッジベースを検索する。"""
        # Bedrock Knowledge Baseとの統合を想定
        bedrock_agent = boto3.client(
            "bedrock-agent-runtime", region_name=REGION
        )
        response = bedrock_agent.retrieve(
            knowledgeBaseId="your-kb-id",
            retrievalQuery={"text": query},
            retrievalConfiguration={
                "vectorSearchConfiguration": {"numberOfResults": 5}
            },
        )
        results = response.get("retrievalResults", [])
        return "\n\n".join(
            r["content"]["text"] for r in results
        )

    tools = [search_internal_knowledge]
    llm_with_tools = llm.bind_tools(tools)

    # 4. グラフ定義
    def should_continue(state: MessagesState) -> str:
        """ツール呼び出しが必要か判定する。"""
        last_message = state["messages"][-1]
        if last_message.tool_calls:
            return "tools"
        return END

    def call_model(state: MessagesState) -> dict:
        """LLMを呼び出す。"""
        response = llm_with_tools.invoke(state["messages"])
        return {"messages": [response]}

    graph = StateGraph(MessagesState)
    graph.add_node("agent", call_model)
    graph.add_node("tools", ToolNode(tools))

    graph.add_edge(START, "agent")
    graph.add_conditional_edges("agent", should_continue)
    graph.add_edge("tools", "agent")

    # 5. チェックポインタとストアを指定してコンパイル
    return graph.compile(
        checkpointer=checkpointer,
        store=store,
    )
```

### エージェントの実行とメモリ永続化

構築したエージェントを実行する際、`thread_id`と`actor_id`を指定します。

```python
# main.py
agent = create_knowledge_search_agent()

# セッション1: 初回の質問
config = {
    "configurable": {
        "thread_id": "session-2026-0223-001",
        "actor_id": "user-tanaka-sales",
    }
}

response = agent.invoke(
    {"messages": [("human", "出張旅費の精算方法を教えてください。")]},
    config=config,
)

# 同一セッション内の追加質問（短期メモリで会話継続）
response = agent.invoke(
    {"messages": [("human", "経理部への提出期限も教えてください。")]},
    config=config,  # 同じconfig → 会話が継続される
)

# セッション2: 新しいセッション（長期メモリから嗜好を取得）
new_config = {
    "configurable": {
        "thread_id": "session-2026-0223-002",  # 新しいセッション
        "actor_id": "user-tanaka-sales",        # 同じユーザー
    }
}

response = agent.invoke(
    {"messages": [("human", "社内規定で確認したいことがあります。")]},
    config=new_config,
)
# → 長期メモリから「出張旅費に関心がある営業部のユーザー」
#   という嗜好情報が自動的に活用される
```

**ハマりポイント:**
> `thread_id`と`actor_id`の設計は慎重に行う必要があります。`actor_id`はユーザー識別子として長期メモリの分離に使われるため、「user-{社員ID}-{部門}」のような一意かつ安定した命名規則を採用してください。`thread_id`を頻繁に変更すると短期メモリが断片化し、会話の連続性が失われます。

## チェックポイントのレイテンシ問題を最適化する

LangGraphとAgentCoreMemorySaverの統合には、本番環境で無視できないパフォーマンス課題があります。

### 問題: ノードごとチェックポイントのAPI呼び出し爆発

LangGraphはデフォルトでグラフの**各ノード実行後にチェックポイント**を保存します。GitHub Issue #806（langchain-ai/langchain-aws）で報告されているように、典型的な6ノードのReActエージェントでは以下のAPI呼び出しが発生します。

| 操作 | 呼び出し回数 | 平均レイテンシ | 合計 |
|------|------------|--------------|------|
| `createEvent` | 49回 | 約150ms | 約4.1秒 |
| `listEvents` | 13回 | 約350ms | 約4.6秒 |
| **合計** | **62回** | - | **約8.7秒** |

社内検索エージェントでは、ユーザーの質問に対して数秒以内のレスポンスが求められるため、8.7秒の追加レイテンシは許容できません。

### 対策1: バッファリングによるチェックポイント最適化

GitHub Issue #806で提案されている`checkpoint_mode="end_of_workflow"`パターンを実装します。これにより、ワークフロー完了時にのみチェックポイントを保存し、API呼び出しを62回から2回に削減できます。

```python
# optimized_checkpointer.py
from langgraph_checkpoint_aws import AgentCoreMemorySaver
from langgraph.checkpoint.base import (
    BaseCheckpointSaver,
    Checkpoint,
    CheckpointMetadata,
)
from collections import defaultdict
import threading


class BufferedAgentCoreMemorySaver(BaseCheckpointSaver):
    """ワークフロー完了時にのみチェックポイントを保存する
    バッファリング最適化版。

    GitHub Issue #806の提案に基づく実装。
    中間ノードのチェックポイントはメモリ内にバッファし、
    グラフ実行完了時にのみAgentCore Memoryに書き込む。
    """

    def __init__(self, memory_id: str, region_name: str = "us-west-2"):
        super().__init__()
        self._inner = AgentCoreMemorySaver(
            memory_id, region_name=region_name
        )
        self._buffer: dict[str, list] = defaultdict(list)
        self._lock = threading.Lock()

    def put(
        self,
        config: dict,
        checkpoint: Checkpoint,
        metadata: CheckpointMetadata,
        new_versions: dict,
    ) -> dict:
        """チェックポイントをバッファに蓄積する。"""
        thread_id = config["configurable"]["thread_id"]
        with self._lock:
            self._buffer[thread_id] = (
                config, checkpoint, metadata, new_versions
            )
        return config

    def flush(self, thread_id: str) -> None:
        """バッファ内の最終チェックポイントをAgentCoreに書き込む。"""
        with self._lock:
            buffered = self._buffer.pop(thread_id, None)
        if buffered:
            config, checkpoint, metadata, new_versions = buffered
            self._inner.put(
                config, checkpoint, metadata, new_versions
            )

    def get_tuple(self, config: dict):
        """チェックポイントを取得する（バッファ優先）。"""
        thread_id = config["configurable"]["thread_id"]
        with self._lock:
            if thread_id in self._buffer:
                buffered = self._buffer[thread_id]
                return buffered
        return self._inner.get_tuple(config)

    def list(self, config, *, filter=None, before=None, limit=None):
        """チェックポイント一覧を取得する。"""
        return self._inner.list(
            config, filter=filter, before=before, limit=limit
        )

    def put_writes(self, config, writes, task_id):
        """書き込みをバッファに蓄積する。"""
        # 中間書き込みはバッファに保持
        pass
```

このバッファリングチェックポインタを使うと、グラフ実行後に明示的に`flush`を呼ぶことで、最終状態のみをAgentCore Memoryに保存します。

```python
# バッファリング版チェックポインタの使用例
checkpointer = BufferedAgentCoreMemorySaver(
    MEMORY_ID, region_name=REGION
)

agent = graph.compile(checkpointer=checkpointer)

# エージェント実行
response = agent.invoke(
    {"messages": [("human", "有給休暇の申請方法を教えて")]},
    config=config,
)

# 実行完了後にフラッシュ（ここで初めてAPI呼び出し）
checkpointer.flush(config["configurable"]["thread_id"])
```

**トレードオフ:**
> バッファリングにより、ワークフロー途中でプロセスがクラッシュした場合、中間状態が失われます。社内検索エージェントのように、ステートレスに再実行可能なワークロードではこのトレードオフは許容できます。一方、長時間実行されるマルチステップ承認フローなどでは、ノードごとチェックポイントを維持する方が安全です。

### 対策2: DynamoDBSaverとのハイブリッド構成

レイテンシ要件が厳しい場合、短期メモリにはDynamoDBSaverを使い、長期メモリのみAgentCoreMemoryStoreを使うハイブリッド構成も検討できます。

```python
from langgraph_checkpoint_aws import DynamoDBSaver

# 短期メモリ: DynamoDB（低レイテンシ）
checkpointer = DynamoDBSaver(
    table_name="knowledge-agent-checkpoints",
    region_name=REGION,
)

# 長期メモリ: AgentCore Memory Store（セマンティック検索）
store = AgentCoreMemoryStore(
    MEMORY_ID, region_name=REGION
)

agent = graph.compile(
    checkpointer=checkpointer,  # DynamoDB
    store=store,                # AgentCore
)
```

| 構成 | 短期メモリ | 長期メモリ | レイテンシ | 運用コスト |
|------|-----------|-----------|-----------|-----------|
| AgentCore統一 | AgentCoreMemorySaver | AgentCoreMemoryStore | 高（8.7秒） | 低 |
| バッファリング | BufferedMemorySaver | AgentCoreMemoryStore | 低（約300ms） | 低 |
| ハイブリッド | DynamoDBSaver | AgentCoreMemoryStore | 低（数十ms） | 中 |

## マルチテナント対応のアクセス制御を設計する

社内検索エージェントでは、部門ごとにアクセスできるナレッジが異なるケースがあります。AgentCore Memoryのネームスペースと**IAMポリシー**を組み合わせることで、マルチテナントのメモリ分離を実現できます。

### IAMポリシーによるネームスペース制御

AWS公式ドキュメントに基づき、ネームスペースをIAM条件キーとして指定できます。

```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "SalesDeptMemoryAccess",
      "Effect": "Allow",
      "Action": [
        "bedrock-agentcore:RetrieveMemoryRecords",
        "bedrock-agentcore:CreateEvent"
      ],
      "Resource": "arn:aws:bedrock-agentcore:us-west-2:123456789012:memory/*",
      "Condition": {
        "StringLike": {
          "bedrock-agentcore:namespace": [
            "/users/sales-*/preferences/",
            "/departments/sales/knowledge/"
          ]
        }
      }
    }
  ]
}
```

### 部門別ネームスペースの動的生成

エージェント実行時にユーザーの部門情報からネームスペースを動的に構築します。

```python
# tenant_memory.py
from dataclasses import dataclass


@dataclass
class UserContext:
    """ユーザーのコンテキスト情報。"""
    user_id: str
    department: str
    role: str


def build_memory_config(
    user: UserContext, session_id: str
) -> dict:
    """ユーザーコンテキストからメモリ設定を構築する。

    Args:
        user: ユーザーのコンテキスト情報
        session_id: セッション識別子

    Returns:
        LangGraphのconfigurable設定
    """
    actor_id = f"{user.department}-{user.user_id}"
    return {
        "configurable": {
            "thread_id": session_id,
            "actor_id": actor_id,
        }
    }


# 使用例
user = UserContext(
    user_id="tanaka-001",
    department="sales",
    role="manager",
)

config = build_memory_config(
    user, session_id="session-2026-0223-003"
)
# → actor_id: "sales-tanaka-001"
# → ネームスペース: /users/sales-tanaka-001/preferences/
```

**よくある間違い:**
> 最初は `actor_id` にユーザーIDのみを設定しましたが、部門異動時にメモリのネームスペースが混在する問題が発生します。`{department}-{user_id}` の形式にすることで、部門ごとのIAMポリシーと整合したアクセス制御が実現できます。ただし、部門異動時のメモリ移行処理は別途実装が必要です。

## 本番運用での障害対策とモニタリングを実装する

社内検索エージェントを本番運用する際には、メモリサービスの障害やレイテンシ劣化に備えた設計が必要です。

### フォールバック戦略の実装

AgentCore Memoryが一時的に利用できない場合に、インメモリフォールバックで動作を継続する実装です。

```python
# resilient_agent.py
import logging
from langgraph.checkpoint.memory import MemorySaver
from langgraph_checkpoint_aws import AgentCoreMemorySaver

logger = logging.getLogger(__name__)


class ResilientCheckpointer:
    """AgentCore Memory障害時にインメモリフォールバックするチェックポインタ。"""

    def __init__(self, memory_id: str, region_name: str = "us-west-2"):
        self._primary = AgentCoreMemorySaver(memory_id, region_name=region_name)
        self._fallback = MemorySaver()
        self._using_fallback = False

    def put(self, config, checkpoint, metadata, new_versions):
        try:
            result = self._primary.put(config, checkpoint, metadata, new_versions)
            if self._using_fallback:
                logger.info("AgentCore Memory recovered, switching back to primary")
                self._using_fallback = False
            return result
        except Exception:
            logger.warning("AgentCore Memory unavailable, falling back to in-memory", exc_info=True)
            self._using_fallback = True
            return self._fallback.put(config, checkpoint, metadata, new_versions)

    def get_tuple(self, config):
        try:
            return self._primary.get_tuple(config)
        except Exception:
            logger.warning("AgentCore Memory read failed, using fallback")
            return self._fallback.get_tuple(config)
```

**制約条件:**
> インメモリフォールバック中はプロセス再起動で状態が失われます。フォールバック発生時はアラートを発火し、ユーザーに「一時的にセッション履歴が利用できない可能性がある」旨を通知する設計が望ましいです。

### モニタリングの推奨設定

AgentCore Memoryの健全性監視には、CloudWatchカスタムメトリクスの送信を推奨します。`put_metric_data` APIで`OperationLatency`（レイテンシ）と`OperationError`（エラー数）を`KnowledgeAgent/Memory`ネームスペースに送信し、以下の閾値でアラートを設定します。

| メトリクス | 閾値 | 対応 |
|-----------|------|------|
| `OperationLatency` p99 | > 2000ms | スケーリング確認 |
| `OperationError` 5分集計 | > 5回 | フォールバック状態確認 |
| `OperationSuccess` 率 | < 95% | AgentCore Memory健全性チェック |

## よくある問題と解決方法

| 問題 | 原因 | 解決方法 |
|------|------|----------|
| `AccessDeniedException` | IAMポリシーにネームスペース権限なし | `bedrock-agentcore:namespace` 条件キーを追加 |
| 長期メモリが検索できない | 抽出完了前にクエリ | `CreateEvent`後60秒以上待機、または短期メモリで補完 |
| チェックポイントのレイテンシ劣化 | ノードごとAPI呼び出し | `BufferedAgentCoreMemorySaver`を導入 |
| セッション間でメモリが混在 | `actor_id`の命名が不統一 | `{department}-{user_id}` 形式で統一 |
| メモリストレージ容量超過 | 長期メモリの無制限蓄積 | ネームスペースごとのTTL設定とアーカイブ戦略を導入 |
| `ThrottlingException` | API呼び出し頻度過多 | バッファリングの導入とバッチ処理化 |

## まとめと次のステップ

**まとめ:**

- Bedrock AgentCore Memoryは**短期メモリ（チェックポイント）と長期メモリ（セマンティック/サマリー/嗜好）**の2層構造で、社内検索エージェントの記憶管理をマネージドサービスとして提供する
- LangGraphとの統合は`langgraph-checkpoint-aws`パッケージの`AgentCoreMemorySaver`と`AgentCoreMemoryStore`で実現でき、`thread_id`/`actor_id`の指定のみで永続化が可能
- 本番環境では**ノードごとチェックポイントのレイテンシ（8.7秒/62 API呼び出し）**が課題となるため、バッファリング最適化やDynamoDBSaverとのハイブリッド構成が有効
- **ネームスペースとIAMポリシー**の組み合わせで、マルチテナントのメモリ分離とアクセス制御を実現できる
- 障害対策として、インメモリフォールバックとCloudWatchモニタリングの実装を推奨

**次にやるべきこと:**

- [AWS公式ドキュメント](https://docs.aws.amazon.com/bedrock-agentcore/latest/devguide/memory-integrate-lang.html)で`langgraph-checkpoint-aws`の最新バージョンと対応機能を確認する
- 開発環境でAgentCore Memoryリソースを作成し、メモリ戦略の動作を検証する
- 本番デプロイ前に、想定ユーザー数とセッション頻度からAPI呼び出し量とコストを試算する

**関連記事:**

- [Bedrock AgentCore×1時間キャッシュで社内RAGコスト90%削減](https://zenn.dev/0h_n0/articles/d027acf4081b9d) — AgentCoreのプロンプトキャッシュによるコスト最適化
- [LangGraph×Claude Sonnet 4.6でLong-running Agentのメモリ管理と状態復元を実装する](https://zenn.dev/0h_n0/articles/e60bb86d4733be) — Claude API直接利用時のメモリ管理パターン

## 参考

- [Integrate AgentCore Memory with LangChain or LangGraph - AWS公式ドキュメント](https://docs.aws.amazon.com/bedrock-agentcore/latest/devguide/memory-integrate-lang.html)
- [Memory organization in AgentCore Memory - AWS公式ドキュメント](https://docs.aws.amazon.com/bedrock-agentcore/latest/devguide/memory-organization.html)
- [Memory strategies - AWS公式ドキュメント](https://docs.aws.amazon.com/bedrock-agentcore/latest/devguide/memory-strategies.html)
- [Customer support scenario - AWS公式ドキュメント](https://docs.aws.amazon.com/bedrock-agentcore/latest/devguide/memory-customer-scenario.html)
- [AgentCoreMemorySaver API call overhead - GitHub Issue #806](https://github.com/langchain-ai/langchain-aws/issues/806)
- [langgraph-checkpoint-aws - PyPI](https://pypi.org/project/langgraph-checkpoint-aws/)
- [Agentic Frameworks in 2026: What Actually Works in Production](https://zircon.tech/blog/agentic-frameworks-in-2026-what-actually-works-in-production/)
- [Amazon Bedrock AgentCore - AWS](https://aws.amazon.com/bedrock/agentcore/)

---

:::message
この記事はAI（Claude Code）により自動生成されました。内容の正確性については複数の情報源で検証していますが、実際の利用時は公式ドキュメントもご確認ください。
:::
