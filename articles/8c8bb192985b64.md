---
title: "2026年版ベクトルDB選定ガイド：pgvector・Qdrant・Pineconeを本番ベンチマークで比較"
emoji: "🔍"
type: "tech"
topics: ["vectordb", "rag", "pinecone", "qdrant", "pgvector"]
published: false
---

# 2026年版ベクトルDB選定ガイド：pgvector・Qdrant・Pineconeを本番ベンチマークで比較

## この記事でわかること

- 主要5つのベクトルDB（pgvector、Qdrant、Pinecone、Milvus、Weaviate）の特性と使い分け
- 50Mベクトル規模での実測ベンチマーク比較（QPS・p99レイテンシ・recall）
- ステージ別（MVP→本番→大規模）の具体的な選定フレームワーク
- 各DBの接続・検索コード例（Python）
- 選定で陥りがちな3つの失敗パターンと回避策

## 対象読者

- **想定読者**: 中級者以上のバックエンドエンジニア・MLエンジニア
- **必要な前提知識**:
  - Python 3.11+ の基本的な使い方
  - ベクトル埋め込み（embedding）の基本概念
  - SQL（PostgreSQL）の基礎知識があるとなお良い

## 結論・成果

**50Mベクトル（768次元）のベンチマークで、pgvectorscaleがQdrantの11.4倍のスループット（471 QPS vs 41 QPS、99% recall）を記録。** 一方、p99レイテンシではQdrantが48%優位（38.71ms vs 74.60ms）。最適解はフェーズと要件次第で変わります。

## ベクトルDBの主要プレイヤーを整理する

2026年現在、選択肢は大きく3カテゴリに分かれます。

### 3カテゴリの特徴比較

| カテゴリ | 代表例 | 強み | 弱み |
|---------|--------|------|------|
| **既存DB拡張型** | pgvector/pgvectorscale | SQL統合、運用ノウハウ流用 | 大規模時の水平スケール |
| **専用ベクトルDB** | Qdrant, Milvus, Weaviate | 高性能、専用最適化 | 運用スタック追加 |
| **マネージドサービス** | Pinecone, Zilliz Cloud | ゼロ運用、サーバーレス | ベンダーロックイン |

**まず既存スタックの拡張を検討しましょう。** PostgreSQL利用中ならpgvector、Elasticsearch利用中ならそのベクトル検索機能から始めるのが現実的です。

> **よくある間違い**: 「専用ベクトルDBの方が常に速い」と思い込みがちですが、実測ではpgvectorscaleがスループットでQdrantを大幅に上回るケースもあります。

### 主要5プロダクトの早見表

| 製品 | ライセンス | 言語 | ハイブリッド検索 | 水平スケール | GitHub Stars |
|------|-----------|------|----------------|-------------|-------------|
| **pgvector** | PostgreSQL License | C | pgvector + pg_trgm | △（リードレプリカ） | 13,000+ |
| **Qdrant** | Apache 2.0 | Rust | Sparse + Dense | ○（ネイティブ） | 22,000+ |
| **Pinecone** | プロプライエタリ | - | Sparse + Dense | ○（サーバーレス） | - |
| **Milvus** | Apache 2.0 | Go/C++ | BM25 + Dense (v2.5+) | ○（分散設計） | 40,000+ |
| **Weaviate** | BSD-3 | Go | BM25 + Dense | ○（ネイティブ） | 13,000+ |

## ベンチマークで実力を比較する

### 50Mベクトル（768次元）の実測結果

Tiger Data社のベンチマーク（2025年公開）による、pgvectorscaleとQdrantの性能比較です。

| 指標 | pgvectorscale | Qdrant | 差 |
|------|-------------|--------|-----|
| **QPS（99% recall）** | 471.57 | 41.47 | pgvectorが**11.4倍** |
| **QPS（90% recall）** | 1,589 | 360 | pgvectorが**4.4倍** |
| **p50レイテンシ** | 31.07ms | 30.75ms | Qdrantが1%優位 |
| **p95レイテンシ** | - | - | Qdrantが**39%優位** |
| **p99レイテンシ** | 74.60ms | 38.71ms | Qdrantが**48%優位** |
| **インデックス構築** | 11.1時間 | 3.3時間 | Qdrantが**3.4倍高速** |

**読み方**: 同時クエリ処理 → pgvectorscaleのQPS優位、リアルタイム応答 → Qdrantのp99優位、インデックス再構築頻度高 → Qdrantの構築速度優位。

> **トレードオフ**: ユーザー体験を重視するリアルタイム検索ではp99が重要、バッチ処理ワークロードではQPSが重要です。用途に応じて重視する指標を使い分けてください。

Qdrant公式ベンチマーク（1M・1536次元）でも、高次元データで**4倍のRPSゲイン**を達成しています。

## 実装コードで接続から検索までを確認する

実際のコードを見てみましょう。開発チームの技術スタックに近い方を選ぶのも重要な判断基準です。

### pgvector：SQLでそのまま検索

```python
# pgvector_search.py （Python 3.11+, psycopg 3.2+, pgvector 0.3+）
import psycopg
from pgvector.psycopg import register_vector

conn = psycopg.connect("postgresql://user:pass@localhost/mydb")
register_vector(conn)

# HNSWインデックス作成（m=16がrecallとスループットのバランスが良い）
conn.execute("""
    CREATE INDEX IF NOT EXISTS idx_docs_embedding
    ON documents USING hnsw (embedding vector_cosine_ops)
    WITH (m = 16, ef_construction = 200)
""")

# ベクトル検索（コサイン類似度、Top 5）
query_vec = [0.1] * 1536  # 実際にはembeddingモデルから取得
results = conn.execute(
    "SELECT id, content, embedding <=> %s::vector AS dist "
    "FROM documents ORDER BY dist LIMIT 5",
    [query_vec],
).fetchall()
```

**pgvectorの強み**: 既存PostgreSQLのJOIN・WHERE句がそのまま使え、バックアップや監視の運用ノウハウも流用できます。

### Qdrant：フィルタ付き高速検索

```python
# qdrant_search.py （Python 3.11+, qdrant-client 1.12+）
from qdrant_client import QdrantClient
from qdrant_client.models import Distance, VectorParams, Filter, FieldCondition, MatchValue

client = QdrantClient(host="localhost", port=6333)

# ベクトル検索 + メタデータフィルタ（Filterable HNSW）
results = client.query_points(
    collection_name="documents",
    query=[0.1] * 1536,
    query_filter=Filter(must=[
        FieldCondition(key="category", match=MatchValue(value="tech"))
    ]),
    limit=5,
)
```

**Qdrantの強み**: Rust実装によるp99 38ms台の低レイテンシと、フィルタ付き検索の高速性が特徴です。

> **制約条件**: Qdrantはスタンドアロンサービスとして運用が必要です。モノリスアーキテクチャでは管理するサービスが1つ増える点に注意してください。

## ステージ別の選定フレームワークを活用する

選定の判断基準は次の通りです。**PostgreSQL利用中 かつ 5M未満** → pgvector、**運用負荷ゼロ優先** → Pinecone Serverless、**オンプレ必須** → Milvus、**複雑フィルタ多用** → Qdrant、**ハイブリッド検索必須** → Weaviate or Milvus 2.5+。

### ステージ別コスト比較（概算）

| フェーズ | データ量 | 推奨DB | 月額概算 |
|---------|---------|--------|---------|
| **MVP** | 〜1Mベクトル | pgvector | $50〜100（RDS） |
| **成長期** | 1M〜10M | Qdrant Cloud / Pinecone | $200〜500 |
| **本番** | 10M〜100M | Pinecone Serverless | $300〜1,000（従量） |
| **大規模** | 100M+ | Milvus（自前クラスタ） | $1,000〜5,000 |

> **ハマりポイント**: オープンソースの「無料」に惹かれて自前運用を始めると、HA構成で3倍レプリケーション + アイドル時のプロビジョニングコスト + DevOps人件費で、マネージドサービスより高くつくケースが多いです。TCO（Total Cost of Ownership）で比較してください。

### 実際に失敗した選定パターン

| 失敗パターン | 内容 | 回避策 |
|-------------|------|--------|
| **ベンチマーク鵜呑み** | ベンダー公式の好条件ベンチのみで判断 | 自社データ・ワークロードで実測する |
| **過剰スペック** | 100Kベクトルに分散DBを導入 | 5M未満ならpgvectorで十分 |
| **フィルタ軽視** | ベクトル検索のみで選定し、後からフィルタ性能がボトルネック | フィルタ付き検索のp99を事前に計測 |

## まとめと次のステップ

**まとめ:**
- pgvectorscaleはQPS最強、テールレイテンシはQdrantが優位
- 選定は「データ量 × 運用体制 × フィルタ要件」の3軸で判断
- MVP→pgvector、本番→Pinecone/Qdrant、大規模→Milvus
- ベンダーベンチマーク鵜呑みNG、自社ワークロードで実測が最重要

**次にやるべきこと:**
- [VectorDBBench](https://github.com/zilliztech/VectorDBBench)で自社データのベンチマークを取る
- 候補2〜3に絞り、1週間のPoCで本番ワークロードを再現する
- フィルタ付き検索のp99レイテンシを必ず計測する

関連記事: [RAG検索システムの実装と本番運用ガイド](https://zenn.dev/0h_n0/articles/ac14636a973cac)

## 参考

- [Qdrant Benchmarks](https://qdrant.tech/benchmarks/)
- [pgvector vs. Qdrant (Tiger Data)](https://www.tigerdata.com/blog/pgvector-vs-qdrant)
- [Best vector databases for production RAG 2026](https://engineersguide.substack.com/p/best-vector-databases-rag)
- [Top 9 Vector Databases 2026 (Shakudo)](https://www.shakudo.io/blog/top-9-vector-databases)
- [VectorDBBench (Zilliz)](https://github.com/zilliztech/VectorDBBench)
- [Milvus 2.6 Release](https://milvus.io/blog/introduce-milvus-2-6-built-for-scale-designed-to-reduce-costs.md)

詳細なリサーチ内容は [Issue #165](https://github.com/0h-n0/zen-auto-create-article/issues/165) を参照してください。

---

:::message
この記事はAI（Claude Code）により自動生成されました。内容の正確性については複数の情報源で検証していますが、実際の利用時は公式ドキュメントもご確認ください。
:::
