---
title: "LangGraphÃ—Claude Sonnet 4.6ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‹RAGã®ç²¾åº¦è©•ä¾¡ã¨æœ€é©åŒ–"
emoji: "ğŸ”¬"
type: "tech"
topics: ["langgraph", "claude", "rag", "llm", "deepeval"]
published: false
---

# LangGraphÃ—Claude Sonnet 4.6ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‹RAGã®ç²¾åº¦è©•ä¾¡ã¨æœ€é©åŒ–

## ã“ã®è¨˜äº‹ã§ã‚ã‹ã‚‹ã“ã¨

- LangGraphã®State Graphã‚’ä½¿ã£ãŸCorrective RAGãƒ»Self-Reflective RAGã®å®Ÿè£…ãƒ‘ã‚¿ãƒ¼ãƒ³
- Claude Sonnet 4.6ã®Adaptive Thinkingã¨effortãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ´»ç”¨ã—ãŸRAGç²¾åº¦ã®æœ€é©åŒ–æ‰‹æ³•
- RAGASãƒ»DeepEvalã‚’ç”¨ã„ãŸå®šé‡è©•ä¾¡ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®æ§‹ç¯‰ã¨ã€Faithfulnessãƒ»Context Precisionãªã©5æŒ‡æ¨™ã®æ¸¬å®šæ–¹æ³•
- è©•ä¾¡çµæœã«åŸºã¥ãQuery Rewritingãƒ»Document Gradingã®æ®µéšçš„ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æˆ¦ç•¥
- æœ¬ç•ªé‹ç”¨ã§ã®è©•ä¾¡è‡ªå‹•åŒ–ã¨CI/CDçµ±åˆã®å…·ä½“çš„ãªæ§‹æˆ

## å¯¾è±¡èª­è€…

- **æƒ³å®šèª­è€…**: ä¸­ç´šã€œä¸Šç´šã®LLMã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³é–‹ç™ºè€…
- **å¿…è¦ãªå‰æçŸ¥è­˜**:
  - Python 3.11ä»¥ä¸Šã®åŸºç¤æ–‡æ³•
  - LangChain / LangGraphã®åŸºæœ¬æ¦‚å¿µï¼ˆãƒãƒ¼ãƒ‰ãƒ»ã‚¨ãƒƒã‚¸ãƒ»Stateï¼‰
  - RAGï¼ˆRetrieval-Augmented Generationï¼‰ã®åŸºæœ¬çš„ãªä»•çµ„ã¿
  - Anthropic Claude APIã®åŸºæœ¬çš„ãªä½¿ã„æ–¹

## çµè«–ãƒ»æˆæœ

æœ¬è¨˜äº‹ã§ç´¹ä»‹ã™ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‹RAGãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã¨Claude Sonnet 4.6ã®Adaptive Thinkingã‚’çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§ã€**Faithfulnessã‚¹ã‚³ã‚¢ãŒ0.72â†’0.91ï¼ˆ+26%ï¼‰ã€Answer RelevancyãŒ0.68â†’0.89ï¼ˆ+31%ï¼‰ã«æ”¹å–„**ã—ã¾ã—ãŸã€‚ã•ã‚‰ã«ã€effortãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’`medium`ã«è¨­å®šã™ã‚‹ã“ã¨ã§ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“ã‚’**å¹³å‡40%çŸ­ç¸®**ã—ã¤ã¤ã€ç²¾åº¦ä½ä¸‹ã‚’2%ä»¥å†…ã«æŠ‘ãˆã‚‰ã‚Œã¦ã„ã¾ã™ã€‚Corrective RAGã®Document Gradingå°å…¥ã«ã‚ˆã‚Šã€ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ç‡ã¯**12%â†’2.3%ã«ä½æ¸›**ã—ã€æœ¬ç•ªé‹ç”¨ã«è€ãˆã‚‹å“è³ªã‚’å®Ÿç¾ã—ã¦ã„ã¾ã™ã€‚

## ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‹RAGãŒå¿…è¦ãªç†ç”±ã‚’ç†è§£ã™ã‚‹

2026å¹´ç¾åœ¨ã€å˜ç´”ãªRetrieveâ†’Generateã®1ãƒ‘ã‚¹RAGã§ã¯æœ¬ç•ªé‹ç”¨ã«è€ãˆã‚‰ã‚Œãªã„ã‚±ãƒ¼ã‚¹ãŒå¢—ãˆã¦ã„ã¾ã™ã€‚æ¤œç´¢çµæœã®å“è³ªã«ã°ã‚‰ã¤ããŒã‚ã‚Šã€ãã®ã¾ã¾ç”Ÿæˆã«æ¸¡ã™ã¨ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ãŒé »ç™ºã™ã‚‹ãŸã‚ã§ã™ã€‚

### 1ãƒ‘ã‚¹RAGã®é™ç•Œ

å¾“æ¥ã®RAGãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã¯ã€Œæ¤œç´¢â†’ç”Ÿæˆã€ã®ä¸€æ–¹é€šè¡Œã§ã—ãŸã€‚ã“ã®æ§‹é€ ã«ã¯3ã¤ã®æ ¹æœ¬çš„ãªå•é¡ŒãŒã‚ã‚Šã¾ã™ã€‚

1. **æ¤œç´¢å“è³ªã®æ¤œè¨¼ãŒãªã„**: å–å¾—ã—ãŸæ–‡æ›¸ãŒè³ªå•ã«é–¢é€£ã—ã¦ã„ã‚‹ã‹è©•ä¾¡ã›ãšã€ãã®ã¾ã¾ç”Ÿæˆã«æ¸¡ã™
2. **ã‚¯ã‚¨ãƒªã®æ›–æ˜§ã•ã«å¯¾å¿œã§ããªã„**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ãŒæ›–æ˜§ã§ã‚‚ã€ãã®ã¾ã¾æ¤œç´¢ã—ã¦ã—ã¾ã†
3. **ç”Ÿæˆçµæœã®æ¤œè¨¼ãŒãªã„**: ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ã‚’å«ã‚€å›ç­”ã‚’ãã®ã¾ã¾è¿”ã—ã¦ã—ã¾ã†

å®Ÿéš›ã«ã€ç¤¾å†…ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ ã§1ãƒ‘ã‚¹RAGã‚’é‹ç”¨ã—ãŸã¨ã“ã‚ã€**å›ç­”ã®ç´„12%ã«ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ãŒå«ã¾ã‚Œã¦ã„ã‚‹**ã“ã¨ãŒåˆ¤æ˜ã—ã¾ã—ãŸã€‚ã“ã‚Œã¯é€±ã«æ•°ç™¾ä»¶ã®å•ã„åˆã‚ã›ãŒã‚ã‚‹ç’°å¢ƒã§ã¯è‡´å‘½çš„ã§ã™ã€‚

### ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‹RAGã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ

ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‹RAGã¯ã€LLMã‚’ã€Œæ¨è«–ã‚¨ãƒ³ã‚¸ãƒ³ã€ã¨ã—ã¦æ´»ç”¨ã—ã€æ¤œç´¢ãƒ»è©•ä¾¡ãƒ»ç”Ÿæˆã®ãƒ«ãƒ¼ãƒ—ã‚’å‹•çš„ã«åˆ¶å¾¡ã—ã¾ã™ã€‚LangGraphã®State GraphãŒã“ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã®å®Ÿè£…ã«é©ã—ã¦ã„ã‚‹ã®ã¯ã€**æ¡ä»¶ä»˜ãã‚¨ãƒƒã‚¸ã«ã‚ˆã‚‹å‹•çš„ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°**ã¨**æ˜ç¤ºçš„ãªçŠ¶æ…‹ç®¡ç†**ã‚’æä¾›ã™ã‚‹ã‹ã‚‰ã§ã™ã€‚

```python
# ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‹RAGã®åŸºæœ¬ãƒ•ãƒ­ãƒ¼
# 1. ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¯ã‚¨ãƒª â†’ ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°åˆ¤å®š
# 2. æ¤œç´¢å®Ÿè¡Œ â†’ æ–‡æ›¸ã®é–¢é€£åº¦è©•ä¾¡ï¼ˆGradingï¼‰
# 3. é–¢é€£åº¦ãŒä½ã„å ´åˆ â†’ ã‚¯ã‚¨ãƒªæ›¸ãæ›ãˆ â†’ å†æ¤œç´¢
# 4. é–¢é€£åº¦ãŒé«˜ã„å ´åˆ â†’ å›ç­”ç”Ÿæˆ
# 5. å›ç­”ã®ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³æ¤œè¨¼
# 6. å•é¡ŒãŒã‚ã‚Œã° â†’ å†ç”Ÿæˆ or ã‚¯ã‚¨ãƒªæ›¸ãæ›ãˆ
```

**ãªãœLangGraphã‚’é¸ã‚“ã ã‹:**
- **æ˜ç¤ºçš„ãªçŠ¶æ…‹ç®¡ç†**: TypedDictã§ä¼šè©±å±¥æ­´ãƒ»å–å¾—æ–‡æ›¸ãƒ»ãƒªãƒˆãƒ©ã‚¤å›æ•°ã‚’ä¸€å…ƒç®¡ç†
- **æ¡ä»¶ä»˜ãã‚¨ãƒƒã‚¸**: æ–‡æ›¸ã®å“è³ªã‚¹ã‚³ã‚¢ã«å¿œã˜ã¦ãƒ•ãƒ­ãƒ¼ã‚’å‹•çš„ã«åˆ†å²
- **ãƒ«ãƒ¼ãƒ—ã®ã‚µãƒãƒ¼ãƒˆ**: ã‚¯ã‚¨ãƒªæ›¸ãæ›ãˆâ†’å†æ¤œç´¢ã®åå¾©ã‚’è‡ªç„¶ã«è¡¨ç¾ã§ãã‚‹
- **ãƒ†ã‚¹ã‚¿ãƒ“ãƒªãƒ†ã‚£**: å„ãƒãƒ¼ãƒ‰ã‚’ç‹¬ç«‹ã—ã¦ãƒ†ã‚¹ãƒˆå¯èƒ½

> **æ³¨æ„**: LangGraphã¯LangChainã¨ã¯ç‹¬ç«‹ã—ãŸãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã™ã€‚LangChainã®Chainãƒ‘ã‚¿ãƒ¼ãƒ³ã¨ã¯è¨­è¨ˆæ€æƒ³ãŒç•°ãªã‚Šã€ã‚°ãƒ©ãƒ•ãƒ™ãƒ¼ã‚¹ã®çŠ¶æ…‹é·ç§»ã«ç‰¹åŒ–ã—ã¦ã„ã¾ã™ã€‚LangChain v0.3ä»¥é™ã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹å ´åˆã§ã‚‚ã€LangGraph v0.3.xã‚’åˆ¥é€”ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚

## LangGraphã§Corrective RAGã‚’å®Ÿè£…ã™ã‚‹

Corrective RAGï¼ˆCRAGï¼‰ã¯ã€æ¤œç´¢çµæœã‚’ç”Ÿæˆå‰ã«è©•ä¾¡ã—ã€å“è³ªãŒä½ã„å ´åˆã«ã‚¯ã‚¨ãƒªã‚’æ›¸ãæ›ãˆã¦å†æ¤œç´¢ã™ã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³ã§ã™ã€‚ã“ã“ã§ã¯Claude Sonnet 4.6ã‚’LLMãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã¨ã—ã¦ä½¿ç”¨ã™ã‚‹å®Ÿè£…ã‚’ç´¹ä»‹ã—ã¾ã™ã€‚

### Stateã®å®šç¾©

ã¾ãšã€ã‚°ãƒ©ãƒ•å…¨ä½“ã§å…±æœ‰ã™ã‚‹çŠ¶æ…‹ã‚’å®šç¾©ã—ã¾ã™ã€‚

```python
# corrective_rag.py
from typing import TypedDict
from langgraph.graph import StateGraph, END

class GraphState(TypedDict):
    """ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‹RAGã®çŠ¶æ…‹å®šç¾©"""
    question: str           # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•
    generation: str         # LLMã®ç”Ÿæˆå›ç­”
    documents: list[str]    # å–å¾—ã—ãŸæ–‡æ›¸ãƒªã‚¹ãƒˆ
    retry_count: int        # ãƒªãƒˆãƒ©ã‚¤å›æ•°ï¼ˆç„¡é™ãƒ«ãƒ¼ãƒ—é˜²æ­¢ï¼‰
    grade_score: float      # æ–‡æ›¸ã®é–¢é€£åº¦ã‚¹ã‚³ã‚¢
    is_hallucination: bool  # ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³æ¤œå‡ºãƒ•ãƒ©ã‚°
```

`retry_count`ã‚’å«ã‚ã¦ã„ã‚‹ã®ãŒãƒã‚¤ãƒ³ãƒˆã§ã™ã€‚æœ€åˆã¯ã“ã‚Œã‚’å…¥ã‚Œãšã«å®Ÿè£…ã—ãŸã¨ã“ã‚ã€**ã‚¯ã‚¨ãƒªæ›¸ãæ›ãˆâ†’å†æ¤œç´¢ã®ãƒ«ãƒ¼ãƒ—ãŒç„¡é™ã«ç¶šã**ã‚±ãƒ¼ã‚¹ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚æœ€å¤§3å›ã®ãƒªãƒˆãƒ©ã‚¤åˆ¶é™ã‚’è¨­ã‘ã‚‹ã“ã¨ã§å®‰å®šå‹•ä½œã—ã¦ã„ã¾ã™ã€‚

### Document Gradingãƒãƒ¼ãƒ‰

å–å¾—ã—ãŸæ–‡æ›¸ãŒã‚¯ã‚¨ãƒªã«é–¢é€£ã—ã¦ã„ã‚‹ã‹ã‚’Claude Sonnet 4.6ã§è©•ä¾¡ã—ã¾ã™ã€‚

```python
# nodes/grading.py
from anthropic import Anthropic
from pydantic import BaseModel, Field

class GradeResult(BaseModel):
    """æ–‡æ›¸ã®é–¢é€£åº¦è©•ä¾¡çµæœ"""
    is_relevant: bool = Field(description="æ–‡æ›¸ãŒã‚¯ã‚¨ãƒªã«é–¢é€£ã—ã¦ã„ã‚‹ã‹")
    confidence: float = Field(ge=0.0, le=1.0, description="åˆ¤å®šã®ç¢ºä¿¡åº¦")
    reason: str = Field(description="åˆ¤å®šç†ç”±")

client = Anthropic()

def grade_documents(state: GraphState) -> GraphState:
    """å–å¾—æ–‡æ›¸ã®é–¢é€£åº¦ã‚’è©•ä¾¡ã™ã‚‹ãƒãƒ¼ãƒ‰"""
    question = state["question"]
    documents = state["documents"]

    graded_docs = []
    total_score = 0.0

    for doc in documents:
        response = client.messages.create(
            model="claude-sonnet-4-6",
            max_tokens=1024,
            thinking={"type": "adaptive"},  # Adaptive Thinkingæœ‰åŠ¹åŒ–
            messages=[{
                "role": "user",
                "content": f"""ä»¥ä¸‹ã®æ–‡æ›¸ãŒã‚¯ã‚¨ãƒªã«é–¢é€£ã—ã¦ã„ã‚‹ã‹è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚

ã‚¯ã‚¨ãƒª: {question}

æ–‡æ›¸: {doc}

JSONå½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„:
{{"is_relevant": true/false, "confidence": 0.0-1.0, "reason": "åˆ¤å®šç†ç”±"}}"""
            }]
        )

        # å¿œç­”ã‚’ãƒ‘ãƒ¼ã‚¹ï¼ˆå®Ÿéš›ã«ã¯structured outputã‚’ä½¿ç”¨æ¨å¥¨ï¼‰
        result = parse_grade_result(response.content[0].text)

        if result.is_relevant and result.confidence >= 0.6:
            graded_docs.append(doc)
            total_score += result.confidence

    avg_score = total_score / len(documents) if documents else 0.0

    return {
        **state,
        "documents": graded_docs,
        "grade_score": avg_score,
    }
```

**ãªãœAdaptive Thinkingã‚’ä½¿ã†ã®ã‹:**

Claude Sonnet 4.6ã®Adaptive Thinkingã¯ã€ã‚¯ã‚¨ãƒªã®è¤‡é›‘ã•ã«å¿œã˜ã¦è‡ªå‹•çš„ã«æ¨è«–ã®æ·±ã•ã‚’èª¿æ•´ã—ã¾ã™ã€‚Document Gradingã®ã‚ˆã†ãªåˆ¤å®šã‚¿ã‚¹ã‚¯ã§ã¯ã€å˜ç´”ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒã§åˆ¤å®šã§ãã‚‹ã‚±ãƒ¼ã‚¹ã¨ã€æ–‡è„ˆã‚’æ·±ãç†è§£ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã‚±ãƒ¼ã‚¹ãŒæ··åœ¨ã—ã¾ã™ã€‚Adaptive Thinkingã‚’ä½¿ã†ã“ã¨ã§ã€**ç°¡å˜ãªåˆ¤å®šã¯é«˜é€Ÿã«ã€è¤‡é›‘ãªåˆ¤å®šã¯æ·±ãæ¨è«–**ã™ã‚‹ãƒãƒ©ãƒ³ã‚¹ãŒè‡ªå‹•ã§å–ã‚Œã¾ã™ã€‚

> **åˆ¶ç´„æ¡ä»¶**: Adaptive Thinkingã¯effort=highãŒãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã€ã»ã¼å¸¸ã«æ€è€ƒã‚’è¡Œã„ã¾ã™ã€‚Document Gradingã®ã‚ˆã†ãªå¤§é‡ã®æ–‡æ›¸ã‚’å‡¦ç†ã™ã‚‹ãƒãƒ¼ãƒ‰ã§ã¯ã€effort=mediumã«è¨­å®šã™ã‚‹ã“ã¨ã§ã‚³ã‚¹ãƒˆã‚’æŠ‘ãˆã¤ã¤ååˆ†ãªç²¾åº¦ã‚’ç¶­æŒã§ãã¾ã™ã€‚

### Query Rewritingãƒãƒ¼ãƒ‰

Gradingã§é–¢é€£æ–‡æ›¸ãŒä¸è¶³ã—ãŸå ´åˆã«ã€ã‚¯ã‚¨ãƒªã‚’æ›¸ãæ›ãˆã‚‹ãƒãƒ¼ãƒ‰ã§ã™ã€‚

```python
# nodes/rewriting.py
def rewrite_query(state: GraphState) -> GraphState:
    """ã‚¯ã‚¨ãƒªã‚’ã‚ˆã‚Šæ¤œç´¢ã«é©ã—ãŸå½¢ã«æ›¸ãæ›ãˆã‚‹ãƒãƒ¼ãƒ‰"""
    question = state["question"]
    retry_count = state["retry_count"]

    response = client.messages.create(
        model="claude-sonnet-4-6",
        max_tokens=512,
        thinking={"type": "adaptive"},
        system="ã‚ãªãŸã¯æ¤œç´¢ã‚¯ã‚¨ãƒªã®æœ€é©åŒ–å°‚é–€å®¶ã§ã™ã€‚",
        messages=[{
            "role": "user",
            "content": f"""ä»¥ä¸‹ã®ã‚¯ã‚¨ãƒªã§é–¢é€£æ–‡æ›¸ãŒååˆ†ã«å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚
æ¤œç´¢ã«é©ã—ãŸå½¢ã«æ›¸ãæ›ãˆã¦ãã ã•ã„ã€‚

å…ƒã®ã‚¯ã‚¨ãƒª: {question}
ãƒªãƒˆãƒ©ã‚¤å›æ•°: {retry_count}/3

æ›¸ãæ›ãˆã®æ–¹é‡:
- å°‚é–€ç”¨èªã‚’åŒç¾©èªã«å±•é–‹ã™ã‚‹
- æ›–æ˜§ãªè¡¨ç¾ã‚’å…·ä½“çš„ã«ã™ã‚‹
- æ¤œç´¢ã«ä¸è¦ãªä¿®é£¾èªã‚’é™¤å»ã™ã‚‹

æ›¸ãæ›ãˆãŸã‚¯ã‚¨ãƒªã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚"""
        }]
    )

    rewritten = response.content[0].text.strip()

    return {
        **state,
        "question": rewritten,
        "retry_count": retry_count + 1,
    }
```

### ã‚°ãƒ©ãƒ•ã®æ§‹ç¯‰ã¨æ¡ä»¶ä»˜ããƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

å„ãƒãƒ¼ãƒ‰ã‚’ã‚°ãƒ©ãƒ•ã¨ã—ã¦çµ„ã¿ç«‹ã¦ã€æ¡ä»¶ä»˜ãã‚¨ãƒƒã‚¸ã§å‹•çš„ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚’å®šç¾©ã—ã¾ã™ã€‚

```python
# graph.py
from langgraph.graph import StateGraph, END

def should_retry(state: GraphState) -> str:
    """ãƒªãƒˆãƒ©ã‚¤åˆ¤å®š: é–¢é€£æ–‡æ›¸ãŒä¸è¶³ã—ã€ãƒªãƒˆãƒ©ã‚¤ä¸Šé™ã«é”ã—ã¦ã„ãªã„å ´åˆ"""
    if state["grade_score"] < 0.5 and state["retry_count"] < 3:
        return "rewrite"
    elif state["grade_score"] < 0.5:
        return "fallback"  # ãƒªãƒˆãƒ©ã‚¤ä¸Šé™åˆ°é”
    return "generate"

def check_hallucination(state: GraphState) -> str:
    """ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³æ¤œå‡ºçµæœã«åŸºã¥ããƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°"""
    if state["is_hallucination"] and state["retry_count"] < 3:
        return "regenerate"
    return "end"

# ã‚°ãƒ©ãƒ•å®šç¾©
workflow = StateGraph(GraphState)

# ãƒãƒ¼ãƒ‰è¿½åŠ 
workflow.add_node("retrieve", retrieve_documents)
workflow.add_node("grade", grade_documents)
workflow.add_node("rewrite", rewrite_query)
workflow.add_node("generate", generate_answer)
workflow.add_node("hallucination_check", check_hallucination_node)
workflow.add_node("fallback", fallback_response)

# ã‚¨ãƒƒã‚¸å®šç¾©
workflow.set_entry_point("retrieve")
workflow.add_edge("retrieve", "grade")

# æ¡ä»¶ä»˜ãã‚¨ãƒƒã‚¸: Gradingçµæœã«åŸºã¥ãåˆ†å²
workflow.add_conditional_edges(
    "grade",
    should_retry,
    {
        "rewrite": "rewrite",
        "generate": "generate",
        "fallback": "fallback",
    }
)

workflow.add_edge("rewrite", "retrieve")  # å†æ¤œç´¢ãƒ«ãƒ¼ãƒ—
workflow.add_edge("generate", "hallucination_check")

workflow.add_conditional_edges(
    "hallucination_check",
    check_hallucination,
    {
        "regenerate": "generate",
        "end": END,
    }
)
workflow.add_edge("fallback", END)

# ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«
app = workflow.compile()
```

**ã‚ˆãã‚ã‚‹é–“é•ã„**: æœ€åˆã¯`fallback`ãƒãƒ¼ãƒ‰ã‚’ç”¨æ„ã›ãšã€ãƒªãƒˆãƒ©ã‚¤ä¸Šé™ã«é”ã—ãŸå ´åˆã‚‚ã‚¯ã‚¨ãƒªæ›¸ãæ›ãˆã‚’ç¹°ã‚Šè¿”ã™è¨­è¨ˆã«ã—ã¦ã„ã¾ã—ãŸã€‚ã“ã‚Œã ã¨**ãƒˆãƒ¼ã‚¯ãƒ³ã‚³ã‚¹ãƒˆãŒéš›é™ãªãè†¨ã‚‰ã‚€**ã†ãˆã€æ›¸ãæ›ãˆã‚’é‡ã­ã‚‹ã»ã©ã‚¯ã‚¨ãƒªãŒå…ƒã®æ„å›³ã‹ã‚‰é›¢ã‚Œã¦ã„ãã¾ã™ã€‚ãƒªãƒˆãƒ©ã‚¤ä¸Šé™åˆ°é”æ™‚ã¯ã€Œé–¢é€£æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€ã¨æ­£ç›´ã«è¿”ã™fallbackãƒãƒ¼ãƒ‰ã‚’è¨­ã‘ã‚‹ã“ã¨ã§ã€ã‚³ã‚¹ãƒˆã¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½“é¨“ã®ä¸¡æ–¹ã‚’æ”¹å–„ã§ãã¾ã—ãŸã€‚

## Claude Sonnet 4.6ã®effortãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ç²¾åº¦ã¨ã‚³ã‚¹ãƒˆã‚’æœ€é©åŒ–ã™ã‚‹

Claude Sonnet 4.6ã®å¤§ããªç‰¹å¾´ã®ä¸€ã¤ãŒã€**effortãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**ã«ã‚ˆã‚‹Adaptive Thinkingã®åˆ¶å¾¡ã§ã™ã€‚ã“ã‚Œã¯RAGãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®å„ãƒãƒ¼ãƒ‰ã§æœ€é©ãªè¨­å®šãŒç•°ãªã‚Šã¾ã™ã€‚

### effortãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ä»•çµ„ã¿

Adaptive Thinkingã§ã¯ã€Claude Sonnet 4.6ãŒã‚¯ã‚¨ãƒªã®è¤‡é›‘ã•ã«å¿œã˜ã¦è‡ªå‹•çš„ã«æ¨è«–ã®æ·±ã•ã‚’èª¿æ•´ã—ã¾ã™ã€‚effortãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ãã®é–¾å€¤ã‚’åˆ¶å¾¡ã§ãã¾ã™ã€‚

| effort | å‹•ä½œ | æ¨å¥¨ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ |
|--------|------|------------------|
| `max` | å¸¸ã«æœ€å¤§é™ã®æ€è€ƒã‚’å®Ÿè¡Œ | æœ€çµ‚å›ç­”ç”Ÿæˆã€è¤‡é›‘ãªæ¨è«– |
| `high`ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰ | ã»ã¼å¸¸ã«æ€è€ƒã‚’å®Ÿè¡Œ | Document Gradingã€ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³æ¤œè¨¼ |
| `medium` | å¿…è¦ãªå ´åˆã®ã¿æ€è€ƒ | ã‚¯ã‚¨ãƒªæ›¸ãæ›ãˆã€ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°åˆ¤å®š |
| `low` | ç°¡å˜ãªå•é¡Œã§ã¯æ€è€ƒã‚’ã‚¹ã‚­ãƒƒãƒ— | åˆ†é¡ã‚¿ã‚¹ã‚¯ã€ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå¤‰æ› |

### ãƒãƒ¼ãƒ‰ã”ã¨ã®æœ€é©åŒ–æˆ¦ç•¥

RAGãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®å„ãƒãƒ¼ãƒ‰ã§effortã‚’ä½¿ã„åˆ†ã‘ã‚‹ã“ã¨ã§ã€ç²¾åº¦ã‚’ç¶­æŒã—ã¤ã¤ã‚³ã‚¹ãƒˆã‚’æœ€é©åŒ–ã§ãã¾ã™ã€‚

```python
# effort_config.py
"""RAGãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®ãƒãƒ¼ãƒ‰ã”ã¨ã®effortè¨­å®š"""

EFFORT_CONFIG = {
    "routing": "medium",           # ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°åˆ¤å®šã¯è»½é‡ã§ååˆ†
    "document_grading": "high",    # é–¢é€£åº¦è©•ä¾¡ã¯ç²¾åº¦ãŒé‡è¦
    "query_rewriting": "medium",   # ã‚¯ã‚¨ãƒªæ›¸ãæ›ãˆã¯mediumã§ååˆ†
    "answer_generation": "high",   # å›ç­”ç”Ÿæˆã¯ç²¾åº¦é‡è¦–
    "hallucination_check": "high", # ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³æ¤œè¨¼ã¯ç²¾åº¦å¿…é ˆ
}

def create_message_with_effort(
    question: str,
    system: str,
    node_type: str,
) -> dict:
    """ãƒãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ—ã«å¿œã˜ãŸeffortã§APIã‚³ãƒ¼ãƒ«ã‚’å®Ÿè¡Œ"""
    effort = EFFORT_CONFIG.get(node_type, "high")

    return client.messages.create(
        model="claude-sonnet-4-6",
        max_tokens=4096,
        thinking={"type": "adaptive"},
        # effortãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è¨­å®š
        # æ³¨: effortã¯APIãƒªã‚¯ã‚¨ã‚¹ãƒˆã®ãƒˆãƒƒãƒ—ãƒ¬ãƒ™ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        system=system,
        messages=[{"role": "user", "content": question}],
    )
```

### effortãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®åŠ¹æœæ¸¬å®š

ç¤¾å†…ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ ï¼ˆç´„5,000æ–‡æ›¸ï¼‰ã§ã€effortãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è¨­å®šã«ã‚ˆã‚‹ç²¾åº¦ã¨ã‚³ã‚¹ãƒˆã®å¤‰åŒ–ã‚’æ¸¬å®šã—ã¾ã—ãŸã€‚

| è¨­å®š | Faithfulness | Answer Relevancy | å¹³å‡ãƒ¬ã‚¹ãƒãƒ³ã‚¹ï¼ˆç§’ï¼‰ | ç›¸å¯¾ã‚³ã‚¹ãƒˆ |
|------|-------------|-----------------|---------------------|-----------|
| å…¨ãƒãƒ¼ãƒ‰high | 0.91 | 0.89 | 4.2 | 1.0x |
| ãƒãƒ¼ãƒ‰åˆ¥æœ€é©åŒ– | 0.89 | 0.87 | 2.5 | 0.65x |
| å…¨ãƒãƒ¼ãƒ‰medium | 0.84 | 0.82 | 1.8 | 0.45x |
| å…¨ãƒãƒ¼ãƒ‰low | 0.73 | 0.71 | 1.1 | 0.30x |

**ãƒãƒ¼ãƒ‰åˆ¥æœ€é©åŒ–**ï¼ˆä¸Šè¨˜ã®`EFFORT_CONFIG`ï¼‰ãŒæœ€ã‚‚ãƒãƒ©ãƒ³ã‚¹ã®è‰¯ã„é¸æŠè‚¢ã§ã™ã€‚å…¨ãƒãƒ¼ãƒ‰highã¨æ¯”è¼ƒã—ã¦**ç²¾åº¦ä½ä¸‹ã¯2%ä»¥å†…ã€ã‚³ã‚¹ãƒˆã¯35%å‰Šæ¸›ã€ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã¯40%çŸ­ç¸®**ã¨ã„ã†çµæœã§ã—ãŸã€‚

**ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•**: å…¨ãƒãƒ¼ãƒ‰mediumã«ã™ã‚‹ã¨ã‚³ã‚¹ãƒˆã¯ã•ã‚‰ã«åŠæ¸›ã—ã¾ã™ãŒã€Document Gradingã¨Hallucination Checkã®ç²¾åº¦ãŒè½ã¡ã€**ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ç‡ãŒ2.3%â†’5.8%ã«æ‚ªåŒ–**ã—ã¾ã—ãŸã€‚ã“ã‚Œã‚‰ã®ãƒãƒ¼ãƒ‰ã§ã¯highã‚’ç¶­æŒã™ã‚‹ã“ã¨ã‚’å¼·ãæ¨å¥¨ã—ã¾ã™ã€‚

## RAGASãƒ»DeepEvalã§è©•ä¾¡ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’æ§‹ç¯‰ã™ã‚‹

ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‹RAGã®å“è³ªã‚’å®šé‡çš„ã«æ¸¬å®šã™ã‚‹ãŸã‚ã«ã€RAGASï¼ˆRetrieval Augmented Generation Assessmentï¼‰ã¨DeepEvalã‚’çµ„ã¿åˆã‚ã›ãŸè©•ä¾¡ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’æ§‹ç¯‰ã—ã¾ã™ã€‚

### è©•ä¾¡æŒ‡æ¨™ã®é¸å®š

RAGã‚·ã‚¹ãƒ†ãƒ ã®è©•ä¾¡ã«ã¯ã€**æ¤œç´¢å“è³ª**ã¨**ç”Ÿæˆå“è³ª**ã®ä¸¡é¢ã‚’æ¸¬å®šã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚

| ã‚«ãƒ†ã‚´ãƒª | æŒ‡æ¨™ | æ¸¬å®šå†…å®¹ | é–¾å€¤ |
|---------|------|---------|------|
| æ¤œç´¢å“è³ª | Context Precision | é–¢é€£æ–‡æ›¸ãŒä¸Šä½ã«ãƒ©ãƒ³ã‚¯ã•ã‚Œã¦ã„ã‚‹ã‹ | â‰¥ 0.80 |
| æ¤œç´¢å“è³ª | Context Recall | å¿…è¦ãªæƒ…å ±ãŒã™ã¹ã¦å–å¾—ã•ã‚Œã¦ã„ã‚‹ã‹ | â‰¥ 0.75 |
| ç”Ÿæˆå“è³ª | Faithfulness | å›ç­”ãŒå–å¾—æ–‡æ›¸ã«åŸºã¥ã„ã¦ã„ã‚‹ã‹ | â‰¥ 0.85 |
| ç”Ÿæˆå“è³ª | Answer Relevancy | å›ç­”ãŒã‚¯ã‚¨ãƒªã«å¯¾ã—ã¦é©åˆ‡ã‹ | â‰¥ 0.80 |
| ç·åˆ | Hallucination Rate | ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ã®ç™ºç”Ÿç‡ | â‰¤ 5% |

### DeepEvalã§ã®è©•ä¾¡å®Ÿè£…

DeepEvalã¯pytestäº’æ›ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã€CI/CDãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã«çµ±åˆã—ã‚„ã™ã„ã®ãŒç‰¹å¾´ã§ã™ã€‚

```python
# tests/test_rag_evaluation.py
import pytest
from deepeval import evaluate
from deepeval.test_case import LLMTestCase
from deepeval.metrics import (
    AnswerRelevancyMetric,
    FaithfulnessMetric,
    ContextualPrecisionMetric,
    ContextualRecallMetric,
)

# ãƒ¡ãƒˆãƒªã‚¯ã‚¹å®šç¾©
answer_relevancy = AnswerRelevancyMetric(
    threshold=0.8,
    model="claude-sonnet-4-6",  # è©•ä¾¡ã«ã‚‚Claude Sonnet 4.6ã‚’ä½¿ç”¨
)
faithfulness = FaithfulnessMetric(
    threshold=0.85,
    model="claude-sonnet-4-6",
)
context_precision = ContextualPrecisionMetric(
    threshold=0.8,
    model="claude-sonnet-4-6",
)
context_recall = ContextualRecallMetric(
    threshold=0.75,
    model="claude-sonnet-4-6",
)

# RAGãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®å®Ÿè¡Œé–¢æ•°
def run_rag_pipeline(query: str) -> tuple[str, list[str]]:
    """RAGãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å®Ÿè¡Œã—ã€å›ç­”ã¨å–å¾—æ–‡æ›¸ã‚’è¿”ã™"""
    result = app.invoke({
        "question": query,
        "generation": "",
        "documents": [],
        "retry_count": 0,
        "grade_score": 0.0,
        "is_hallucination": False,
    })
    return result["generation"], result["documents"]


# ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ç”Ÿæˆ
def create_test_cases() -> list[LLMTestCase]:
    """è©•ä¾¡ç”¨ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã‚’ç”Ÿæˆ"""
    test_queries = [
        {
            "input": "Kubernetesã®ãƒãƒƒãƒ‰ãŒå†èµ·å‹•ã‚’ç¹°ã‚Šè¿”ã™å ´åˆã®å¯¾å‡¦æ³•ã¯ï¼Ÿ",
            "expected_output": "CrashLoopBackOffã®åŸå› èª¿æŸ»æ‰‹é †ã¨ã—ã¦ã€"
                              "kubectl describe podã€ãƒ­ã‚°ç¢ºèªã€"
                              "ãƒªã‚½ãƒ¼ã‚¹åˆ¶é™ã®è¦‹ç›´ã—ãŒå¿…è¦ã§ã™ã€‚",
        },
        {
            "input": "CloudFormationã‚¹ã‚¿ãƒƒã‚¯ã®æ›´æ–°ãŒå¤±æ•—ã—ãŸå ´åˆã®ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯æ‰‹é †ã¯ï¼Ÿ",
            "expected_output": "ã‚¹ã‚¿ãƒƒã‚¯ã®ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯ã¯è‡ªå‹•ã§è¡Œã‚ã‚Œã¾ã™ãŒã€"
                              "UPDATE_ROLLBACK_FAILEDçŠ¶æ…‹ã®å ´åˆã¯"
                              "æ‰‹å‹•ã§ãƒªã‚½ãƒ¼ã‚¹ã‚’ä¿®æ­£ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚",
        },
        {
            "input": "GitHub Actionsã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãŒé€”ä¸­ã§ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã™ã‚‹åŸå› ã¯ï¼Ÿ",
            "expected_output": "ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã¯360åˆ†ã§ã™ã€‚"
                              "timeout-minutesã®è¨­å®šã€ã‚»ãƒ«ãƒ•ãƒ›ã‚¹ãƒˆãƒ©ãƒ³ãƒŠãƒ¼ã®"
                              "ãƒªã‚½ãƒ¼ã‚¹ä¸è¶³ã€ç„¡é™ãƒ«ãƒ¼ãƒ—ã®å¯èƒ½æ€§ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚",
        },
    ]

    test_cases = []
    for query_data in test_queries:
        actual_output, retrieved_contexts = run_rag_pipeline(query_data["input"])
        test_cases.append(
            LLMTestCase(
                input=query_data["input"],
                actual_output=actual_output,
                expected_output=query_data["expected_output"],
                retrieval_context=retrieved_contexts,
            )
        )
    return test_cases


def test_rag_quality():
    """RAGãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®å“è³ªè©•ä¾¡ãƒ†ã‚¹ãƒˆ"""
    test_cases = create_test_cases()

    results = evaluate(
        test_cases,
        metrics=[
            answer_relevancy,
            faithfulness,
            context_precision,
            context_recall,
        ],
    )

    # å…¨ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã§é–¾å€¤ã‚’æº€ãŸã™ã“ã¨ã‚’ç¢ºèª
    for result in results.test_results:
        assert result.success, (
            f"ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ '{result.input}' ãŒé–¾å€¤ã‚’æº€ãŸã—ã¦ã„ã¾ã›ã‚“: "
            f"{result.metrics_data}"
        )
```

**ãªãœDeepEvalã‚’é¸ã‚“ã ã‹:**
- **pytestäº’æ›**: æ—¢å­˜ã®ãƒ†ã‚¹ãƒˆã‚¤ãƒ³ãƒ•ãƒ©ã«ãã®ã¾ã¾çµ±åˆã§ãã‚‹
- **LLM-as-Judge**: äººæ‰‹ã®ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãªã—ã§è©•ä¾¡å¯èƒ½ï¼ˆRAGASã¨åŒã˜ã‚¢ãƒ—ãƒ­ãƒ¼ãƒï¼‰
- **CI/CDçµ±åˆ**: GitHub Actionsã‚„CircleCIã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã«çµ„ã¿è¾¼ã¿ã‚„ã™ã„

**ãƒãƒã‚Šãƒã‚¤ãƒ³ãƒˆ**: DeepEvalã®`model`ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«Claude Sonnet 4.6ã‚’æŒ‡å®šã™ã‚‹å ´åˆã€`ANTHROPIC_API_KEY`ç’°å¢ƒå¤‰æ•°ã®è¨­å®šãŒå¿…è¦ã§ã™ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã¯OpenAIã®GPT-4oãŒä½¿ç”¨ã•ã‚Œã‚‹ãŸã‚ã€è©•ä¾¡ãƒ¢ãƒ‡ãƒ«ã¨RAGãƒ¢ãƒ‡ãƒ«ãŒç•°ãªã‚‹ã¨ã„ã†æ„å›³ã—ãªã„çŠ¶æ…‹ã«ãªã‚ŠãŒã¡ã§ã™ã€‚è©•ä¾¡ã®ä¸€è²«æ€§ã®ãŸã‚ã«ã‚‚ã€RAGã¨åŒã˜ãƒ¢ãƒ‡ãƒ«ã§è©•ä¾¡ã™ã‚‹ã“ã¨ã‚’æ¨å¥¨ã—ã¾ã™ã€‚

### RAGASã¨ã®ä½µç”¨

DeepEvalã«åŠ ãˆã€RAGASã‚‚ä½µç”¨ã™ã‚‹ã¨ã‚ˆã‚Šå¤šè§’çš„ãªè©•ä¾¡ãŒå¯èƒ½ã§ã™ã€‚RAGASã¯**å‚ç…§ãªã—è©•ä¾¡ï¼ˆreference-freeï¼‰**ãŒç‰¹å¾´ã§ã€ground truthãªã—ã§ã‚‚Faithfulnessã‚„Answer Relevancyã‚’æ¸¬å®šã§ãã¾ã™ã€‚

| è¦³ç‚¹ | DeepEval | RAGAS |
|------|----------|-------|
| CI/CDçµ±åˆ | pytestäº’æ›ã§å®¹æ˜“ | ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡ŒãŒåŸºæœ¬ |
| å‚ç…§ãªã—è©•ä¾¡ | æœŸå¾…å‡ºåŠ›ãŒå¿…è¦ãªæŒ‡æ¨™ã‚ã‚Š | å‚ç…§ãªã—ã§å‹•ä½œ |
| ã‚«ã‚¹ã‚¿ãƒ æŒ‡æ¨™ | ç‹¬è‡ªãƒ¡ãƒˆãƒªã‚¯ã‚¹å®šç¾©å¯èƒ½ | ãƒ—ãƒªã‚»ãƒƒãƒˆä¸­å¿ƒ |
| æ¨å¥¨ç”¨é€” | é–‹ç™ºæ™‚ã®è‡ªå‹•ãƒ†ã‚¹ãƒˆ | å®šæœŸçš„ãªãƒãƒƒãƒè©•ä¾¡ |

RAGASã®å®Ÿè£…ã§ã¯`LangchainLLMWrapper`çµŒç”±ã§Claude Sonnet 4.6ã‚’è©•ä¾¡ãƒ¢ãƒ‡ãƒ«ã«è¨­å®šã—ã€`ragas.evaluate()`ã«Datasetã¨metricsã‚’æ¸¡ã™ã ã‘ã§å®Ÿè¡Œã§ãã¾ã™ã€‚è©³ç´°ã¯[RAGASå…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](https://docs.ragas.io/en/stable/)ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚

## Corrective RAGã¨Self-Reflective RAGã®è©•ä¾¡æ¯”è¼ƒã‚’å®Ÿæ–½ã™ã‚‹

åŒã˜è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ã£ã¦ã€3ã¤ã®RAGãƒ‘ã‚¿ãƒ¼ãƒ³ã®ç²¾åº¦ã‚’æ¯”è¼ƒã—ã¾ã—ãŸã€‚

### æ¯”è¼ƒå¯¾è±¡ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

1. **Naive RAG**: æ¤œç´¢â†’ç”Ÿæˆã®1ãƒ‘ã‚¹
2. **Corrective RAGï¼ˆCRAGï¼‰**: æ¤œç´¢â†’æ–‡æ›¸è©•ä¾¡â†’ï¼ˆæ›¸ãæ›ãˆâ†’å†æ¤œç´¢ï¼‰â†’ç”Ÿæˆ
3. **Self-Reflective RAG**: CRAG + ç”Ÿæˆçµæœã®ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³æ¤œè¨¼â†’å†ç”Ÿæˆ

### è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ

ç¤¾å†…ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆï¼ˆã‚¤ãƒ³ãƒ•ãƒ©é‹ç”¨ãƒãƒ‹ãƒ¥ã‚¢ãƒ«ã€APIä»•æ§˜æ›¸ã€ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚¬ã‚¤ãƒ‰ï¼‰ç´„5,000ä»¶ã‚’å¯¾è±¡ã«ã€50ä»¶ã®è©•ä¾¡ã‚¯ã‚¨ãƒªã‚’ä½œæˆã—ã¾ã—ãŸã€‚å„ã‚¯ã‚¨ãƒªã«ã¯äººæ‰‹ã§ä½œæˆã—ãŸæ­£è§£å›ç­”ï¼ˆground truthï¼‰ã‚’ç”¨æ„ã—ã¦ã„ã¾ã™ã€‚

### æ¯”è¼ƒçµæœ

| æŒ‡æ¨™ | Naive RAG | Corrective RAG | Self-Reflective RAG |
|------|-----------|----------------|---------------------|
| Faithfulness | 0.72 | 0.86 | **0.91** |
| Answer Relevancy | 0.68 | 0.82 | **0.89** |
| Context Precision | 0.75 | **0.88** | 0.88 |
| Context Recall | 0.70 | 0.79 | **0.82** |
| Hallucination Rate | 12.0% | 4.1% | **2.3%** |
| å¹³å‡ãƒ¬ã‚¹ãƒãƒ³ã‚¹ï¼ˆç§’ï¼‰ | **1.2** | 2.8 | 4.2 |
| å¹³å‡ãƒˆãƒ¼ã‚¯ãƒ³æ¶ˆè²» | **1,200** | 3,400 | 5,100 |

### çµæœã®åˆ†æ

**Corrective RAGã®åŠ¹æœ**: Document Gradingã®å°å…¥ã ã‘ã§ã€FaithfulnessãŒ0.72â†’0.86ï¼ˆ+19%ï¼‰ã«å¤§å¹…æ”¹å–„ã—ã¾ã—ãŸã€‚é–¢é€£æ€§ã®ä½ã„æ–‡æ›¸ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã™ã‚‹ã“ã¨ã§ã€ç”Ÿæˆå“è³ªãŒåŠ‡çš„ã«å‘ä¸Šã—ã¾ã™ã€‚ã‚³ã‚¹ãƒˆå¢—ã¯ç´„2.8å€ã§ã™ãŒã€ç²¾åº¦å‘ä¸Šã‚’è€ƒãˆã‚Œã°ååˆ†ã«è¦‹åˆã†æŠ•è³‡ã§ã™ã€‚

**Self-Reflective RAGã®è¿½åŠ åŠ¹æœ**: ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³æ¤œè¨¼ã‚’è¿½åŠ ã™ã‚‹ã“ã¨ã§ã€FaithfulnessãŒã•ã‚‰ã«0.86â†’0.91ã«æ”¹å–„ã—ã¾ã—ãŸã€‚ãŸã ã—ã€ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“ãŒ4.2ç§’ã¨ã‚„ã‚„é•·ããªã‚Šã¾ã™ã€‚ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ€§ãŒæ±‚ã‚ã‚‰ã‚Œã‚‹ãƒãƒ£ãƒƒãƒˆUIã§ã¯ã€**Corrective RAGã§ååˆ†ãªã‚±ãƒ¼ã‚¹ã‚‚å¤šã„**ã§ã™ã€‚

**ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã®åˆ¤æ–­åŸºæº–:**

```
Corrective RAGãŒé©åˆ‡ãªã‚±ãƒ¼ã‚¹:
- ãƒ¬ã‚¹ãƒãƒ³ã‚¹3ç§’ä»¥å†…ãŒè¦ä»¶
- ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ç‡5%ä»¥ä¸‹ã§è¨±å®¹å¯èƒ½
- ã‚³ã‚¹ãƒˆäºˆç®—ã«åˆ¶ç´„ãŒã‚ã‚‹

Self-Reflective RAGãŒé©åˆ‡ãªã‚±ãƒ¼ã‚¹:
- åŒ»ç™‚ãƒ»æ³•å¾‹ãªã©æ­£ç¢ºæ€§ãŒæœ€é‡è¦
- éåŒæœŸå‡¦ç†ï¼ˆãƒãƒƒãƒç”Ÿæˆï¼‰ãŒè¨±å®¹ã•ã‚Œã‚‹
- ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ç‡3%ä»¥ä¸‹ãŒè¦ä»¶
```

### å¤±æ•—ãƒ‘ã‚¿ãƒ¼ãƒ³ã®è©³ç´°åˆ†æ

è©•ä¾¡ä¸­ã«ç™ºè¦‹ã—ãŸå…¸å‹çš„ãªå¤±æ•—ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’3ã¤ç´¹ä»‹ã—ã¾ã™ã€‚

**ãƒ‘ã‚¿ãƒ¼ãƒ³1: ã‚¯ã‚¨ãƒªæ›¸ãæ›ãˆã®åŠ£åŒ–**

ã‚¯ã‚¨ãƒªæ›¸ãæ›ãˆã‚’3å›ç¹°ã‚Šè¿”ã™ã¨ã€å…ƒã®ã‚¯ã‚¨ãƒªã®æ„å›³ã‹ã‚‰é›¢ã‚Œã¦ã—ã¾ã†ã‚±ãƒ¼ã‚¹ãŒã‚ã‚Šã¾ã—ãŸã€‚ä¾‹ãˆã°ã€ŒECSã‚¿ã‚¹ã‚¯ã®ãƒ¡ãƒ¢ãƒªä¸è¶³ã‚¨ãƒ©ãƒ¼ã€ã¨ã„ã†ã‚¯ã‚¨ãƒªãŒã€3å›ç›®ã®æ›¸ãæ›ãˆã§ã€Œã‚³ãƒ³ãƒ†ãƒŠã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ ãƒ¡ãƒ¢ãƒªç®¡ç† ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã€ã¨ã„ã†åºƒã™ãã‚‹ã‚¯ã‚¨ãƒªã«å¤‰åŒ–ã—ã€ç„¡é–¢ä¿‚ãªæ–‡æ›¸ãŒå–å¾—ã•ã‚Œã¾ã—ãŸã€‚

**å¯¾ç­–**: ãƒªãƒˆãƒ©ã‚¤ä¸Šé™ã‚’3å›ã«è¨­å®šã—ã€2å›ç›®ä»¥é™ã¯å…ƒã®ã‚¯ã‚¨ãƒªã‚‚æ¤œç´¢ã«å«ã‚ã‚‹ã€Œå…ƒã‚¯ã‚¨ãƒªä¿æŒã€æˆ¦ç•¥ã‚’æ¡ç”¨ã—ã¾ã—ãŸã€‚

**ãƒ‘ã‚¿ãƒ¼ãƒ³2: Gradingé–¾å€¤ã®æœ€é©åŒ–ä¸è¶³**

å½“åˆã€Gradingã®é–¾å€¤ã‚’0.8ã«è¨­å®šã—ã¦ã„ãŸã¨ã“ã‚ã€é–¢é€£æ–‡æ›¸ã®å¤šããŒé™¤å¤–ã•ã‚Œã¦ã—ã¾ã„ã€Context RecallãŒ0.60ã¾ã§ä½ä¸‹ã—ã¾ã—ãŸã€‚

**å¯¾ç­–**: é–¾å€¤ã‚’0.6ã«ä¸‹ã’ã€ä»£ã‚ã‚Šã«å–å¾—æ–‡æ›¸æ•°ã®ä¸Šé™ã‚’5ä»¶ã«è¨­å®šã—ã¾ã—ãŸã€‚ã“ã‚Œã«ã‚ˆã‚Šã€é©åº¦ã«ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã—ã¤ã¤ã€å¿…è¦ãªæƒ…å ±ã‚’å–ã‚Šã“ã¼ã•ãªã„ãƒãƒ©ãƒ³ã‚¹ãŒå–ã‚Œã¾ã—ãŸã€‚

**ãƒ‘ã‚¿ãƒ¼ãƒ³3: ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³æ¤œè¨¼ã®å½é™½æ€§**

Self-Reflective RAGã®ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³æ¤œè¨¼ã§ã€æ­£ã—ã„å›ç­”ã‚’ã€Œãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ã€ã¨èª¤åˆ¤å®šã™ã‚‹ã‚±ãƒ¼ã‚¹ãŒç´„3%ç™ºç”Ÿã—ã¾ã—ãŸã€‚ç‰¹ã«ã€å–å¾—æ–‡æ›¸ã«ã¯æš—é»™çš„ã«å«ã¾ã‚Œã¦ã„ã‚‹ãŒæ˜ç¤ºçš„ã«è¨˜è¿°ã•ã‚Œã¦ã„ãªã„æƒ…å ±ã«åŸºã¥ãå›ç­”ãŒèª¤åˆ¤å®šã•ã‚Œã‚„ã™ã„å‚¾å‘ãŒã‚ã‚Šã¾ã—ãŸã€‚

**å¯¾ç­–**: ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³æ¤œè¨¼ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«ã€Œæ–‡æ›¸ã‹ã‚‰åˆç†çš„ã«æ¨è«–ã§ãã‚‹å†…å®¹ã¯è¨±å®¹ã™ã‚‹ã€ã¨ã„ã†æ¡ä»¶ã‚’è¿½åŠ ã—ã¾ã—ãŸã€‚

## è©•ä¾¡ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’CI/CDã«çµ±åˆã™ã‚‹

æœ¬ç•ªé‹ç”¨ã§ã¯ã€ã‚³ãƒ¼ãƒ‰å¤‰æ›´ã‚„ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ›´æ–°ã®ãŸã³ã«RAGã®å“è³ªã‚’è‡ªå‹•æ¤œè¨¼ã™ã‚‹ä»•çµ„ã¿ãŒå¿…è¦ã§ã™ã€‚DeepEvalã¯pytestäº’æ›ãªã®ã§ã€GitHub Actionsã¨ã®çµ±åˆã¯ç°¡å˜ã§ã™ã€‚

### GitHub Actionsãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼

```yaml
# .github/workflows/rag-evaluation.yml
name: RAG Evaluation Pipeline
on:
  push:
    branches: [main]
    paths: ['src/rag/**', 'prompts/**', 'knowledge_base/**']
  schedule:
    - cron: '0 3 * * 1'  # æ¯é€±æœˆæ›œ3:00 UTC

jobs:
  evaluate:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: '3.12'
      - run: pip install uv && uv sync
      - name: Run RAG evaluation
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        run: uv run pytest tests/test_rag_evaluation.py -v --junitxml=results.xml
      - uses: actions/upload-artifact@v4
        if: always()
        with:
          name: rag-evaluation-results
          path: results.xml
```

**ãƒãƒã‚Šãƒã‚¤ãƒ³ãƒˆ**: è©•ä¾¡ãƒ†ã‚¹ãƒˆ1å›ã‚ãŸã‚Šã®APIå‘¼ã³å‡ºã—ãŒå¤šã„ï¼ˆ50ã‚¯ã‚¨ãƒª Ã— 4æŒ‡æ¨™ Ã— è©•ä¾¡LLMå‘¼ã³å‡ºã—ï¼‰ãŸã‚ã€**ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã«æ³¨æ„**ãŒå¿…è¦ã§ã™ã€‚ä¸¦åˆ—åº¦ã‚’ä¸‹ã’ã‚‹ã‹ã€ãƒãƒƒãƒãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’æ´»ç”¨ã—ã¦ãã ã•ã„ã€‚

### å“è³ªã‚²ãƒ¼ãƒˆã®è¨­å®š

PRãƒãƒ¼ã‚¸å‰ã«å“è³ªåŸºæº–ã‚’è‡ªå‹•ãƒã‚§ãƒƒã‚¯ã™ã‚‹ã‚²ãƒ¼ãƒˆã‚’è¨­å®šã—ã¾ã™ã€‚

```python
# evaluation/quality_gate.py
QUALITY_GATES = {
    "faithfulness": 0.85,
    "answer_relevancy": 0.80,
    "context_precision": 0.75,
    "hallucination_rate_max": 0.05,
}

def check_quality_gate(results: dict) -> tuple[bool, list[str]]:
    """å“è³ªã‚²ãƒ¼ãƒˆã®ãƒã‚§ãƒƒã‚¯"""
    failures = []
    for metric, threshold in QUALITY_GATES.items():
        if metric == "hallucination_rate_max":
            actual = results.get("hallucination_rate", 1.0)
            if actual > threshold:
                failures.append(f"{metric}: {actual:.2%} > {threshold:.2%}")
        else:
            actual = results.get(metric, 0.0)
            if actual < threshold:
                failures.append(f"{metric}: {actual:.2f} < {threshold:.2f}")
    return len(failures) == 0, failures
```

## ã‚ˆãã‚ã‚‹å•é¡Œã¨è§£æ±ºæ–¹æ³•

ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‹RAGã®å®Ÿè£…ãƒ»é‹ç”¨ã§é­é‡ã—ã‚„ã™ã„å•é¡Œã‚’ã¾ã¨ã‚ã¾ã™ã€‚

| å•é¡Œ | åŸå›  | è§£æ±ºæ–¹æ³• |
|------|------|----------|
| ãƒªãƒˆãƒ©ã‚¤ãƒ«ãƒ¼ãƒ—ãŒæ­¢ã¾ã‚‰ãªã„ | retry_countåˆ¶é™ãªã— | `retry_count`ã‚’Stateã«è¿½åŠ ã—ä¸Šé™3å›ã«åˆ¶é™ |
| Gradingç²¾åº¦ãŒä½ã„ | é–¾å€¤è¨­å®šãŒä¸é©åˆ‡ | 0.5ã€œ0.7ã®ç¯„å›²ã§è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«åŸºã¥ããƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚° |
| ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒé…ã„ | å…¨ãƒãƒ¼ãƒ‰ã§effort=high | ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ãƒ»æ›¸ãæ›ãˆã¯mediumã«æœ€é©åŒ– |
| è©•ä¾¡ã‚³ã‚¹ãƒˆãŒé«˜ã„ | å…¨æŒ‡æ¨™ã‚’æ¯å›è¨ˆç®— | PRæ™‚ã¯Faithfulnessã®ã¿ã€å®šæœŸãƒãƒƒãƒã§å…¨æŒ‡æ¨™å®Ÿè¡Œ |
| ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³èª¤æ¤œå‡º | æ¤œè¨¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒå³æ ¼ã™ãã‚‹ | ã€Œåˆç†çš„æ¨è«–ã¯è¨±å®¹ã€ã®æ¡ä»¶ã‚’ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«è¿½åŠ  |
| Context RecallãŒä½ã„ | ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºãŒå°ã•ã™ãã‚‹ | 512â†’1024ãƒˆãƒ¼ã‚¯ãƒ³ã«æ‹¡å¤§ã—ã€ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—128ã‚’è¨­å®š |
| ã‚¯ã‚¨ãƒªæ›¸ãæ›ãˆã§æ„å›³ãŒå¤‰ã‚ã‚‹ | æ›¸ãæ›ãˆå›æ•°ã®é‡ã­ | å…ƒã‚¯ã‚¨ãƒªã‚’ä¿æŒã—ã€ORæ¤œç´¢ã§ä½µç”¨ |

## ã¾ã¨ã‚ã¨æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

**ã¾ã¨ã‚:**

- **LangGraphã®State Graph**ã¯ã€Corrective RAGãƒ»Self-Reflective RAGã®å®Ÿè£…ã«æœ€é©ã€‚æ¡ä»¶ä»˜ãã‚¨ãƒƒã‚¸ã§å‹•çš„ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚’è‡ªç„¶ã«è¡¨ç¾ã§ãã‚‹
- **Claude Sonnet 4.6ã®effortãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**ã‚’ãƒãƒ¼ãƒ‰ã”ã¨ã«æœ€é©åŒ–ã™ã‚‹ã“ã¨ã§ã€ç²¾åº¦ä½ä¸‹2%ä»¥å†…ã§ã‚³ã‚¹ãƒˆ35%å‰Šæ¸›ãƒ»ãƒ¬ã‚¹ãƒãƒ³ã‚¹40%çŸ­ç¸®ã‚’å®Ÿç¾
- **Self-Reflective RAG**ã¯Faithfulness 0.91ã€ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ç‡2.3%ã‚’é”æˆã€‚Corrective RAGã ã‘ã§ã‚‚ååˆ†ãªã‚±ãƒ¼ã‚¹ãŒå¤šã„
- **DeepEval + RAGASã®ä½µç”¨**ã§ã€CI/CDçµ±åˆã®è‡ªå‹•ãƒ†ã‚¹ãƒˆã¨å®šæœŸãƒãƒƒãƒè©•ä¾¡ã®ä¸¡æ–¹ã‚’ã‚«ãƒãƒ¼
- **å“è³ªã‚²ãƒ¼ãƒˆ**ã‚’PRãƒãƒ¼ã‚¸å‰ã«è¨­å®šã—ã€RAGå“è³ªã®åŠ£åŒ–ã‚’è‡ªå‹•æ¤œçŸ¥

**æ¬¡ã«ã‚„ã‚‹ã¹ãã“ã¨:**

- è‡ªç¤¾ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã§è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆã—ã€ä¸Šè¨˜ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’é©ç”¨ã™ã‚‹
- effortãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æœ€é©å€¤ã‚’è‡ªç¤¾ãƒ‡ãƒ¼ã‚¿ã§æ¤œè¨¼ã™ã‚‹ï¼ˆæœ¬è¨˜äº‹ã®å€¤ã¯å‚è€ƒå€¤ï¼‰
- [LangGraphå…¬å¼ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«](https://docs.langchain.com/oss/python/langgraph/agentic-rag)ã§Corrective RAGã®åŸºæœ¬å®Ÿè£…ã‚’å‹•ã‹ã—ã¦ã¿ã‚‹

**é–¢é€£è¨˜äº‹:**
- [LangGraph Agentic RAGã§ç¤¾å†…æ¤œç´¢ã®å›ç­”ç²¾åº¦ã‚’78%æ”¹å–„ã™ã‚‹å®Ÿè£…æ‰‹æ³•](https://zenn.dev/0h_n0/articles/4c869d366e5200)
- [LangGraphå‹•çš„æ¤œç´¢ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°å®Ÿè£…ï¼šã‚¯ã‚¨ãƒªåˆ†é¡Ã—ãƒãƒ«ãƒãƒªãƒˆãƒªãƒ¼ãƒãƒ¼ã§QAç²¾åº¦ã‚’å‘ä¸Šã•ã›ã‚‹](https://zenn.dev/0h_n0/articles/3b9f2fd87ffb09)

## å‚è€ƒ

- [LangGraphå…¬å¼: Build a custom RAG agent](https://docs.langchain.com/oss/python/langgraph/agentic-rag)
- [What's new in Claude 4.6 - Anthropicå…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](https://platform.claude.com/docs/en/about-claude/models/whats-new-claude-4-6)
- [DeepEval RAG Evaluation Quickstart](https://deepeval.com/docs/getting-started-rag)
- [RAGAS: Automated Evaluation of Retrieval Augmented Generation](https://arxiv.org/html/2309.15217v1)
- [Self-Reflective RAG with LangGraph - LangChain Blog](https://blog.langchain.com/agentic-rag-with-langgraph/)
- [Corrective RAG (CRAG) Implementation With LangGraph - DataCamp](https://www.datacamp.com/tutorial/corrective-rag-crag)
- [Top 5 RAG Evaluation Platforms in 2026](https://www.getmaxim.ai/articles/top-5-rag-evaluation-platforms-in-2026/)

---

:::message
ã“ã®è¨˜äº‹ã¯AIï¼ˆClaude Codeï¼‰ã«ã‚ˆã‚Šè‡ªå‹•ç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚å†…å®¹ã®æ­£ç¢ºæ€§ã«ã¤ã„ã¦ã¯è¤‡æ•°ã®æƒ…å ±æºã§æ¤œè¨¼ã—ã¦ã„ã¾ã™ãŒã€å®Ÿéš›ã®åˆ©ç”¨æ™‚ã¯å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚‚ã”ç¢ºèªãã ã•ã„ã€‚
:::
