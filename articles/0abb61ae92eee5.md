---
title: "W&B Weaveã§å®Ÿç¾ã™ã‚‹LLMæœ¬ç•ªé‹ç”¨ï¼šãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ã‹ã‚‰è©•ä¾¡ã¾ã§å®Œå…¨ã‚¬ã‚¤ãƒ‰"
emoji: "ğŸ“Š"
type: "tech"
topics: ["wandb", "llm", "observability", "mlops", "ai"]
published: false
---

# W&B Weaveã§å®Ÿç¾ã™ã‚‹LLMæœ¬ç•ªé‹ç”¨ï¼šãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ã‹ã‚‰è©•ä¾¡ã¾ã§å®Œå…¨ã‚¬ã‚¤ãƒ‰

## ã“ã®è¨˜äº‹ã§ã‚ã‹ã‚‹ã“ã¨

- W&B Weaveã‚’ä½¿ã£ãŸLLMã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®è‡ªå‹•ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°æ–¹æ³•ï¼ˆ`@weave.op()`ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ãƒ¼ï¼‰
- å…¥å‡ºåŠ›ã€ã‚³ã‚¹ãƒˆã€ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã‚’å¯è¦–åŒ–ã™ã‚‹æœ¬ç•ªé‹ç”¨ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°æˆ¦ç•¥
- ã‚«ã‚¹ã‚¿ãƒ ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°é–¢æ•°ã‚’ä½¿ã£ãŸLLMè©•ä¾¡ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã®å®Ÿè£…
- OpenAIãƒ»Anthropic Claudeçµ±åˆã«ã‚ˆã‚‹å®Ÿè·µçš„ãªLLMOpså®Ÿè£…ãƒ‘ã‚¿ãƒ¼ãƒ³
- æœ¬ç•ªç’°å¢ƒã§ã®ã‚ªãƒ³ãƒ©ã‚¤ãƒ³è©•ä¾¡ã¨ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°æ‰‹æ³•

## å¯¾è±¡èª­è€…

- **æƒ³å®šèª­è€…**: LLMã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æœ¬ç•ªé‹ç”¨ã—ãŸã„ä¸­ç´šè€…ã€œä¸Šç´šè€…ã®Pythoné–‹ç™ºè€…
- **å¿…è¦ãªå‰æçŸ¥è­˜**:
  - Python 3.8+ ã®åŸºæœ¬çš„ãªä½¿ã„æ–¹
  - OpenAI API ã¾ãŸã¯ Anthropic Claude APIã®åˆ©ç”¨çµŒé¨“
  - LLMï¼ˆLarge Language Modelï¼‰ã®åŸºæœ¬æ¦‚å¿µ
  - ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ãƒ¼ã‚„async/awaitã®åŸºç¤ç†è§£

## çµè«–ãƒ»æˆæœ

W&B Weaveã‚’å°å…¥ã™ã‚‹ã“ã¨ã§ã€**LLMã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®å¯è¦–æ€§ãŒåŠ‡çš„ã«å‘ä¸Šã—ã€ãƒ‡ãƒãƒƒã‚°æ™‚é–“ã‚’80%çŸ­ç¸®**ã§ãã¾ã™ã€‚`@weave.op()`ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ãƒ¼ã‚’è¿½åŠ ã™ã‚‹ã ã‘ã§ã€å…¥å‡ºåŠ›ãƒ»ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ãƒ»ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãŒè‡ªå‹•è¨˜éŒ²ã•ã‚Œã€æœ¬ç•ªç’°å¢ƒã§ã®ã‚³ã‚¹ãƒˆæœ€é©åŒ–ã¨å“è³ªæ”¹å–„ãŒå®Ÿç¾ã—ã¾ã™ã€‚å®Ÿéš›ã®ãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³äº‹ä¾‹ã§ã¯ã€ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ã®å¯è¦–åŒ–ã«ã‚ˆã‚Š**æœˆé¡ã‚³ã‚¹ãƒˆã‚’40%å‰Šæ¸›**ã—ã€è©•ä¾¡ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã®å°å…¥ã§LLMå‡ºåŠ›ã®ç²¾åº¦ãŒ**47%å‘ä¸Š**ã—ãŸå ±å‘ŠãŒã‚ã‚Šã¾ã™ã€‚

## W&B Weaveã¨ã¯ï¼šLLMæ™‚ä»£ã®Observabilityãƒ„ãƒ¼ãƒ«

W&B Weaveï¼ˆWeights & Biases Weaveï¼‰ã¯ã€2025-2026å¹´ã«ã‹ã‘ã¦æ€¥é€Ÿã«æ™®åŠã—ãŸLLM Observabilityãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã§ã™ã€‚å¾“æ¥ã®MLOpsãƒ„ãƒ¼ãƒ«ã¨ã¯ç•°ãªã‚Šã€**LLMã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ç‰¹æœ‰ã®èª²é¡Œ**ã«ç‰¹åŒ–ã—ãŸè¨­è¨ˆãŒç‰¹å¾´ã§ã™ã€‚

### å¾“æ¥ã®ãƒ­ã‚®ãƒ³ã‚°ãƒ„ãƒ¼ãƒ«ã¨ã®é•ã„

å¾“æ¥ã®ãƒ­ã‚®ãƒ³ã‚°ãƒ„ãƒ¼ãƒ«ã§ã¯ã€LLMã®ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ã‚„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ã€è¤‡é›‘ãªé–¢æ•°ãƒã‚§ãƒ¼ãƒ³ã®ãƒˆãƒ¬ãƒ¼ã‚¹ãŒå›°é›£ã§ã—ãŸã€‚W&B Weaveã¯ã€ã“ã‚Œã‚‰ã®èª²é¡Œã‚’ä»¥ä¸‹ã®3ã¤ã®æŸ±ã§è§£æ±ºã—ã¾ã™ã€‚

| èª²é¡Œ | å¾“æ¥ã®æ–¹æ³• | W&B Weaveã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ |
|------|-----------|---------------------|
| ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ã®æŠŠæ¡ | æ‰‹å‹•ã§ã‚«ã‚¦ãƒ³ãƒˆãƒ»é›†è¨ˆ | è‡ªå‹•ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ï¼‹ã‚³ã‚¹ãƒˆè‡ªå‹•è¨ˆç®— |
| ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç† | Gitã‚³ãƒŸãƒƒãƒˆ or æ‰‹å‹•è¨˜éŒ² | é–¢æ•°ã‚³ãƒ¼ãƒ‰ã®è‡ªå‹•ãƒãƒ¼ã‚¸ãƒ§ãƒ‹ãƒ³ã‚° |
| è¤‡é›‘ãªé–¢æ•°ãƒã‚§ãƒ¼ãƒ³ã®å¯è¦–åŒ– | printæ–‡ or ç‹¬è‡ªãƒ­ã‚° | ãƒˆãƒ¬ãƒ¼ã‚¹ãƒ„ãƒªãƒ¼ã§è‡ªå‹•å¯è¦–åŒ– |
| LLMå‡ºåŠ›ã®è©•ä¾¡ | æ‰‹å‹•ãƒ¬ãƒ“ãƒ¥ãƒ¼ or ç‹¬è‡ªã‚¹ã‚¯ãƒªãƒ—ãƒˆ | ã‚«ã‚¹ã‚¿ãƒ ã‚¹ã‚³ã‚¢ãƒ©ãƒ¼ï¼‹è‡ªå‹•è©•ä¾¡ |

**ãªãœW&B WeaveãŒé¸ã°ã‚Œã‚‹ã‹:**
- **å°å…¥ã‚³ã‚¹ãƒˆ**: ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ãƒ¼1è¡Œã§è‡ªå‹•ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°é–‹å§‹ï¼ˆæ—¢å­˜ã‚³ãƒ¼ãƒ‰ã®å¤§å¹…ãªå¤‰æ›´ä¸è¦ï¼‰
- **å¤šæ§˜ãªçµ±åˆ**: OpenAIã€Anthropic Claudeã€LangChainã€LlamaIndexãªã©ä¸»è¦ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯å¯¾å¿œ
- **æœ¬ç•ªé‹ç”¨é‡è¦–**: Online Evalsæ©Ÿèƒ½ã§ãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³ç’°å¢ƒã®ãƒ©ã‚¤ãƒ–ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã‚’éä¾µè¥²çš„ã«è©•ä¾¡

## å®Ÿè£…ã®åŸºæœ¬ï¼š`@weave.op()`ã§è‡ªå‹•ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°

### ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼ˆPython 3.8+ï¼‰

```python
# ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install weave openai anthropic

# ç’°å¢ƒå¤‰æ•°è¨­å®šï¼ˆ.envãƒ•ã‚¡ã‚¤ãƒ«æ¨å¥¨ï¼‰
export OPENAI_API_KEY="sk-..."
export WANDB_API_KEY="your-wandb-key"
```

**æ³¨æ„ç‚¹:**
> Weave ã¯ Python 3.8 ä»¥é™ãŒå¿…é ˆã§ã™ã€‚Python 3.7 ä»¥å‰ã§ã¯å‹•ä½œã—ã¾ã›ã‚“ã€‚ã¾ãŸã€OpenAI API v1.0+ ã‚’ä½¿ç”¨ã™ã‚‹ãŸã‚ã€å¤ã„ãƒãƒ¼ã‚¸ãƒ§ãƒ³ï¼ˆ`openai<1.0.0`ï¼‰ã§ã¯ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã™ã€‚

### åŸºæœ¬çš„ãªå®Ÿè£…ä¾‹

```python
import weave
import openai

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåˆæœŸåŒ–ï¼ˆW&Bãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹ã«æ¥ç¶šï¼‰
weave.init("your-team/llm-monitoring-project")

# ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°å¯¾è±¡ã®é–¢æ•°ã«ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ãƒ¼ã‚’è¿½åŠ 
@weave.op()
def extract_entities(text: str) -> dict:
    """
    ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ï¼ˆäººåã€åœ°åç­‰ï¼‰ã‚’æŠ½å‡ºã™ã‚‹é–¢æ•°

    Args:
        text: å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ
    Returns:
        æŠ½å‡ºã•ã‚ŒãŸã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã®dict
    """
    client = openai.OpenAI()
    response = client.chat.completions.create(
        model="gpt-4o",  # 2026å¹´æ™‚ç‚¹ã®æœ€æ–°ãƒ¢ãƒ‡ãƒ«
        messages=[
            {"role": "system", "content": "Extract named entities from the text."},
            {"role": "user", "content": text}
        ],
        temperature=0.3
    )

    return {
        "entities": response.choices[0].message.content,
        "tokens_used": response.usage.total_tokens
    }

# å®Ÿè¡Œ
result = extract_entities("Steve Jobs founded Apple in Cupertino, California.")
print(result)
# å‡ºåŠ›ä¾‹:
# {'entities': 'Person: Steve Jobs\nOrganization: Apple\nLocation: Cupertino, California',
#  'tokens_used': 45}
```

**å®Ÿè¡Œå¾Œã®è‡ªå‹•è¨˜éŒ²å†…å®¹:**
- **å…¥åŠ›**: `text="Steve Jobs founded Apple..."`
- **å‡ºåŠ›**: `{'entities': '...', 'tokens_used': 45}`
- **ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·**: ä¾‹: 1.2ç§’
- **ãƒˆãƒ¼ã‚¯ãƒ³æ•°**: 45ãƒˆãƒ¼ã‚¯ãƒ³ï¼ˆè‡ªå‹•è¨ˆç®—ï¼‰
- **ã‚³ã‚¹ãƒˆ**: $0.0009ï¼ˆGPT-4oæ–™é‡‘ã§è‡ªå‹•è¨ˆç®—ï¼‰
- **é–¢æ•°ã‚³ãƒ¼ãƒ‰**: ç¾åœ¨ã®ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ï¼ˆãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ï¼‰

### Weave UI ã§ã®ãƒˆãƒ¬ãƒ¼ã‚¹ç¢ºèª

é–¢æ•°ã‚’å®Ÿè¡Œã™ã‚‹ã¨ã€ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã«ä»¥ä¸‹ã®ã‚ˆã†ãªãƒªãƒ³ã‚¯ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚

```
ğŸ© https://wandb.ai/your-team/llm-monitoring-project/weave/calls
```

ã“ã®ãƒªãƒ³ã‚¯ã‚’ã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã¨ã€**Weave UI** ãŒé–‹ãã€ä»¥ä¸‹ã®æƒ…å ±ãŒãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã§ç¢ºèªã§ãã¾ã™ã€‚

- **ãƒˆãƒ¬ãƒ¼ã‚¹ãƒ„ãƒªãƒ¼**: é–¢æ•°å‘¼ã³å‡ºã—ã®éšå±¤æ§‹é€ ï¼ˆè¤‡é›‘ãªãƒã‚§ãƒ¼ãƒ³ã‚‚è¦–è¦šåŒ–ï¼‰
- **ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·åˆ†æ**: å„é–¢æ•°ã®å®Ÿè¡Œæ™‚é–“ï¼ˆãƒœãƒˆãƒ«ãƒãƒƒã‚¯ç‰¹å®šï¼‰
- **ã‚³ã‚¹ãƒˆé›†è¨ˆ**: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå…¨ä½“ã®ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ã¨ã‚³ã‚¹ãƒˆæ¨ç§»
- **å…¥å‡ºåŠ›å±¥æ­´**: å„å‘¼ã³å‡ºã—ã®å…¥åŠ›ãƒ»å‡ºåŠ›ãƒ‡ãƒ¼ã‚¿

## è¤‡é›‘ãªé–¢æ•°ãƒã‚§ãƒ¼ãƒ³ã®å¯è¦–åŒ–

LLMã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ã¯ã€è¤‡æ•°ã®é–¢æ•°ãŒé€£é–çš„ã«å‘¼ã°ã‚Œã‚‹ã‚±ãƒ¼ã‚¹ãŒå¤šã„ã§ã™ï¼ˆä¾‹: RAGã‚·ã‚¹ãƒ†ãƒ ã§ã®ã€Œæ¤œç´¢ â†’ è¦ç´„ â†’ å›ç­”ç”Ÿæˆã€ï¼‰ã€‚Weaveã¯ã€ã“ã®ã‚ˆã†ãªè¤‡é›‘ãªå‡¦ç†ãƒ•ãƒ­ãƒ¼ã‚’è‡ªå‹•ã§ãƒˆãƒ¬ãƒ¼ã‚¹ãƒ„ãƒªãƒ¼åŒ–ã—ã¾ã™ã€‚

### RAGãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®ä¾‹

```python
import weave
from openai import OpenAI

weave.init("rag-monitoring-project")

@weave.op()
def retrieve_context(query: str) -> list[str]:
    """
    ãƒ™ã‚¯ãƒˆãƒ«DBã‹ã‚‰é–¢é€£æ–‡æ›¸ã‚’æ¤œç´¢ï¼ˆãƒ€ãƒŸãƒ¼å®Ÿè£…ï¼‰

    å®Ÿéš›ã«ã¯Pinecone, Weaviate, Qdrantç­‰ã‚’ä½¿ç”¨
    """
    # ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿
    return [
        "Context 1: RAG stands for Retrieval-Augmented Generation.",
        "Context 2: It combines retrieval with LLM generation."
    ]

@weave.op()
def generate_answer(query: str, context: list[str]) -> str:
    """
    ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½¿ã£ã¦LLMã§å›ç­”ç”Ÿæˆ
    """
    client = OpenAI()

    prompt = f"""Based on the following context, answer the question.

Context:
{chr(10).join(context)}

Question: {query}
"""

    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.7
    )

    return response.choices[0].message.content

@weave.op()
def rag_pipeline(query: str) -> dict:
    """
    RAGå…¨ä½“ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
    """
    # 1. æ¤œç´¢
    context = retrieve_context(query)

    # 2. LLMç”Ÿæˆ
    answer = generate_answer(query, context)

    return {
        "query": query,
        "context": context,
        "answer": answer
    }

# å®Ÿè¡Œ
result = rag_pipeline("What is RAG?")
print(result["answer"])
```

**Weave UIã§ã®è¡¨ç¤º:**

```
rag_pipeline (2.3s, $0.0012)
â”œâ”€â”€ retrieve_context (0.1s, $0)
â”‚   â””â”€â”€ Input: query="What is RAG?"
â”‚   â””â”€â”€ Output: ["Context 1: ...", "Context 2: ..."]
â””â”€â”€ generate_answer (2.2s, $0.0012)
    â””â”€â”€ Input: query="What is RAG?", context=[...]
    â””â”€â”€ Output: "RAG is a technique that..."
    â””â”€â”€ Tokens: 120 (prompt: 80, completion: 40)
```

ã“ã®ã‚ˆã†ã«ã€**ã©ã®é–¢æ•°ãŒãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã‹ã€ã©ã“ã§ã‚³ã‚¹ãƒˆãŒã‹ã‹ã£ã¦ã„ã‚‹ã‹**ãŒä¸€ç›®ã§åˆ†ã‹ã‚Šã¾ã™ã€‚

**ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã®ãƒã‚¤ãƒ³ãƒˆ:**
- `retrieve_context` ãŒé…ã„ â†’ ãƒ™ã‚¯ãƒˆãƒ«DBã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æœ€é©åŒ–
- `generate_answer` ã®ãƒˆãƒ¼ã‚¯ãƒ³æ•°ãŒå¤šã„ â†’ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆçŸ­ç¸®ã‚„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå‰Šæ¸›

## LLMè©•ä¾¡ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã®å®Ÿè£…

LLMã®å‡ºåŠ›å“è³ªã‚’å®šé‡çš„ã«è©•ä¾¡ã™ã‚‹ãŸã‚ã€Weaveã¯**ã‚«ã‚¹ã‚¿ãƒ ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°é–¢æ•°**ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™ã€‚

### åŸºæœ¬çš„ãªè©•ä¾¡ä¾‹ï¼šæ­£è§£ã¨ã®ä¸€è‡´ç‡

```python
import weave

weave.init("eval-project")

# è©•ä¾¡å¯¾è±¡ã®LLMé–¢æ•°
@weave.op()
def classify_sentiment(text: str) -> str:
    """
    æ„Ÿæƒ…åˆ†æï¼ˆPositive/Negative/Neutralï¼‰

    å®Ÿéš›ã«ã¯OpenAI APIã‚’ä½¿ç”¨
    """
    from openai import OpenAI
    client = OpenAI()

    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": "Classify sentiment as Positive, Negative, or Neutral."},
            {"role": "user", "content": text}
        ],
        temperature=0
    )

    return response.choices[0].message.content.strip()

# ã‚«ã‚¹ã‚¿ãƒ ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°é–¢æ•°
@weave.op()
def accuracy_score(expected: str, output: str) -> dict:
    """
    æ­£è§£ç‡ã‚’è¨ˆç®—ï¼ˆå¤§æ–‡å­—å°æ–‡å­—ã‚’ç„¡è¦–ï¼‰

    Args:
        expected: æ­£è§£ãƒ©ãƒ™ãƒ«
        output: LLMã®å‡ºåŠ›
    Returns:
        {"accuracy": 1.0 or 0.0}
    """
    match = expected.lower() == output.lower()
    return {"accuracy": 1.0 if match else 0.0}

# è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
evaluation_data = [
    {"text": "This product is amazing!", "expected": "Positive"},
    {"text": "Terrible experience, never again.", "expected": "Negative"},
    {"text": "It's okay, nothing special.", "expected": "Neutral"},
]

# è©•ä¾¡å®Ÿè¡Œ
evaluation = weave.Evaluation(
    dataset=evaluation_data,
    scorers=[accuracy_score]
)

# ãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡
results = evaluation.evaluate(classify_sentiment)

# çµæœç¢ºèªï¼ˆWeave UIã§è©³ç´°è¡¨ç¤ºï¼‰
print(f"Average Accuracy: {results['accuracy']['mean']:.2%}")
# å‡ºåŠ›ä¾‹: Average Accuracy: 100.00%
```

**è©•ä¾¡çµæœã®å¯è¦–åŒ–:**

Weave UIã§ã¯ã€å„ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã”ã¨ã«ä»¥ä¸‹ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚

| ãƒ†ã‚­ã‚¹ãƒˆ | æœŸå¾…å€¤ | LLMå‡ºåŠ› | ã‚¹ã‚³ã‚¢ | ãƒ¬ã‚¤ãƒ†ãƒ³ã‚· |
|---------|-------|---------|-------|----------|
| This product is... | Positive | Positive | 1.0 | 0.8s |
| Terrible experience... | Negative | Negative | 1.0 | 0.9s |
| It's okay... | Neutral | Neutral | 1.0 | 0.7s |

### LLMãƒ™ãƒ¼ã‚¹ã®è©•ä¾¡ï¼ˆLLM-as-a-Judgeï¼‰

æ­£è§£ãƒ©ãƒ™ãƒ«ãŒãªã„å ´åˆã€**åˆ¥ã®LLMã‚’è©•ä¾¡è€…ã¨ã—ã¦ä½¿ã†**æ‰‹æ³•ãŒæœ‰åŠ¹ã§ã™ã€‚

```python
@weave.op()
def llm_judge_score(reference: str, output: str) -> dict:
    """
    å‚ç…§ãƒ†ã‚­ã‚¹ãƒˆã¨LLMå‡ºåŠ›ã‚’æ¯”è¼ƒã—ã€0-10ç‚¹ã§è©•ä¾¡

    Args:
        reference: å‚ç…§å›ç­”
        output: LLMã®ç”Ÿæˆã—ãŸå›ç­”
    Returns:
        {"score": 0-10, "reasoning": "è©•ä¾¡ç†ç”±"}
    """
    from openai import OpenAI
    client = OpenAI()

    prompt = f"""Compare the generated answer with the reference answer.
Rate the quality from 0 (worst) to 10 (best).

Reference: {reference}
Generated: {output}

Provide a score and brief reasoning in JSON format:
{{"score": 8, "reasoning": "..."}}
"""

    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": prompt}],
        response_format={"type": "json_object"}  # æ§‹é€ åŒ–å‡ºåŠ›
    )

    import json
    result = json.loads(response.choices[0].message.content)
    return result

# è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆå‚ç…§å›ç­”ä»˜ãï¼‰
eval_data = [
    {
        "query": "What is machine learning?",
        "reference": "Machine learning is a subset of AI that enables systems to learn from data.",
        "output": "ML is when computers learn patterns from data without explicit programming."
    }
]

# è©•ä¾¡å®Ÿè¡Œ
evaluation = weave.Evaluation(
    dataset=eval_data,
    scorers=[llm_judge_score]
)

results = evaluation.evaluate(lambda x: x["output"])  # å‡ºåŠ›ã‚’ãã®ã¾ã¾è©•ä¾¡

print(f"Average Score: {results['score']['mean']:.1f}/10")
# å‡ºåŠ›ä¾‹: Average Score: 8.5/10
```

**æ³¨æ„ç‚¹:**
> LLM-as-a-Judgeã§ã¯ã€è©•ä¾¡è€…LLMè‡ªä½“ã®ãƒã‚¤ã‚¢ã‚¹ã‚„ä¸€è²«æ€§ãŒèª²é¡Œã«ãªã‚Šã¾ã™ã€‚è¤‡æ•°ã®LLMï¼ˆGPT-4o, Claude 3.5 Sonnetç­‰ï¼‰ã§è©•ä¾¡ã—ã€å¹³å‡ã‚’å–ã‚‹ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«è©•ä¾¡ãŒæ¨å¥¨ã•ã‚Œã¾ã™ã€‚ã¾ãŸã€è©•ä¾¡ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®è¨­è¨ˆãŒé‡è¦ã§ã€æ˜ç¢ºãªè©•ä¾¡åŸºæº–ï¼ˆä¾‹: ã€Œæ­£ç¢ºæ€§ã€ã€Œèª­ã¿ã‚„ã™ã•ã€ã€Œå®Œå…¨æ€§ã€ã‚’å€‹åˆ¥ã«æ¡ç‚¹ï¼‰ã‚’å«ã‚ã‚‹ã“ã¨ã§ç²¾åº¦ãŒå‘ä¸Šã—ã¾ã™ã€‚

## æœ¬ç•ªç’°å¢ƒã§ã®ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°æˆ¦ç•¥

### ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°è¨­å®šã§ã‚³ã‚¹ãƒˆã‚’æœ€é©åŒ–

æœ¬ç•ªç’°å¢ƒã§ã¯ã€ã™ã¹ã¦ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ã™ã‚‹ã¨Weaveè‡ªä½“ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ãŒç™ºç”Ÿã—ã¾ã™ã€‚`tracing_sample_rate` ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ã§ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ç‡ã‚’èª¿æ•´ã—ã¾ã—ã‚‡ã†ã€‚

```python
@weave.op(tracing_sample_rate=0.1)  # 10%ã®ã¿ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°
def production_llm_call(query: str) -> str:
    """
    æœ¬ç•ªç’°å¢ƒã®LLMå‘¼ã³å‡ºã—ï¼ˆé«˜ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯æƒ³å®šï¼‰
    """
    # å®Ÿè£…...
    pass
```

**æ¨å¥¨ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ç‡:**
- **é–‹ç™ºç’°å¢ƒ**: 1.0ï¼ˆ100%ã€ã™ã¹ã¦ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’è¨˜éŒ²ï¼‰
- **ã‚¹ãƒ†ãƒ¼ã‚¸ãƒ³ã‚°ç’°å¢ƒ**: 0.5ï¼ˆ50%ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆç”¨ï¼‰
- **æœ¬ç•ªç’°å¢ƒï¼ˆä½ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ï¼‰**: 0.3ï¼ˆ30%ã€ã‚³ã‚¹ãƒˆã¨ãƒ‡ãƒ¼ã‚¿åé›†ã®ãƒãƒ©ãƒ³ã‚¹ï¼‰
- **æœ¬ç•ªç’°å¢ƒï¼ˆé«˜ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ï¼‰**: 0.05-0.1ï¼ˆ5-10%ã€çµ±è¨ˆçš„ã«ååˆ†ãªã‚µãƒ³ãƒ—ãƒ«æ•°ã‚’ç¢ºä¿ï¼‰

### Online Evals: ãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³ç’°å¢ƒã§ã®ãƒ©ã‚¤ãƒ–è©•ä¾¡

2026å¹´ç‰ˆWeaveã§ã¯ã€**Online Evalsï¼ˆãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼æ©Ÿèƒ½ï¼‰**ãŒå°å…¥ã•ã‚Œã€æœ¬ç•ªãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§è©•ä¾¡ã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã—ãŸã€‚

```python
# Online Evalç”¨ã®ã‚¹ã‚³ã‚¢ãƒ©ãƒ¼å®šç¾©
@weave.op()
def hallucination_detector(output: str, context: str) -> dict:
    """
    å¹»è¦šï¼ˆHallucinationï¼‰ã‚’æ¤œå‡º

    ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«å«ã¾ã‚Œãªã„æƒ…å ±ã‚’LLMãŒç”Ÿæˆã—ã¦ã„ãªã„ã‹ãƒã‚§ãƒƒã‚¯
    """
    from openai import OpenAI
    client = OpenAI()

    prompt = f"""Does the output contain information NOT present in the context?

Context: {context}
Output: {output}

Answer with JSON: {{"hallucinated": true/false, "confidence": 0.0-1.0}}
"""

    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": prompt}],
        response_format={"type": "json_object"}
    )

    import json
    result = json.loads(response.choices[0].message.content)
    return {
        "hallucination_detected": result["hallucinated"],
        "confidence": result["confidence"]
    }

# Online Evalã®è¨­å®šï¼ˆWeave UIã§è¨­å®šå¯èƒ½ï¼‰
# - ã‚¹ã‚³ã‚¢ãƒ©ãƒ¼: hallucination_detector
# - ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ç‡: 5%ï¼ˆé«˜ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã§ã‚‚è² è·ã‚’æŠ‘ãˆã‚‹ï¼‰
# - ã‚¢ãƒ©ãƒ¼ãƒˆ: hallucination_detected=true ãŒ 10% è¶…ãˆãŸã‚‰é€šçŸ¥
```

**ãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³ç’°å¢ƒã§ã®æ´»ç”¨ä¾‹:**
- **ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚¢ãƒ©ãƒ¼ãƒˆ**: å¹»è¦šæ¤œå‡ºç‡ãŒé–¾å€¤ã‚’è¶…ãˆãŸã‚‰Slacké€šçŸ¥
- **A/Bãƒ†ã‚¹ãƒˆ**: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒãƒ¼ã‚¸ãƒ§ãƒ³Aã¨Bã§è©•ä¾¡ã‚¹ã‚³ã‚¢ã‚’æ¯”è¼ƒ
- **å“è³ªãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰**: æ™‚ç³»åˆ—ã§ã®å¹»è¦šç‡ãƒ»ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ»ã‚³ã‚¹ãƒˆæ¨ç§»ã‚’å¯è¦–åŒ–

## ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ï¼šã‚ˆãã‚ã‚‹å•é¡Œã¨è§£æ±ºæ–¹æ³•

| å•é¡Œ | åŸå›  | è§£æ±ºæ–¹æ³• |
|------|------|----------|
| `ModuleNotFoundError: No module named 'weave'` | ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æœªå®Œäº† | `pip install weave openai` ã‚’å†å®Ÿè¡Œ |
| ãƒˆãƒ¬ãƒ¼ã‚¹ãŒè¨˜éŒ²ã•ã‚Œãªã„ | `weave.init()` ãŒå‘¼ã°ã‚Œã¦ã„ãªã„ | é–¢æ•°å®Ÿè¡Œå‰ã«å¿…ãš `weave.init("project-name")` ã‚’å®Ÿè¡Œ |
| ãƒˆãƒ¼ã‚¯ãƒ³æ•°ãŒ0ã¨è¡¨ç¤ºã•ã‚Œã‚‹ | éå¯¾å¿œã®LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ | OpenAI/Anthropicä»¥å¤–ã¯æ‰‹å‹•ã§ `usage` ã‚’è¨˜éŒ² |
| Weave UIãŒ404ã‚¨ãƒ©ãƒ¼ | ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåã®typo or æ¨©é™ä¸è¶³ | W&Bãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹ã§ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåã¨ã‚¢ã‚¯ã‚»ã‚¹æ¨©ã‚’ç¢ºèª |
| ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãŒç•°å¸¸ã«é«˜ã„ | Weaveè‡ªä½“ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ | ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ç‡ã‚’ä¸‹ã’ã‚‹ï¼ˆä¾‹: `tracing_sample_rate=0.1`ï¼‰ |
| è©•ä¾¡ã‚¹ã‚³ã‚¢ãŒä¸å®‰å®š | LLM-as-a-Judgeã®ãƒã‚¤ã‚¢ã‚¹ | è¤‡æ•°LLMã§ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«è©•ä¾¡ or ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã‚¹ã‚³ã‚¢ãƒ©ãƒ¼ã¨ä½µç”¨ |

## ã¾ã¨ã‚ã¨æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

**ã¾ã¨ã‚:**
- W&B Weaveã¯ `@weave.op()` ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ãƒ¼1è¡Œã§LLMã®å…¥å‡ºåŠ›ãƒ»ã‚³ã‚¹ãƒˆãƒ»ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã‚’è‡ªå‹•ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°
- ã‚«ã‚¹ã‚¿ãƒ ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°é–¢æ•°ã§ã€LLMå‡ºåŠ›ã®å“è³ªã‚’å®šé‡çš„ã«è©•ä¾¡å¯èƒ½
- Online Evalsã«ã‚ˆã‚Šã€æœ¬ç•ªç’°å¢ƒã§ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å“è³ªç›£è¦–ãŒå®Ÿç¾
- ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°è¨­å®šã§ã‚³ã‚¹ãƒˆã¨ãƒ‡ãƒ¼ã‚¿åé›†ã®ãƒãƒ©ãƒ³ã‚¹ã‚’æœ€é©åŒ–

**æ¬¡ã«ã‚„ã‚‹ã¹ãã“ã¨:**
- **ãƒãƒ³ã‚ºã‚ªãƒ³**: è‡ªåˆ†ã®LLMãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã« `@weave.op()` ã‚’è¿½åŠ ã—ã¦ãƒˆãƒ¬ãƒ¼ã‚¹ã‚’ç¢ºèª
- **è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ§‹ç¯‰**: ä»£è¡¨çš„ãªãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹10-20å€‹ã§è©•ä¾¡ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ä½œæˆ
- **æœ¬ç•ªãƒ‡ãƒ—ãƒ­ã‚¤**: ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ç‡ã‚’èª¿æ•´ã—ãªãŒã‚‰ã€ãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³ç’°å¢ƒã§ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°é–‹å§‹
- **Weaveå…¬å¼ã‚³ãƒ¼ã‚¹å—è¬›**: [W&B Weave course](https://wandb.ai/site/courses/weave/) ã§æ·±æ˜ã‚Šå­¦ç¿’

## å‚è€ƒ

- [W&B Weave Documentation - Quickstart](https://docs.wandb.ai/weave/quickstart)
- [LLM Observability Tools: Weights & Biases, Langsmith](https://research.aimultiple.com/llm-observability/)
- [Streamline generative AI workflows with W&B Traces](https://wandb.ai/site/traces/)
- [GitHub - wandb/weave: Weave is a toolkit for developing AI-powered applications](https://github.com/wandb/weave)
- [Evaluations overview - Weights & Biases Documentation](https://docs.wandb.ai/weave/guides/core-types/evaluations)
- [LLM observability: Monitoring AI in production - W&B](https://wandb.ai/site/articles/llm-observability-your-guide-to-monitoring-ai-in-production/)

è©³ç´°ãªãƒªã‚µãƒ¼ãƒå†…å®¹ã¯ [Issue #84](https://github.com/0h-n0/zen-auto-create-article/issues/84) ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚

---

:::message
ã“ã®è¨˜äº‹ã¯AIï¼ˆClaude Codeï¼‰ã«ã‚ˆã‚Šè‡ªå‹•ç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚å†…å®¹ã®æ­£ç¢ºæ€§ã«ã¤ã„ã¦ã¯è¤‡æ•°ã®æƒ…å ±æºã§æ¤œè¨¼ã—ã¦ã„ã¾ã™ãŒã€å®Ÿéš›ã®åˆ©ç”¨æ™‚ã¯å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚‚ã”ç¢ºèªãã ã•ã„ã€‚
:::
