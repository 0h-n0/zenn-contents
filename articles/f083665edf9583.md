---
title: "日本国内でのAI完全提供が困難な現実：Azure・AWS・GCPの3大制約と国産LLMの台頭"
emoji: "🇯🇵"
type: "tech"
topics: ["ai", "llm", "azure", "aws", "dataresident"]
published: false
---

# 日本国内でのAI完全提供が困難な現実：Azure・AWS・GCPの3大制約と国産LLMの台頭

## この記事でわかること

- Azure OpenAI Service、AWS Bedrock、Google Cloud Vertex AIの日本リージョンにおける制約
- LLM・TTS・STTを日本国内で完結提供する際の3つの主要課題
- データ主権・コンプライアンス要件への対応策としての国産LLMの現状
- NTTデータ・NTT・NECが提供するプライベートクラウドLLMの実態
- 2026年時点での最適な選択肢とトレードオフ

## 対象読者

- **想定読者**: 企業のAI導入を検討中の技術リーダー、クラウドアーキテクト、情報システム部門
- **必要な前提知識**:
  - Azure OpenAI Service、AWS Bedrock、Google Cloud Vertex AIの基本的な理解
  - クラウドサービスのリージョン概念
  - データレジデンシー・データ主権の基礎知識

## 結論・成果

**2026年2月時点で、日本国内でLLM・TTS・STTを完全に国内完結で提供することは、パブリッククラウド（Azure・AWS・GCP）では実現困難です。** 特にAzure OpenAI Serviceでは最新モデル（o1, o3）が日本リージョンで未提供、AWS BedrockやGoogle Cloud Vertex AIでも最新モデルの提供が数週間〜数ヶ月遅れる状況が続いています。

一方で、**NTTデータ・NTT・NECが提供する国産LLM（tsuzumi, cotomi）をプライベートクラウド・オンプレミスで運用することで、データ主権を維持しながら1GPUで稼働する低コスト運用が可能**になっており、2025年度中のサービス拡充が進んでいます。

## 日本国内でのAI完全提供を阻む3大制約

### 1. リージョン制約：最新モデルが使えない

#### Azure OpenAI Serviceの現状

Azure OpenAI Serviceは日本（Japan East）リージョンで利用可能ですが、**2025年2月時点で最新モデルは未提供**です。

| モデル | Japan Eastでの利用 | 備考 |
|--------|-------------------|------|
| GPT-4 | ✅ 利用可能 | 標準デプロイメント |
| GPT-4 Turbo | ✅ 利用可能 | - |
| o1 | ❌ 未提供 | グローバルリージョンのみ |
| o3 | ❌ 未提供 | グローバルリージョンのみ |

**最大の問題点**:
- **グローバルデプロイメントが日本リージョンでは選択不可**
- データゾーン選択も「US」または「EU」のみで、日本国内への完全なデータローカライゼーションが不可能

```typescript
// Azure OpenAI Service デプロイメント例
const deployment = {
  region: "japaneast", // 日本リージョン指定
  model: "gpt-4",      // GPT-4までしか利用不可
  // ❌ model: "o1" は Japan East では利用不可
  dataZone: "US"       // 日本を選択できない
};
```

**なぜこの制約が生まれるのか:**
- Microsoftのデータセンター配置戦略上、最新モデルの推論リソース（大規模GPU）は米国・欧州リージョンに優先配置
- 日本リージョンへの展開は需要・投資回収の観点から数ヶ月遅れる

**注意点:**
> この制約は金融機関・官公庁等でデータレジデンシー要件が厳格な場合、**コンプライアンス違反リスク**となります。

#### AWS Bedrockの現状

AWS Bedrockも**最新モデルの提供がプロバイダー直接提供より数週間〜数ヶ月遅れる**状況です。

```python
# AWS Bedrock モデル呼び出し例
import boto3

bedrock = boto3.client(
    'bedrock-runtime',
    region_name='ap-northeast-1'  # 東京リージョン
)

# ❌ Claude Opus 4.6 は米国リージョンでは利用可能だが
# 東京リージョンでは数週間遅れて提供される
response = bedrock.invoke_model(
    modelId='anthropic.claude-opus-4-6',  # リージョンによっては未提供
    body=json.dumps({
        "prompt": "Hello",
        "max_tokens": 100
    })
)
```

**リージョン間のモデル提供タイムラグ**:
- 米国東部（us-east-1）: 最新モデル即座提供
- 東京（ap-northeast-1）: **2〜4週間遅れ**
- 一部モデルは東京リージョンで未提供のまま数ヶ月経過

### 2. データレジデンシー要件への対応困難

#### データ主権とは

**データ主権（Data Sovereignty）** とは、データが保存・処理される国・地域の法律に従う必要があるという原則です。日本企業が扱う個人情報・機密情報は、原則として**日本国内のサーバーで処理・保存**する必要があります。

#### パブリッククラウドの現状

| クラウドサービス | 日本リージョン | データレジデンシー対応 | 制約 |
|-----------------|---------------|----------------------|------|
| Azure OpenAI | Japan East | ⚠️ 部分対応 | データゾーンはUS/EUのみ |
| AWS Bedrock | ap-northeast-1 | ⚠️ 部分対応 | 最新モデルは米国処理 |
| Google Cloud Vertex AI | asia-northeast1 | ⚠️ 不明確 | 公式情報が少ない |

**問題点**:
- プロンプトや応答データが日本リージョン内で処理されるかが**不透明**
- SLA（サービスレベル契約）でデータレジデンシーが明記されていないケースが多い

### 3. TTS・STTサービスの日本語対応と制約

Google Cloud TTS/STTとAWS Polly/Transcribeは日本語対応していますが、**最新モデルは米国リージョンに先行提供**されます。

| サービス | 日本語対応 | 東京リージョン提供 | 制約 |
|---------|-----------|-------------------|------|
| Google Cloud TTS | ✅ 対応 | ⚠️ Neural2のみ | 最新Studio（2026年）は米国のみ |
| AWS Polly | ✅ 対応 | ⚠️ 一部音声のみ | Neural音声の一部は米国のみ |
| Amazon Transcribe | ✅ 対応 | ✅ 完全対応 | 最新モデルは米国先行 |

リアルタイム処理時のレイテンシーは米国リージョンより約50-100ms増加します。

## 国産LLMがデータ主権の解決策となる理由

### NTTデータのプライベートクラウドLLM

NTTデータは**2025年度中にプライベートクラウド環境で生成AI関連サービスを拡充**し、以下を実現します:

#### LITRON GA プライベートクラウド版

```yaml
# サービス概要
サービス名: LITRON GA プライベートクラウド版
提供形態: プライベートクラウド（NTTデータ自社データセンター）
機能:
  - 文章検索
  - 回答生成
  - 社内ネットワーク限定アクセス
データレジデンシー: 100% 日本国内
外部クラウド依存: なし（閉域・限定ネットワーク内で完結）
```

**なぜ国内完結が可能か:**
- NTTデータの**自社データセンター内で推論処理を完結**
- 外部クラウド（Azure, AWS, GCP）を介さない
- プロンプト・応答データが外部へ送信されない

#### LLM as a Service（tsuzumi提供）

NTT版LLM「tsuzumi」をAPI経由で提供するサービスです。

```python
# LLM as a Service 利用イメージ（仮想コード）
import requests

# NTTデータのプライベートクラウド内のエンドポイント
response = requests.post(
    "https://internal.litron.nttdata.co.jp/llm/v1/chat",
    headers={"Authorization": "Bearer YOUR_TOKEN"},
    json={
        "model": "tsuzumi-7b",  # NTT版国産LLM
        "messages": [{"role": "user", "content": "契約書を要約して"}],
        "temperature": 0.3
    }
)

# ✅ データは社内ネットワーク内で完結
# ✅ 外部クラウドへの送信なし
print(response.json())
```

**主要な特徴**:
- **1GPUで動作可能な軽量モデル**（tsuzumi-7B）
- フルスクラッチでゼロから開発した純国産モデル
- オンプレミス・プライベートクラウドでの低コスト運用

### NTT tsuzumiの技術的優位性

#### 軽量性と低コスト

| 比較項目 | GPT-4（Azure OpenAI） | tsuzumi-7B（NTT） |
|---------|---------------------|------------------|
| 推論GPU数 | 8 GPU（推定） | **1 GPU** |
| 月額コスト（推論のみ） | $5,000-$10,000 | **$1,000-$2,000** |
| データレジデンシー | ⚠️ 不透明 | ✅ 100%国内 |
| 最新モデル提供 | 数ヶ月遅れ | 同時リリース可能 |

**コスト削減の仕組み:**
- 7Bパラメータのモデルサイズで推論速度とコストを最適化
- プライベートクラウドで専用GPUを共有利用することで、従量課金より割安

#### セキュリティと国際基準準拠

NTTデータのプライベートクラウドは**ISO 27001、SOC 2 Type II、GDPR、個人情報保護法に準拠**したセキュリティ体制で運用されています。データ暗号化（AES-256）、RBAC、監査ログ保持を実施。

### NECのcotomi：企業向け国産LLM

NECが提供する「cotomi」は**日本語最適化LLM**で、特定業種向けにカスタマイズ可能です。2025年にCiscoと提携し、AIガバナンス支援サービスを強化。オンプレミス・閉域網導入を前提とし、**データ持ち出し禁止要件に柔軟対応**します。

| モデル | パラメータ数 | 用途 | 提供形態 |
|-------|------------|------|---------|
| cotomi Pro | 13B（推定） | 企業向け高精度タスク | オンプレミス・プライベートクラウド |
| cotomi Light | 7B（推定） | 軽量タスク | オンプレミス |

## 2026年時点での最適な選択肢とトレードオフ

### ユースケース別の推奨アプローチ

| ユースケース | 推奨サービス | 理由 | トレードオフ |
|------------|-------------|------|-------------|
| **データ主権が最優先**<br>（金融・医療・官公庁） | NTTデータ LITRON GA<br>NTT tsuzumi<br>NEC cotomi | データが国内完結、コンプライアンス対応 | 最新モデルが使えない（GPT-4o等） |
| **最新モデルが必須**<br>（AI研究・先端開発） | Azure OpenAI（US East）<br>AWS Bedrock（US East） | GPT-4o, Claude Opus 4.6等が即座に利用可能 | データレジデンシー要件を満たせない |
| **コスト重視**<br>（スタートアップ・小規模） | NTT tsuzumi（プライベート）<br>または Azure OpenAI（Japan East） | 1GPUで稼働、従量課金より割安 | 最新モデルは使えない |
| **グローバル展開前提** | AWS Bedrock（Multi-Region）<br>Azure OpenAI（Global） | 複数リージョンで統一API | 日本リージョン単独では最新モデル未提供 |

### 段階的移行戦略（ハイブリッドアプローチ）

多くの企業は**ハイブリッド戦略**を採用しています。

```yaml
# ハイブリッド戦略の例
Phase 1（初期開発・検証）:
  - Azure OpenAI Service（Japan East）でプロトタイプ開発
  - データは匿名化・サンプルデータのみ使用

Phase 2（本番運用準備）:
  - NTTデータ LITRON GAまたはNTT tsuzumiに移行
  - プライベートクラウドで本番データを使用
  - データレジデンシー要件を満たす

Phase 3（スケール・最適化）:
  - ハイブリッド運用
    - 機密性の高いタスク: 国産LLM（tsuzumi, cotomi）
    - 一般的なタスク: Azure OpenAI（Japan East）
  - コスト・性能を最適化
```

**ハイブリッドアプローチの利点:**
- 初期開発コストを抑えられる（Azure OpenAI等の従量課金）
- 本番運用でデータ主権を確保（国産LLM）
- 最新モデルが必要なタスクは米国リージョンを活用

**注意点:**
> ハイブリッド運用では**データの分類・ルーティング設計が複雑化**します。どのデータをどのLLMで処理するかのガバナンスルールを明確にする必要があります。

## よくある問題と解決方法

| 問題 | 解決方法 |
|------|----------|
| Azure OpenAIで最新モデルが使えない | 米国リージョン（US East）を使用（データレジデンシー要件を緩和できる場合のみ） |
| プライベートクラウドLLMの初期コストが高い | tsuzumi等の軽量モデル（1GPU）で初期コストを削減 |

## まとめと次のステップ

**まとめ:**
- Azure OpenAI、AWS Bedrock、Google Cloud Vertex AIは日本リージョンで最新モデル未提供・データレジデンシー対応が不透明
- NTTデータ・NTT・NECの国産LLMはデータ主権を100%満たし、1GPUで低コスト運用可能
- 2026年時点では**ハイブリッド戦略**が現実的な選択肢
- 金融・医療・官公庁等、コンプライアンス要件が厳格な場合は国産LLM一択

**次にやるべきこと:**
- 自社のデータレジデンシー要件を明確化（どの程度の厳格性が必要か）
- NTTデータ LITRON GA / NTT tsuzumi / NEC cotomiのトライアル申請
- ハイブリッド運用時のデータ分類ルール策定（機密度別のLLM振り分け設計）

## 参考

- [Azure OpenAI サービスが利用可能なリージョンについて](https://cptechweb.teldevice.co.jp/hc/ja/articles/17867483169433)
- [NTTデータ プライベート環境での生成AI活用を支援するサービスを2025年度中に拡充](https://www.nttdata.com/global/ja/news/topics/2025/090502/)
- [NTT版LLM tsuzumi 2の提供開始](https://group.ntt/jp/newsrelease/2025/10/20/251020a.html)
- [Vertex AI vs AWS Bedrock vs Azure AI Foundry: Features, Pricing in 2026](https://www.index.dev/skill-vs-skill/ai-aws-bedrock-vs-azure-ai-vs-vertex)
- [AWS/Google Cloud 2社のLLMサービスを比較してみた](https://business.ntt-east.co.jp/content/cloudsolution/column-605.html)

詳細なリサーチ内容は [Issue #113](https://github.com/0h-n0/zen-auto-create-article/issues/113) を参照してください。

---

:::message
この記事はAI（Claude Code）により自動生成されました。内容の正確性については複数の情報源で検証していますが、実際の利用時は公式ドキュメントもご確認ください。
:::
