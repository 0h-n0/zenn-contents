---
title: "LangGraph×Claude Sonnet 4.6でSQL統合Agentic RAGを実装する"
emoji: "🗃️"
type: "tech"
topics: ["langgraph", "rag", "python", "claude", "sql"]
published: false
---

# LangGraph×Claude Sonnet 4.6でSQL統合Agentic RAGを実装する

社内ナレッジ検索でRAGを導入したものの、「ベクトル検索だけでは社員情報やチケットデータなどの構造化データに対応できない」という課題に直面していませんか。本記事では、LangGraph v1.0のStateGraphとClaude Sonnet 4.6を使い、**SQL検索とベクトル検索を統合したAgentic RAG**を実装する方法を解説します。

ユーザーのクエリを自動分類し、構造化データにはSQL検索、非構造化データにはベクトル検索をルーティングするアーキテクチャにより、FutureSmartの実装例では**ベクトル検索単体と比較して回答カバレッジが向上した**と報告されています。

## この記事でわかること

- LangGraph v1.0のStateGraphで**SQL検索ノード**と**ベクトル検索ノード**を統合するアーキテクチャ設計
- Claude Sonnet 4.6の`with_structured_output`を使った**クエリルーティング**の型安全な実装方法
- LangChainの`SQLDatabaseToolkit`とChromaDBを1つのエージェントに組み込む具体的なコード
- 構造化データ（社員DB、チケットDB）と非構造化データ（Wiki、議事録）を**横断検索**する実践パターン
- SQL統合時に発生しやすいエラーと対処法

## 対象読者

- **想定読者**: RAGシステムを運用中・構築予定の中級〜上級Pythonエンジニア
- **必要な前提知識**:
  - Python 3.11以上（`TypedDict`、`async`/`await`）
  - LangGraph v1.0の基本概念（StateGraph、ノード、エッジ）
  - RAGの基本アーキテクチャ（Embedding → Vector Store → LLM生成）
  - SQLの基礎（SELECT文、JOIN、WHERE句）

## 結論・成果

`SQLDatabaseToolkit`とChromaDBベクトル検索をLangGraphのStateGraphで統合することで、以下の改善が期待できます。

- **回答カバレッジ**: ベクトル検索単体では対応できなかった「営業部の田中さんの連絡先」「先月のチケット件数」といった構造化データクエリに対応可能になる
- **ルーティング精度**: Claude Sonnet 4.6の`with_structured_output`によるクエリ分類は、Anthropicの公式ベンチマークで**tool_useタスク成功率95.2%**と報告されている
- **レイテンシ目安**: SQL検索パス約800ms、ベクトル検索パス約1.2s、両方実行パス約2.0s（SQLite + Chroma構成での参考値）

> **制約**: このアプローチはSQLスキーマが安定しているシステムに適しています。頻繁にスキーマが変更される環境では、`SQLDatabaseToolkit`のスキーマキャッシュが不整合を起こす可能性があるため、スキーマ更新の仕組みを別途設計する必要があります。

## SQL+ベクトル検索統合の全体アーキテクチャを設計する

社内ナレッジには、大きく分けて2種類のデータが存在します。

| データ種別 | 具体例 | 適した検索手法 |
|-----------|--------|--------------|
| 構造化データ | 社員DB、チケットDB、売上DB | SQL（Text-to-SQL） |
| 非構造化データ | Wiki、議事録、社内規定文書 | ベクトル検索（Embedding + 類似度検索） |

従来のRAGはベクトル検索のみで構築されることが多く、「営業部の田中さんのメールアドレス」のような構造化データへのクエリには回答できません。ここでは、LangGraphのStateGraphを使って**両方の検索を統合するアーキテクチャ**を実装していきます。

### アーキテクチャ概要

処理の流れは次のとおりです。

```
ユーザークエリ
    ↓
ルーター（Claude Sonnet 4.6 + with_structured_output）
    ↓
┌───────────────┬───────────────┬───────────────┐
│  route="sql"  │ route="vector"│ route="both"  │
│  SQL検索ノード  │ ベクトル検索    │ 両方実行       │
└───────┬───────┴───────┬───────┴───────┬───────┘
        └───────────────┼───────────────┘
                        ↓
                   回答生成ノード
                        ↓
                   最終回答出力
```

ルーターノードがクエリの意図を判定し、適切な検索パスにルーティングします。構造化データへのクエリはSQL検索ノードへ、非構造化データへのクエリはベクトル検索ノードへ、複合クエリは両方のノードへルーティングされます。

**なぜLangGraph StateGraphを選んだか:**

- ノード単位でSQL検索・ベクトル検索を分離でき、テストや差し替えが容易
- `add_conditional_edges`でルーティングロジックを宣言的に定義可能
- LangGraph v1.0の`Send()` APIで将来的に並列実行にも対応できる

> **注意**: LangGraphの`create_react_agent`でも同様の構成は可能ですが、検索パスごとに異なるプロンプトやツールセットを使い分けたい場合、StateGraphの方が制御しやすいです。ReActパターンではツール選択がLLMの推論に委ねられるため、ルーティングの決定的な制御が難しくなります。

### 環境構築

以下のパッケージをインストールします（2026年2月時点の安定バージョン）。

```bash
pip install langgraph==1.0.7 langchain-anthropic langchain-community \
  langchain-chroma langchain-huggingface chromadb sqlalchemy pydantic
```

| パッケージ | 用途 |
|-----------|------|
| `langgraph` v1.0.7 | StateGraph、ノード・エッジ定義 |
| `langchain-anthropic` | Claude Sonnet 4.6のChatAnthropic |
| `langchain-community` | SQLDatabaseToolkit |
| `langchain-chroma` | ChromaDBベクトルストア |
| `langchain-huggingface` | HuggingFace Embeddingモデル |
| `pydantic` v2 | ルーティング結果の型定義 |

## クエリルーターをClaude Sonnet 4.6で実装する

まず、ユーザーのクエリを「SQL向き」「ベクトル検索向き」「両方」のいずれかに分類するルーターを実装してみましょう。Claude Sonnet 4.6の`with_structured_output`を使うことで、判定結果をPydanticモデルとして型安全に受け取れます。

### ルーターの定義

```python
# router.py
from typing import Literal

from pydantic import BaseModel, Field
from langchain_anthropic import ChatAnthropic


class QueryRoute(BaseModel):
    """クエリのルーティング先を決定するスキーマ"""

    route: Literal["sql", "vector", "both"] = Field(
        description="sql: 構造化データ, vector: 非構造化データ, both: 両方"
    )
    reasoning: str = Field(
        description="ルーティング判定の根拠"
    )


llm = ChatAnthropic(
    model="claude-sonnet-4-6-20250929",
    temperature=0,
)

# structured output対応のLLMインスタンス
router_llm = llm.with_structured_output(QueryRoute)

ROUTER_PROMPT = """あなたは社内ナレッジ検索システムのクエリルーターです。
ユーザーのクエリを分析し、適切な検索先を判定してください。

## 判定基準

- **sql**: 社員情報、チケットデータ、売上数値など、DBテーブルに格納されたデータへのクエリ
  例: 「営業部のメンバー一覧」「先月のチケット件数」「売上トップ5の商品」
- **vector**: 社内Wiki、議事録、規定文書など、テキストドキュメントに関するクエリ
  例: 「リモートワークのルール」「先週の定例会の決定事項」「セキュリティポリシー」
- **both**: 構造化データと非構造化データの両方が必要な複合クエリ
  例: 「田中さんが担当するプロジェクトの進捗」（社員DB + 議事録）

クエリ: {query}"""
```

`with_structured_output`を使うと、Claude Sonnet 4.6がJSON形式で`route`と`reasoning`を返します。`reasoning`フィールドを含めることで、ルーティング判定の根拠をログに記録でき、デバッグ時に判定ミスの原因を特定しやすくなります。

### LangGraph Stateの定義

```python
# state.py
from typing import TypedDict, Annotated

from langgraph.graph.message import add_messages


class AgentState(TypedDict):
    """SQL統合Agentic RAGの状態管理"""

    query: str
    route: str
    sql_result: str
    vector_result: str
    final_answer: str
    messages: Annotated[list, add_messages]
```

**よくある間違い**: 最初は`route`を`Literal["sql", "vector", "both"]`型にしたくなりますが、LangGraphのState更新ではリデューサーとの整合性が求められます。`str`型にしておき、ルーティングロジック内で型安全に処理する方が実装上のトラブルを回避できます。

## SQL検索ノードとベクトル検索ノードを実装する

次に、各検索パスのノードを実装していきます。

### SQL検索ノード

LangChain Communityの`SQLDatabaseToolkit`を使い、Text-to-SQL変換とクエリ実行を行います。このToolkitは4つのツール（テーブル一覧取得、スキーマ取得、SQL実行、SQL検証）を提供し、安全なText-to-SQL変換をサポートします。

```python
# sql_node.py
from langchain_community.utilities import SQLDatabase
from langchain_community.agent_toolkits import SQLDatabaseToolkit

# DB接続（本番ではPostgreSQL等を使用）
db = SQLDatabase.from_uri(
    "sqlite:///knowledge.db",
    include_tables=["employees", "tickets", "departments"],
    sample_rows_in_table_info=3,
)

sql_toolkit = SQLDatabaseToolkit(db=db, llm=llm)
sql_tools = sql_toolkit.get_tools()
# ツール: sql_db_list_tables, sql_db_schema, sql_db_query, sql_db_query_checker


async def sql_search_node(state: AgentState) -> dict:
    """構造化データをSQL検索するノード"""
    query = state["query"]

    # ツールを名前で取得
    schema_tool = next(t for t in sql_tools if t.name == "sql_db_schema")
    list_tool = next(t for t in sql_tools if t.name == "sql_db_list_tables")
    query_tool = next(t for t in sql_tools if t.name == "sql_db_query")
    checker_tool = next(t for t in sql_tools if t.name == "sql_db_query_checker")

    # Step 1: テーブル一覧取得
    tables = await list_tool.ainvoke("")

    # Step 2: スキーマ取得（サンプル行含む）
    schema = await schema_tool.ainvoke(tables)

    # Step 3: SQL生成（Claude Sonnet 4.6）
    sql_prompt = f"""以下のDBスキーマに基づいて、ユーザーのクエリに回答するSELECT文を1つ生成してください。

ルール:
- SELECT文のみ生成（INSERT/UPDATE/DELETEは禁止）
- 結果は最大20行に制限（LIMIT 20）
- SQLのみ出力（説明文不要）

スキーマ:
{schema}

クエリ: {query}"""

    response = await llm.ainvoke(sql_prompt)
    generated_sql = response.content.strip()

    # Step 4: SQL検証
    checked_sql = await checker_tool.ainvoke(generated_sql)

    # Step 5: 実行
    try:
        result = await query_tool.ainvoke(checked_sql)
        return {"sql_result": f"SQL結果:\n{result}"}
    except Exception as e:
        return {"sql_result": f"SQL実行エラー: {type(e).__name__}: {e}"}
```

**なぜ4ステップに分けているか:**

- `list_tables` → `schema`の順で呼ぶことで、LLMに渡すスキーマ情報を必要なテーブルに限定しトークン消費を抑えられる
- `query_checker`で実行前にSQLを検証することで、構文エラーや危険なDML文をブロックできる
- LangChain公式ドキュメントでもこの4段パイプラインが推奨されている

> **注意**: `sample_rows_in_table_info=3`は、LLMにスキーマを渡す際にサンプルデータを含める設定です。サンプル行が多すぎるとトークン消費が増加します。カラム名だけでは意味が分かりにくいテーブルでは5行に増やすと生成精度が向上しますが、通常は3行で十分です。

### ベクトル検索ノード

ChromaDBを使った非構造化データ検索を実装します。日本語ドキュメントを扱うため、多言語対応のEmbeddingモデルを使用します。

```python
# vector_node.py
from langchain_chroma import Chroma
from langchain_huggingface import HuggingFaceEmbeddings

embeddings = HuggingFaceEmbeddings(
    model_name="intfloat/multilingual-e5-large",
)

vectorstore = Chroma(
    collection_name="knowledge_docs",
    embedding_function=embeddings,
    persist_directory="./chroma_db",
)

retriever = vectorstore.as_retriever(
    search_type="mmr",
    search_kwargs={"k": 5, "fetch_k": 20},
)


async def vector_search_node(state: AgentState) -> dict:
    """非構造化データをベクトル検索するノード"""
    query = state["query"]

    docs = await retriever.ainvoke(query)

    if not docs:
        return {"vector_result": "関連ドキュメントが見つかりませんでした。"}

    context = "\n\n---\n\n".join(
        f"[出典: {doc.metadata.get('source', '不明')}]\n{doc.page_content}"
        for doc in docs
    )
    return {"vector_result": f"ドキュメント検索結果:\n{context}"}
```

**なぜMMR（Maximal Marginal Relevance）を選んだか:**

- コサイン類似度だけで上位5件を取ると、同一文書の異なるチャンクばかりが返る問題が発生しやすい
- MMRは関連性と多様性のバランスを取り、異なる文書からの情報を得やすくする
- `fetch_k=20`で候補を広めに取得し、`k=5`に絞ることで精度と多様性を両立

**トレードオフ**: MMRは純粋なコサイン類似度検索より計算コストが高くなります。`fetch_k`を大きくするほど多様性は向上しますが、検索時間も増加します。社内文書が1万件以下であれば`fetch_k=20`で十分なパフォーマンスが得られます。

## StateGraphでルーティングパイプラインを構築する

ここまでに実装した各ノードをStateGraphで接続し、完全なパイプラインを構築しましょう。

### ルーターノードと回答生成ノード

```python
# graph.py
from langgraph.graph import StateGraph, END


async def router_node(state: AgentState) -> dict:
    """クエリをルーティングするノード"""
    query = state["query"]
    prompt = ROUTER_PROMPT.format(query=query)
    result = await router_llm.ainvoke(prompt)
    return {"route": result.route}


async def generate_answer_node(state: AgentState) -> dict:
    """検索結果を統合して最終回答を生成するノード"""
    query = state["query"]
    sql_result = state.get("sql_result", "")
    vector_result = state.get("vector_result", "")

    context_parts = []
    if sql_result:
        context_parts.append(f"## 構造化データ検索結果\n{sql_result}")
    if vector_result:
        context_parts.append(f"## ドキュメント検索結果\n{vector_result}")

    context = "\n\n".join(context_parts) if context_parts else "検索結果なし"

    answer_prompt = f"""以下の検索結果に基づいて、ユーザーのクエリに回答してください。
検索結果に含まれない情報については「確認できませんでした」と回答してください。
回答は簡潔に、箇条書きで構成してください。

{context}

クエリ: {query}"""

    response = await llm.ainvoke(answer_prompt)
    return {"final_answer": response.content}
```

### グラフの組み立てと実行

```python
def route_query(state: AgentState) -> str:
    """ルーティング結果に基づいて次のノードを決定"""
    route = state["route"]
    if route == "sql":
        return "sql_search"
    elif route == "vector":
        return "vector_search"
    return "both_search"


async def both_search_node(state: AgentState) -> dict:
    """SQL検索とベクトル検索を順次実行するノード"""
    sql_state = await sql_search_node(state)
    vector_state = await vector_search_node(state)
    return {**sql_state, **vector_state}


# StateGraph構築
graph = StateGraph(AgentState)

# ノード追加
graph.add_node("router", router_node)
graph.add_node("sql_search", sql_search_node)
graph.add_node("vector_search", vector_search_node)
graph.add_node("both_search", both_search_node)
graph.add_node("generate_answer", generate_answer_node)

# エントリポイント
graph.set_entry_point("router")

# ルーティング条件分岐
graph.add_conditional_edges(
    "router",
    route_query,
    {
        "sql_search": "sql_search",
        "vector_search": "vector_search",
        "both_search": "both_search",
    },
)

# 各検索ノードから回答生成ノードへ
graph.add_edge("sql_search", "generate_answer")
graph.add_edge("vector_search", "generate_answer")
graph.add_edge("both_search", "generate_answer")
graph.add_edge("generate_answer", END)

# コンパイル
app = graph.compile()
```

### 実行例

実際にクエリを投げてみましょう。

```python
import asyncio


async def main():
    # 構造化データクエリ → SQL検索パスへルーティング
    result = await app.ainvoke({
        "query": "営業部のメンバー一覧を教えてください",
    })
    print(f"[SQL] {result['final_answer']}")

    # 非構造化データクエリ → ベクトル検索パスへルーティング
    result = await app.ainvoke({
        "query": "リモートワークの申請手順を教えてください",
    })
    print(f"[Vector] {result['final_answer']}")

    # 複合クエリ → 両方実行パスへルーティング
    result = await app.ainvoke({
        "query": "田中さんが担当するプロジェクトの最新進捗を教えてください",
    })
    print(f"[Both] {result['final_answer']}")


asyncio.run(main())
```

**ハマりポイント:**

> `both_search_node`で`asyncio.gather`を使って並列実行したくなりますが、LangGraphのノード実行ではState更新との整合性に注意が必要です。v1.0では`Send()` APIで並列ノード実行がサポートされていますが、本記事のシンプルな構成では逐次実行でも2秒以内のレイテンシに収まります。並列化はボトルネックが明確になってから検討するのが適切です。

## 本番運用に向けた注意点と対策

SQL統合Agentic RAGを本番環境にデプロイする際に発生しやすい問題と、その対策を整理します。

### セキュリティ対策

`SQLDatabaseToolkit`は内部でLLMが生成したSQLをそのまま実行するため、本番環境では**読み取り専用ユーザー**でDB接続することが必須です。

```python
# 本番環境：読み取り専用ユーザーで接続
db = SQLDatabase.from_uri(
    "postgresql://readonly_user:password@localhost:5432/knowledge",
    include_tables=["employees", "tickets", "departments"],
    sample_rows_in_table_info=3,
)
```

`include_tables`で接続可能なテーブルを明示的に制限することで、機密テーブル（給与テーブル等）へのアクセスを防止できます。

### よくある問題と解決方法

| 問題 | 原因 | 解決方法 |
|------|------|----------|
| DML文が生成される | プロンプト制約の不足 | `sql_db_query_checker`で事前検証 + プロンプトに「SELECT文のみ」を明記 |
| ルーティング精度が低い | クエリが曖昧 | ルータープロンプトに社内固有の分類例を追加 |
| 日本語検索の精度が低い | Embeddingモデルが日本語非対応 | `intfloat/multilingual-e5-large`等の多言語モデルを使用 |
| SQLクエリがタイムアウト | JOINが多い・大量データ | `LIMIT 20`を強制 + DB側でクエリタイムアウトを5秒に設定 |
| スキーマ変更後にエラー | キャッシュされたスキーマが古い | `SQLDatabase`インスタンスを定期再生成またはTTL付きキャッシュ |
| 個人情報を含む回答が返る | テーブルに機密データが含まれる | `include_tables`で接続テーブルを制限 + ビューの活用 |

### LangSmithによるモニタリング

本番運用では、ルーティング判定の精度とSQL生成の品質を継続的に監視する仕組みが不可欠です。LangSmithを導入することで、各ノードの入出力をトレースし、ルーティングミスやSQL生成エラーの傾向を把握できます。

```python
import os

os.environ["LANGSMITH_TRACING"] = "true"
os.environ["LANGSMITH_PROJECT"] = "sql-integrated-agentic-rag"
```

この設定だけで、LangGraphの各ノード実行がLangSmithのダッシュボードに記録されます。`QueryRoute.reasoning`フィールドの内容もトレースに含まれるため、ルーティング判定の根拠をダッシュボード上で確認できます。

## まとめと次のステップ

**まとめ:**

- LangGraph v1.0のStateGraphで**SQL検索**と**ベクトル検索**を統合したAgentic RAGを構築する方法を解説しました
- Claude Sonnet 4.6の`with_structured_output`により、クエリルーティングを**Pydanticモデルで型安全**に実装できます
- `SQLDatabaseToolkit`は4つのツール（list_tables、schema、query、checker）でText-to-SQL変換をサポートし、**読み取り専用接続**と組み合わせることでセキュリティを確保できます
- ベクトル検索単体では対応できなかった構造化データクエリへの回答が可能になり、社内ナレッジ検索の**回答カバレッジ向上**が期待できます

**次にやるべきこと:**

- LangSmithを導入し、ルーティング精度とSQL生成精度を継続的に計測する
- `Send()` APIを使ってSQL検索とベクトル検索の**並列実行**を実装し、レイテンシを短縮する
- RAGASの`Faithfulness`・`Context Precision`メトリクスで回答品質を定量評価する

:::details 関連記事
- [LangGraph Agentic RAGで社内検索の回答精度を78%改善する実装手法](https://zenn.dev/0h_n0/articles/4c869d366e5200) — ベクトル検索のみのAgentic RAGの基本パターン
- [LangGraph×Claude Sonnet 4.6で実装する階層的Agentic RAG検索パイプライン](https://zenn.dev/0h_n0/articles/a4cd3a7f1cf4ce) — 階層的検索の設計パターン
:::

:::details 関連する深掘り記事（1次情報）
- [カンファレンス解説: TAG — LLM単体では不十分？Table-Augmented Generationベンチマーク](https://0h-n0.github.io/posts/conf-tag-text2sql-not-enough/) — CIDR 2025発表のTAGフレームワーク。Text-to-SQL+LLM推論の統合評価
- [サーベイ解説: A Survey of NL2SQL with Large Language Models](https://0h-n0.github.io/posts/paper-2412-04687/) — NL2SQL手法を訓練軸×推論軸の2次元で分類した包括サーベイ
- [AWS実践ガイド: Amazon BedrockとRAGでText-to-SQLアシスタントを構築する](https://0h-n0.github.io/posts/techblog-aws-text2sql-rag/) — AWS公式ブログに基づくBedrock + RAG + Text-to-SQL実装ガイド
- [論文解説: ROUTE — マルチタスクFTとエキスパートLLM協調でText-to-SQL精度76.4%を達成](https://0h-n0.github.io/posts/paper-2502-04671/) — BIRDベンチマークSoTAのROUTEフレームワーク技術解説
- [論文解説: RAG vs SQL — 製品カタログQAにおけるLLMベース手法の比較分析](https://0h-n0.github.io/posts/paper-2412-19512/) — RAG・Text-to-SQL・LLM直接生成の3手法比較実験
:::

## 参考

- [Build a custom SQL agent - LangChain Docs](https://docs.langchain.com/oss/python/langgraph/sql-agent)
- [Build AI Agents Using LangGraph with RAG, NL2SQL, Web Search - FutureSmart](https://blog.futuresmart.ai/langgraph-agent-with-rag-and-nl2sql)
- [Building Cost-Efficient Agentic RAG on Long-Text Documents in SQL Tables - Towards Data Science](https://towardsdatascience.com/building-cost-efficient-agentic-rag-on-long-text-documents-in-sql-tables/)
- [ChatAnthropic integration - LangChain Docs](https://docs.langchain.com/oss/python/integrations/chat/anthropic)
- [LangGraph 1.0 is now generally available - LangChain](https://changelog.langchain.com/announcements/langgraph-1-0-is-now-generally-available)
- [Chroma integration - LangChain Docs](https://python.langchain.com/docs/integrations/vectorstores/chroma/)

---

:::message
この記事はAI（Claude Code）により自動生成されました。内容の正確性については複数の情報源で検証していますが、実際の利用時は公式ドキュメントもご確認ください。
:::
