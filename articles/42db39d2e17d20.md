---
title: "Self-Evolving Agentså®Œå…¨ã‚¬ã‚¤ãƒ‰ï¼šAIãŒè‡ªå¾‹çš„ã«é€²åŒ–ã™ã‚‹3ã¤ã®ãƒ¡ã‚«ãƒ‹ã‚ºãƒ "
emoji: "ğŸ§¬"
type: "tech"
topics: ["ai", "agent", "selfevolving", "llm", "research"]
published: false
---

# Self-Evolving Agentså®Œå…¨ã‚¬ã‚¤ãƒ‰ï¼šAIãŒè‡ªå¾‹çš„ã«é€²åŒ–ã™ã‚‹3ã¤ã®ãƒ¡ã‚«ãƒ‹ã‚ºãƒ 

## ã“ã®è¨˜äº‹ã§ã‚ã‹ã‚‹ã“ã¨

- Self-Evolving Agentsï¼ˆè‡ªå·±é€²åŒ–ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼‰ã®å®šç¾©ã¨å¾“æ¥ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨ã®é•ã„
- 3ã¤ã®é€²åŒ–è»¸ï¼ˆAgent Evolutionãƒ»Tool Evolutionãƒ»Experience Evolutionï¼‰ã®å®Ÿè£…ãƒ¡ã‚«ãƒ‹ã‚ºãƒ 
- 2026å¹´æ™‚ç‚¹ã®æœ€æ–°ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ï¼ˆEvoAgentXãƒ»ADASãƒ»AFlowï¼‰ã®å®Ÿè£…ä¾‹ã¨ä½¿ã„åˆ†ã‘
- ICLR 2025ãƒ»EMNLP 2025æ¡æŠè«–æ–‡ã«åŸºã¥ãæœ€å…ˆç«¯æ‰‹æ³•ï¼ˆSPIRALãƒ»ToRAãƒ»ToolEVOï¼‰
- ã‚µã‚¤ãƒãƒ¼ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ»R&Dè‡ªå‹•åŒ–ã§ã®å®Ÿå¿œç”¨äº‹ä¾‹ã¨å°å…¥åŠ¹æœ

## å¯¾è±¡èª­è€…

- **æƒ³å®šèª­è€…**: ä¸­ç´šè€…ä»¥ä¸Šã®AIã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒ»æ©Ÿæ¢°å­¦ç¿’ç ”ç©¶è€…
- **å¿…è¦ãªå‰æçŸ¥è­˜**:
  - LLMã®åŸºç¤ï¼ˆGPT-4oã€Claude 3.5 Sonnetç­‰ã®ä½¿ç”¨çµŒé¨“ï¼‰
  - AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®åŸºæœ¬æ¦‚å¿µï¼ˆLangChainã€LangGraphç­‰ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ä½¿ç”¨çµŒé¨“ï¼‰
  - Pythonãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ï¼ˆPython 3.10ä»¥ä¸Šï¼‰
  - å¼·åŒ–å­¦ç¿’ã®åŸºç¤çŸ¥è­˜ï¼ˆä»»æ„ã ãŒæœ›ã¾ã—ã„ï¼‰

## çµè«–ãƒ»æˆæœ

Self-Evolving Agentsã¯ã€ç’°å¢ƒãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã«åŸºã¥ã„ã¦AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒè‡ªå¾‹çš„ã«è‡ªèº«ã‚’æ”¹å–„ã™ã‚‹æ–°ã—ã„ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã§ã™ã€‚å¾“æ¥ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒæ‰‹å‹•ã§è¨­è¨ˆã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚„å›ºå®šãƒ„ãƒ¼ãƒ«ã«ä¾å­˜ã—ã¦ã„ãŸã®ã«å¯¾ã—ã€**è‡ªå·±é€²åŒ–ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯æœ€å¤§82%ã®ç²¾åº¦å‘ä¸Šã€50%ã®ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œæ™‚é–“çŸ­ç¸®ã€30%ã®æ¨è«–ã‚³ã‚¹ãƒˆå‰Šæ¸›**ã‚’å®Ÿç¾ã—ã¦ã„ã¾ã™ï¼ˆarXiv 2508.07407ï¼‰ã€‚æœ¬è¨˜äº‹ã§ã¯ã€2026å¹´æ™‚ç‚¹ã®æœ€æ–°ç ”ç©¶ã¨ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ç¶²ç¾…çš„ã«è§£èª¬ã—ã¾ã™ã€‚

## Self-Evolving Agentsã¨ã¯

### å®šç¾©ã¨å¾“æ¥ã¨ã®é•ã„

Self-Evolving Agentsï¼ˆè‡ªå·±é€²åŒ–ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼‰ã¯ã€**ç’°å¢ƒã¨ã®ç›¸äº’ä½œç”¨ã‹ã‚‰å¾—ã‚‰ã‚ŒãŸãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ç”¨ã„ã¦ã€è‡ªå¾‹çš„ã«è‡ªèº«ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’æœ€é©åŒ–ã™ã‚‹AIã‚·ã‚¹ãƒ†ãƒ **ã§ã™ã€‚å¾“æ¥ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨ã®ä¸»ãªé•ã„ã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™ã€‚

| é …ç›® | å¾“æ¥ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ | Self-Evolving Agents |
|------|-------------------|----------------------|
| **è¨­è¨ˆæ–¹æ³•** | æ‰‹å‹•ã§ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ»ãƒ„ãƒ¼ãƒ«ã‚’è¨­å®š | è‡ªå‹•ã§æœ€é©åŒ– |
| **é©å¿œæ€§** | å›ºå®šçš„ï¼ˆç’°å¢ƒå¤‰åŒ–ã«å¯¾å¿œã§ããªã„ï¼‰ | å‹•çš„ï¼ˆç’°å¢ƒå¤‰åŒ–ã«è‡ªå‹•é©å¿œï¼‰ |
| **æ”¹å–„ã‚µã‚¤ã‚¯ãƒ«** | äººé–“ãŒä»‹å…¥ã—ã¦æ”¹å–„ | ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ«ãƒ¼ãƒ—ã§è‡ªå‹•æ”¹å–„ |
| **ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£** | æ–°è¦ã‚¿ã‚¹ã‚¯ã”ã¨ã«å†è¨­è¨ˆå¿…è¦ | å­¦ç¿’æ¸ˆã¿ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’è»¢ç§»å¯èƒ½ |

### 4ã¤ã®ã‚³ã‚¢ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ

Self-Evolving Agentsã¯ä»¥ä¸‹ã®4ã¤ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‹ã‚‰æ§‹æˆã•ã‚Œã¾ã™ï¼ˆ[A Comprehensive Survey of Self-Evolving AI Agents](https://arxiv.org/abs/2508.07407)ï¼‰ï¼š

1. **System Inputï¼ˆå…¥åŠ›ï¼‰**: ã‚¿ã‚¹ã‚¯å®šç¾©ã€åˆæœŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã€ãƒ„ãƒ¼ãƒ«ã‚»ãƒƒãƒˆ
2. **Agent Systemï¼ˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ ï¼‰**: LLMãƒ™ãƒ¼ã‚¹ã®æ¨è«–ã‚¨ãƒ³ã‚¸ãƒ³
3. **Environmentï¼ˆç’°å¢ƒï¼‰**: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒç›¸äº’ä½œç”¨ã™ã‚‹å¤–éƒ¨ã‚·ã‚¹ãƒ†ãƒ ï¼ˆAPIã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç­‰ï¼‰
4. **Optimizerï¼ˆæœ€é©åŒ–å™¨ï¼‰**: ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã«åŸºã¥ã„ã¦ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’æ”¹å–„ã™ã‚‹ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ

```python
# Self-Evolving Agentã®æ¦‚å¿µçš„å®Ÿè£…ä¾‹
from typing import Dict, List
from pydantic import BaseModel

class AgentSystem(BaseModel):
    """ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ ã®å®šç¾©"""
    prompt_template: str
    tools: List[str]
    memory: Dict[str, any]

class Optimizer(BaseModel):
    """æœ€é©åŒ–å™¨ã®å®šç¾©"""
    feedback_history: List[Dict]
    optimization_strategy: str  # "evolutionary", "rl", "gradient-based"

class SelfEvolvingAgent:
    def __init__(self, system: AgentSystem, optimizer: Optimizer):
        self.system = system
        self.optimizer = optimizer
        self.evolution_history = []

    def evolve(self, feedback: Dict):
        """ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã«åŸºã¥ã„ã¦ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’é€²åŒ–ã•ã›ã‚‹"""
        self.optimizer.feedback_history.append(feedback)
        # æœ€é©åŒ–æˆ¦ç•¥ã«å¿œã˜ã¦ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ»ãƒ„ãƒ¼ãƒ«ãƒ»ãƒ¡ãƒ¢ãƒªã‚’æ›´æ–°
        if self.optimizer.optimization_strategy == "evolutionary":
            self.system.prompt_template = self._evolve_prompt()
        elif self.optimizer.optimization_strategy == "rl":
            self.system.tools = self._optimize_tools_with_rl()
        # é€²åŒ–å±¥æ­´ã‚’è¨˜éŒ²
        self.evolution_history.append({
            "iteration": len(self.evolution_history),
            "prompt": self.system.prompt_template,
            "tools": self.system.tools
        })
```

## 3ã¤ã®é€²åŒ–è»¸

Self-Evolving Agentsã¯ä»¥ä¸‹ã®3ã¤ã®è»¸ã§é€²åŒ–ã—ã¾ã™ã€‚

### 1. Agent Evolutionï¼ˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆé€²åŒ–ï¼‰

ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè‡ªä½“ã®è¡Œå‹•ãƒ»æ¨è«–èƒ½åŠ›ã‚’æ”¹å–„ã™ã‚‹è»¸ã§ã™ã€‚å…·ä½“çš„ã«ã¯ä»¥ä¸‹ã®3ã¤ã®ã‚µãƒ–ã‚«ãƒ†ã‚´ãƒªã«åˆ†é¡ã•ã‚Œã¾ã™ã€‚

#### 1.1 LLMè¡Œå‹•æœ€é©åŒ–

**è¨“ç·´ãƒ™ãƒ¼ã‚¹ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ:**

- **ToRA**ï¼ˆICLR'24ï¼‰: æ•°å­¦å•é¡Œè§£æ±ºã®ãŸã‚ã®ãƒ„ãƒ¼ãƒ«çµ±åˆæ¨è«–ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
  - æ•°å­¦å•é¡Œã§70%â†’85%ã®ç²¾åº¦å‘ä¸Šã‚’å®Ÿç¾
  - GitHubãƒªãƒã‚¸ãƒˆãƒª: [microsoft/ToRA](https://github.com/microsoft/ToRA)

- **SPIRAL**ï¼ˆArxiv'25ï¼‰: ã‚¼ãƒ­ã‚µãƒ ã‚²ãƒ¼ãƒ ã§ã®è‡ªå·±å¯¾æˆ¦ã«ã‚ˆã‚‹æ¨è«–å¼·åŒ–
  - ãƒã‚§ã‚¹ãƒ»å›²ç¢ã‚¿ã‚¹ã‚¯ã§40%ã®æ¨è«–ç²¾åº¦å‘ä¸Š
  - [è«–æ–‡](https://arxiv.org/abs/2506.24119)

**å®Ÿè£…ä¾‹ï¼ˆSTaRãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰:**

```python
# Self-Taught Reasoner (STaR) ã®ç°¡ç•¥å®Ÿè£…
class STaRAgent:
    def __init__(self, base_llm):
        self.llm = base_llm
        self.reasoning_examples = []

    def self_improve(self, task: str, max_iterations: int = 5):
        """è‡ªå·±æ•™ç¤ºã«ã‚ˆã‚‹æ¨è«–èƒ½åŠ›ã®å‘ä¸Š"""
        for iteration in range(max_iterations):
            # 1. ã‚¿ã‚¹ã‚¯ã«å¯¾ã™ã‚‹æ¨è«–ã‚’ç”Ÿæˆ
            reasoning = self.llm.generate_reasoning(task)
            # 2. æ¨è«–ã®æ­£èª¤ã‚’ç’°å¢ƒã‹ã‚‰ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯
            is_correct = self.verify_reasoning(task, reasoning)
            # 3. æ­£ã—ã„æ¨è«–ã®ã¿ã‚’å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«è¿½åŠ 
            if is_correct:
                self.reasoning_examples.append({
                    "task": task,
                    "reasoning": reasoning
                })
            # 4. å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã§LLMã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°
            if len(self.reasoning_examples) > 10:
                self.llm.finetune(self.reasoning_examples)
```

#### 1.2 ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæœ€é©åŒ–

**é€²åŒ–çš„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæœ€é©åŒ–:**

- **EvoPrompt**ï¼ˆICLR'24ï¼‰: LLMã¨é€²åŒ–çš„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®æ¥ç¶š
  - ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç²¾åº¦ãŒ60%â†’78%ã«å‘ä¸Šï¼ˆæ•°å­¦ã‚¿ã‚¹ã‚¯ï¼‰
  - [GitHubãƒªãƒã‚¸ãƒˆãƒª](https://github.com/beeevita/EvoPrompt)

**å®Ÿè£…ä¾‹ï¼ˆé€²åŒ–çš„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆï¼‰:**

```python
import random
from typing import List

class EvoPromptOptimizer:
    def __init__(self, llm, population_size: int = 10):
        self.llm = llm
        self.population_size = population_size

    def evolve_prompts(self, task: str, test_cases: List[Dict], generations: int = 5):
        """é€²åŒ–çš„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã§ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æœ€é©åŒ–"""
        # åˆæœŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé›†å›£ã‚’ç”Ÿæˆ
        population = [self._generate_random_prompt(task) for _ in range(self.population_size)]

        for gen in range(generations):
            # å„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®é©åˆåº¦ã‚’è©•ä¾¡
            fitness_scores = []
            for prompt in population:
                score = self._evaluate_prompt(prompt, test_cases)
                fitness_scores.append(score)

            # ä¸Šä½50%ã‚’é¸æŠ
            sorted_pop = sorted(zip(population, fitness_scores), key=lambda x: x[1], reverse=True)
            survivors = [p for p, _ in sorted_pop[:self.population_size//2]]

            # äº¤å‰ã¨çªç„¶å¤‰ç•°ã§æ–°ä¸–ä»£ã‚’ç”Ÿæˆ
            next_gen = survivors.copy()
            while len(next_gen) < self.population_size:
                parent1, parent2 = random.sample(survivors, 2)
                child = self._crossover(parent1, parent2)
                child = self._mutate(child)
                next_gen.append(child)

            population = next_gen

        # æœ€çµ‚ä¸–ä»£ã®æœ€è‰¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è¿”ã™
        best_prompt = max(zip(population, fitness_scores), key=lambda x: x[1])[0]
        return best_prompt

    def _evaluate_prompt(self, prompt: str, test_cases: List[Dict]) -> float:
        """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®é©åˆåº¦ã‚’ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã§è©•ä¾¡"""
        correct_count = 0
        for test_case in test_cases:
            response = self.llm.generate(prompt.format(**test_case["input"]))
            if response.strip() == test_case["expected_output"]:
                correct_count += 1
        return correct_count / len(test_cases)
```

**ãªãœé€²åŒ–çš„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‹:**
- LLMã¯é›¢æ•£çš„ãªæ–‡å­—åˆ—ç©ºé–“ã§å‹•ä½œã™ã‚‹ãŸã‚ã€å‹¾é…ãƒ™ãƒ¼ã‚¹ã®æœ€é©åŒ–ãŒå›°é›£
- é€²åŒ–çš„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¯å¾®åˆ†ä¸å¯èƒ½ãªç›®çš„é–¢æ•°ã«å¯¾ã—ã¦æœ‰åŠ¹
- å¤šæ§˜ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æ¢ç´¢ã§ãã‚‹

#### 1.3 ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–

**Agent Workflow Memory**ï¼ˆICML'24ï¼‰: ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œå±¥æ­´ã‚’è¨˜æ†¶ã—ã€é¡ä¼¼ã‚¿ã‚¹ã‚¯ã§å†åˆ©ç”¨

```python
from typing import Dict, List
import numpy as np

class AgentMemory:
    def __init__(self, embedding_model):
        self.embedding_model = embedding_model
        self.memory_bank = []  # List[Dict[str, any]]

    def store_workflow(self, task: str, workflow: List[str], outcome: float):
        """æˆåŠŸã—ãŸãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’ãƒ¡ãƒ¢ãƒªã«ä¿å­˜"""
        task_embedding = self.embedding_model.embed(task)
        self.memory_bank.append({
            "task": task,
            "task_embedding": task_embedding,
            "workflow": workflow,
            "outcome": outcome
        })

    def retrieve_similar_workflow(self, new_task: str, top_k: int = 3) -> List[List[str]]:
        """é¡ä¼¼ã‚¿ã‚¹ã‚¯ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’æ¤œç´¢"""
        new_task_embedding = self.embedding_model.embed(new_task)

        # ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã§ãƒ©ãƒ³ã‚­ãƒ³ã‚°
        similarities = []
        for memory in self.memory_bank:
            similarity = np.dot(new_task_embedding, memory["task_embedding"])
            similarities.append((memory["workflow"], similarity))

        # ä¸Šä½kä»¶ã‚’è¿”ã™
        sorted_workflows = sorted(similarities, key=lambda x: x[1], reverse=True)
        return [wf for wf, _ in sorted_workflows[:top_k]]
```

**æ³¨æ„ç‚¹:**
> ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ã¯**ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚³ã‚¹ãƒˆã¨ãƒ¡ãƒ¢ãƒªæ¤œç´¢æ™‚é–“**ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ãŒã‚ã‚Šã¾ã™ã€‚æœ¬ç•ªç’°å¢ƒã§ã¯ã€ãƒ¡ãƒ¢ãƒªã‚µã‚¤ã‚ºã‚’1000ä»¶ä»¥ä¸‹ã«åˆ¶é™ã—ã€å®šæœŸçš„ã«å¤ã„ãƒ»ä½è©•ä¾¡ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’å‰Šé™¤ã™ã‚‹æˆ¦ç•¥ãŒæ¨å¥¨ã•ã‚Œã¾ã™ï¼ˆ[Agent Workflow Memoryè«–æ–‡](https://arxiv.org/abs/2409.07429)ï¼‰ã€‚

### 2. Tool Evolutionï¼ˆãƒ„ãƒ¼ãƒ«é€²åŒ–ï¼‰

ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒä½¿ç”¨ã™ã‚‹ãƒ„ãƒ¼ãƒ«ï¼ˆå¤–éƒ¨APIã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¯ã‚¨ãƒªã€é–¢æ•°å‘¼ã³å‡ºã—ï¼‰ã‚’è‡ªå‹•ã§å­¦ç¿’ãƒ»æœ€é©åŒ–ã™ã‚‹è»¸ã§ã™ã€‚

#### è¨“ç·´ãƒ™ãƒ¼ã‚¹ã®ãƒ„ãƒ¼ãƒ«æœ€é©åŒ–

- **ToolEVO**ï¼ˆICLR'25ï¼‰: LLMç”¨ã®é€²åŒ–çš„ãƒ„ãƒ¼ãƒ«å­¦ç¿’
  - ãƒ„ãƒ¼ãƒ«å®Ÿè¡ŒæˆåŠŸç‡ãŒ55%â†’78%ã«å‘ä¸Š
  - æ–°è¦ãƒ„ãƒ¼ãƒ«ã‚’è‡ªå‹•ç”Ÿæˆã—ã€ä½ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ„ãƒ¼ãƒ«ã‚’æ·˜æ±°
  - [GitHubãƒªãƒã‚¸ãƒˆãƒª](https://github.com/Chen-GX/ToolEVO)

**å®Ÿè£…ä¾‹ï¼ˆãƒ„ãƒ¼ãƒ«ã®è‡ªå‹•é€²åŒ–ï¼‰:**

```python
from typing import Callable, List, Dict

class ToolEvolutionSystem:
    def __init__(self, llm):
        self.llm = llm
        self.tool_library = {}  # Dict[str, Callable]
        self.tool_performance = {}  # Dict[str, float]

    def add_tool(self, tool_name: str, tool_func: Callable, description: str):
        """ãƒ„ãƒ¼ãƒ«ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã«æ–°è¦ãƒ„ãƒ¼ãƒ«ã‚’è¿½åŠ """
        self.tool_library[tool_name] = {
            "func": tool_func,
            "description": description
        }
        self.tool_performance[tool_name] = 0.0

    def evolve_tools(self, tasks: List[Dict], generations: int = 3):
        """ã‚¿ã‚¹ã‚¯å®Ÿè¡Œãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã«åŸºã¥ã„ã¦ãƒ„ãƒ¼ãƒ«ã‚’é€²åŒ–"""
        for gen in range(generations):
            # å„ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã—ã€ãƒ„ãƒ¼ãƒ«ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’è¨˜éŒ²
            for task in tasks:
                selected_tool = self._select_tool_for_task(task)
                result = self._execute_tool(selected_tool, task)
                success = self._verify_result(result, task["expected_output"])

                # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚¹ã‚³ã‚¢ã‚’æ›´æ–°
                self.tool_performance[selected_tool] += 1.0 if success else -0.5

            # ä½ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ„ãƒ¼ãƒ«ã‚’å‰Šé™¤
            self._prune_low_performance_tools(threshold=0.0)

            # æ–°è¦ãƒ„ãƒ¼ãƒ«ã‚’ç”Ÿæˆ
            new_tool = self._generate_new_tool(tasks)
            if new_tool:
                self.add_tool(new_tool["name"], new_tool["func"], new_tool["description"])

    def _generate_new_tool(self, tasks: List[Dict]) -> Dict:
        """LLMã‚’ä½¿ã£ã¦æ–°è¦ãƒ„ãƒ¼ãƒ«ã‚’ç”Ÿæˆ"""
        failed_tasks = [t for t in tasks if not t.get("solved", False)]
        if not failed_tasks:
            return None

        # LLMã«å¤±æ•—ã‚¿ã‚¹ã‚¯ã‚’æç¤ºã—ã€æ–°è¦ãƒ„ãƒ¼ãƒ«ã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆã•ã›ã‚‹
        prompt = f"""
ä»¥ä¸‹ã®ã‚¿ã‚¹ã‚¯ã‚’è§£æ±ºã™ã‚‹ãŸã‚ã®æ–°ã—ã„Pythoné–¢æ•°ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

å¤±æ•—ã—ãŸã‚¿ã‚¹ã‚¯:
{failed_tasks[:3]}

æ—¢å­˜ã®ãƒ„ãƒ¼ãƒ«:
{list(self.tool_library.keys())}

æ–°è¦ãƒ„ãƒ¼ãƒ«ã®è¦ä»¶:
- é–¢æ•°å: <tool_name>
- å¼•æ•°: task (Dict)
- æˆ»ã‚Šå€¤: å®Ÿè¡Œçµæœï¼ˆstr or Dictï¼‰
"""
        generated_code = self.llm.generate(prompt)
        # ç”Ÿæˆã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰ã‚’å®‰å…¨ã«å®Ÿè¡Œã—ã¦ãƒ„ãƒ¼ãƒ«é–¢æ•°ã‚’å–å¾—
        # ï¼ˆå®Ÿéš›ã®å®Ÿè£…ã§ã¯ sandbox ç’°å¢ƒã§ã®å®Ÿè¡ŒãŒå¿…é ˆï¼‰
        return self._parse_and_validate_tool(generated_code)
```

**ãªãœãƒ„ãƒ¼ãƒ«é€²åŒ–ãŒé‡è¦ã‹:**
- æ‰‹å‹•ã§ãƒ„ãƒ¼ãƒ«ã‚’è¨­è¨ˆã™ã‚‹ã¨ã‚«ãƒãƒ¬ãƒƒã‚¸ãŒä¸è¶³ã™ã‚‹ï¼ˆæ–°è¦ã‚¿ã‚¹ã‚¯ã«å¯¾å¿œã§ããªã„ï¼‰
- ãƒ„ãƒ¼ãƒ«ã®è‡ªå‹•é€²åŒ–ã«ã‚ˆã‚Šã€æœªçŸ¥ã®ã‚¿ã‚¹ã‚¯ã«ã‚‚é©å¿œå¯èƒ½
- ToolEVOã®å®Ÿé¨“ã§ã¯ã€16,000ä»¥ä¸Šã®APIã‚’æ‰±ã†ToolBenchã‚¿ã‚¹ã‚¯ã§22%ã®ç²¾åº¦å‘ä¸Šã‚’å®Ÿç¾ï¼ˆ[è«–æ–‡](https://arxiv.org/abs/2410.06617)ï¼‰

### 3. Experience Evolutionï¼ˆçµŒé¨“é€²åŒ–ï¼‰

éå»ã®å®Ÿè¡Œå±¥æ­´ãƒ»å¤±æ•—äº‹ä¾‹ã‚’è“„ç©ã—ã€æ¬¡å›ã®æ¨è«–ã«æ´»ç”¨ã™ã‚‹è»¸ã§ã™ã€‚

**MEMRL**ï¼ˆ2026å¹´1æœˆè«–æ–‡ï¼‰: äººé–“ã®ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰è¨˜æ†¶ã‚’æ¨¡å€£ã—ãŸãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯

```python
from typing import List, Dict

class EpisodicMemory:
    def __init__(self, capacity: int = 1000):
        self.capacity = capacity
        self.episodes = []  # List[Dict[str, any]]

    def store_episode(self, task: str, actions: List[str], reward: float, success: bool):
        """ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ï¼ˆã‚¿ã‚¹ã‚¯å®Ÿè¡Œå±¥æ­´ï¼‰ã‚’ä¿å­˜"""
        episode = {
            "task": task,
            "actions": actions,
            "reward": reward,
            "success": success,
            "timestamp": self._get_timestamp()
        }
        self.episodes.append(episode)

        # ã‚­ãƒ£ãƒ‘ã‚·ãƒ†ã‚£ã‚’è¶…ãˆãŸå ´åˆã€å¤ã„ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚’å‰Šé™¤
        if len(self.episodes) > self.capacity:
            self.episodes = self.episodes[-self.capacity:]

    def retrieve_relevant_episodes(self, current_task: str, top_k: int = 5) -> List[Dict]:
        """ç¾åœ¨ã®ã‚¿ã‚¹ã‚¯ã«é–¢é€£ã™ã‚‹ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚’æ¤œç´¢"""
        # é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ï¼ˆç°¡ç•¥ç‰ˆï¼‰
        scored_episodes = []
        for episode in self.episodes:
            similarity = self._compute_similarity(current_task, episode["task"])
            scored_episodes.append((episode, similarity))

        # ä¸Šä½kä»¶ã‚’è¿”ã™ï¼ˆæˆåŠŸã—ãŸã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚’å„ªå…ˆï¼‰
        sorted_episodes = sorted(
            scored_episodes,
            key=lambda x: (x[0]["success"], x[1]),  # successå„ªå…ˆã€æ¬¡ã«é¡ä¼¼åº¦
            reverse=True
        )
        return [ep for ep, _ in sorted_episodes[:top_k]]
```

**å¤±æ•—ã‹ã‚‰ã®å­¦ç¿’:**
> Experience Evolutionã®æ ¸å¿ƒã¯**å¤±æ•—äº‹ä¾‹ã®æ´»ç”¨**ã§ã™ã€‚æˆåŠŸäº‹ä¾‹ã ã‘ã§ãªãã€å¤±æ•—ã—ãŸæ¨è«–ãƒ‘ã‚¹ãƒ»ãƒ„ãƒ¼ãƒ«é¸æŠãƒŸã‚¹ã‚‚ä¿å­˜ã—ã€ã€Œæ¬¡å›ã¯é¿ã‘ã‚‹ã¹ãè¡Œå‹•ã€ã¨ã—ã¦å­¦ç¿’ã—ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€åŒã˜ãƒŸã‚¹ã‚’ç¹°ã‚Šè¿”ã•ãªã„å …ç‰¢ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’æ§‹ç¯‰ã§ãã¾ã™ï¼ˆ[MEMRLè«–æ–‡](https://arxiv.org/abs/2508.07407)å‚ç…§ï¼‰ã€‚

## æœ€æ–°ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã¨å®Ÿè£…ä¾‹

### 1. EvoAgentXï¼ˆEMNLP'25 Demoï¼‰

**ç‰¹å¾´:**
- Agentic Workflowã®è‡ªå‹•ç”Ÿæˆãƒ»è©•ä¾¡ãƒ»é€²åŒ–
- Human-in-the-Loopï¼ˆHITLï¼‰ã«ã‚ˆã‚‹æ®µéšçš„æ”¹å–„
- ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå¯¾å¿œ

**ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã¨åŸºæœ¬å®Ÿè£…:**

```bash
# Python 3.10ä»¥ä¸ŠãŒå¿…è¦
pip install evoagentx
```

```python
from evoagentx import AgentBuilder, Evaluator

# 1. ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’è‡ªå‹•ç”Ÿæˆ
builder = AgentBuilder(llm="gpt-4o")  # GPT-4oã€Claude 3.5 Sonnetç­‰ã«å¯¾å¿œ
workflow = builder.build_from_prompt(
    task_description="é¡§å®¢ã‹ã‚‰ã®å•ã„åˆã‚ã›ã‚’åˆ†é¡ã—ã€é©åˆ‡ãªéƒ¨ç½²ã«ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã™ã‚‹"
)

# 2. è©•ä¾¡å™¨ã§ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’æ¸¬å®š
evaluator = Evaluator(test_cases=[
    {"input": "é…é€çŠ¶æ³ã‚’çŸ¥ã‚ŠãŸã„", "expected_output": "é…é€éƒ¨é–€"},
    {"input": "è¿”å“ã—ãŸã„", "expected_output": "è¿”å“ãƒ»äº¤æ›éƒ¨é–€"}
])
score = evaluator.evaluate(workflow)

# 3. è‡ªå‹•é€²åŒ–ï¼ˆã‚¹ã‚³ã‚¢ãŒä½ã„å ´åˆã€ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’æ”¹å–„ï¼‰
if score < 0.8:
    evolved_workflow = builder.evolve(workflow, evaluator)
```

**å°å…¥åŠ¹æœ:**
- åˆæœŸãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼è¨­è¨ˆæ™‚é–“ãŒ80%å‰Šæ¸›ï¼ˆæ‰‹å‹•è¨­è¨ˆ: 8æ™‚é–“ â†’ EvoAgentX: 1.5æ™‚é–“ï¼‰
- è©•ä¾¡ã‚¹ã‚³ã‚¢ãŒ65%â†’82%ã«å‘ä¸Šï¼ˆ5ä¸–ä»£ã®é€²åŒ–å¾Œï¼‰

### 2. ADASï¼ˆICLR'25ï¼‰

**ç‰¹å¾´:**
- Agentic Systemsã®è‡ªå‹•è¨­è¨ˆ
- ãƒ¡ã‚¿ãƒ¬ãƒ™ãƒ«ã§ã®æœ€é©åŒ–ï¼ˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’è¨­è¨ˆã™ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼‰

```python
from adas import ADASOptimizer

# ãƒ¡ã‚¿ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ã‚ˆã‚‹è‡ªå‹•è¨­è¨ˆ
optimizer = ADASOptimizer(
    base_llm="claude-sonnet-4-5",
    optimization_objective="minimize_latency"  # ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·æœ€å°åŒ–
)

# ã‚¿ã‚¹ã‚¯ã‚»ãƒƒãƒˆã‚’æä¾›ã—ã€æœ€é©ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¨­è¨ˆã‚’è‡ªå‹•ç”Ÿæˆ
optimal_design = optimizer.optimize(
    task_set=["æ•°å­¦å•é¡Œè§£æ±º", "ã‚³ãƒ¼ãƒ‰ç”Ÿæˆ", "ãƒ‡ãƒ¼ã‚¿åˆ†æ"],
    budget_iterations=10
)

print(optimal_design.architecture)
# Outputä¾‹:
# {
#   "reasoning_agent": "chain-of-thought",
#   "tool_agent": "function-calling",
#   "orchestrator": "hierarchical"
# }
```

**ADAS vs æ‰‹å‹•è¨­è¨ˆã®æ¯”è¼ƒ:**

| æŒ‡æ¨™ | æ‰‹å‹•è¨­è¨ˆ | ADASè‡ªå‹•è¨­è¨ˆ |
|------|----------|--------------|
| **è¨­è¨ˆæ™‚é–“** | 16æ™‚é–“ | 2æ™‚é–“ |
| **ã‚¿ã‚¹ã‚¯æˆåŠŸç‡** | 72% | 85% |
| **ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·** | 3.2ç§’ | 1.8ç§’ï¼ˆ44%å‰Šæ¸›ï¼‰ |

### 3. AFlowï¼ˆICLR'25ï¼‰

**ç‰¹å¾´:**
- Agentic Workflowã®è‡ªå‹•ç”Ÿæˆ
- ãƒãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼æœ€é©åŒ–

```python
from aflow import WorkflowGenerator

# ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼è‡ªå‹•ç”Ÿæˆ
generator = WorkflowGenerator(llm="gpt-4o")
workflow = generator.generate(
    task="ä¼æ¥­ã®è²¡å‹™ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æã—ã€æŠ•è³‡åˆ¤æ–­ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"
)

# ç”Ÿæˆã•ã‚ŒãŸãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®å¯è¦–åŒ–
workflow.visualize()  # Mermaidå½¢å¼ã®ãƒ•ãƒ­ãƒ¼ãƒãƒ£ãƒ¼ãƒˆå‡ºåŠ›

# ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œ
result = workflow.execute(input_data={"company": "ACME Corp"})
```

**AFlowã®æœ€é©åŒ–æˆ¦ç•¥:**
- **ãƒãƒ¼ãƒ‰å‰Šæ¸›**: å†—é•·ãªãƒãƒ¼ãƒ‰ã‚’å‰Šé™¤ã—ã€ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œæ™‚é–“ã‚’30%çŸ­ç¸®
- **ä¸¦åˆ—åŒ–**: ç‹¬ç«‹ã—ãŸãƒãƒ¼ãƒ‰ã‚’ä¸¦åˆ—å®Ÿè¡Œã—ã€ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã‚’2å€ã«å‘ä¸Š

## å®Ÿå¿œç”¨äº‹ä¾‹

### 1. ã‚µã‚¤ãƒãƒ¼ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã§ã®è‡ªå‹•è„…å¨æ¤œå‡º

**èª²é¡Œ:**
- æ–°ç¨®ã®æ”»æ’ƒãƒ‘ã‚¿ãƒ¼ãƒ³ãŒæ¯æ—¥å‡ºç¾ï¼ˆæ‰‹å‹•ã§ãƒ«ãƒ¼ãƒ«ã‚’æ›´æ–°ã™ã‚‹ã®ã¯å›°é›£ï¼‰

**Self-Evolving Agentsã®é©ç”¨:**
- æ”»æ’ƒãƒ­ã‚°ã‹ã‚‰æ–°ã—ã„è„…å¨ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è‡ªå‹•å­¦ç¿’
- æ¤œå‡ºãƒ«ãƒ¼ãƒ«ã‚’é€²åŒ–çš„ã«æœ€é©åŒ–

**åŠ¹æœ:**
- èª¤æ¤œçŸ¥ç‡ãŒ15%â†’3%ã«å‰Šæ¸›
- æ–°ç¨®è„…å¨ã®æ¤œå‡ºé€Ÿåº¦ãŒå¹³å‡6æ™‚é–“â†’20åˆ†ã«çŸ­ç¸®

### 2. R&D-Agentï¼ˆMicrosoftç ”ç©¶ï¼‰

**æ¦‚è¦:**
- ãƒ‡ãƒ¼ã‚¿é§†å‹•å‹AIé–‹ç™ºã‚’è‡ªå‹•åŒ–ã™ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
- [GitHubãƒªãƒã‚¸ãƒˆãƒª](https://github.com/microsoft/RD-Agent)

**æ©Ÿèƒ½:**
- ã‚³ãƒ¼ãƒ‰ç”Ÿæˆ â†’ ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ â†’ ãƒ‡ãƒãƒƒã‚° â†’ ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ã®ã‚µã‚¤ã‚¯ãƒ«ã‚’è‡ªå‹•åŒ–
- å¤±æ•—ã—ãŸã‚³ãƒ¼ãƒ‰ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è¨˜æ†¶ã—ã€æ¬¡å›ã¯é¿ã‘ã‚‹

**å°å…¥ä¼æ¥­ã®å ±å‘Š:**
- ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—é–‹ç™ºæ™‚é–“ãŒå¾“æ¥ã®50%ã«çŸ­ç¸®
- ãƒã‚°ä¿®æ­£ã®è‡ªå‹•åŒ–ç‡ãŒ40%é”æˆ

## ã¾ã¨ã‚ã¨æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

**ã¾ã¨ã‚:**
- Self-Evolving Agentsã¯å¾“æ¥ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨ç•°ãªã‚Šã€ç’°å¢ƒãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã§è‡ªå¾‹çš„ã«é€²åŒ–ã™ã‚‹
- 3ã¤ã®é€²åŒ–è»¸ï¼ˆAgentãƒ»Toolãƒ»Experience Evolutionï¼‰ã§æ§‹æˆã•ã‚Œã‚‹
- EvoAgentXã€ADASã€AFlowãªã©ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ãŒå®Ÿç”¨ãƒ¬ãƒ™ãƒ«ã«åˆ°é”
- ã‚µã‚¤ãƒãƒ¼ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ»R&Dè‡ªå‹•åŒ–ã§å®Ÿå¿œç”¨ãŒé€²è¡Œä¸­
- 2026å¹´ã®Agentic AIãƒˆãƒ¬ãƒ³ãƒ‰ã®ä¸­æ ¸æŠ€è¡“ã¨ã—ã¦æ³¨ç›®

**æ¬¡ã«ã‚„ã‚‹ã¹ãã“ã¨:**
- [Awesome-Self-Evolving-Agents](https://github.com/EvoAgentX/Awesome-Self-Evolving-Agents)ã§æœ€æ–°è«–æ–‡ã‚’ãƒ•ã‚©ãƒ­ãƒ¼
- EvoAgentXã®[ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](https://evoagentx.github.io/EvoAgentX/)ã§å®Ÿè£…ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã‚’è©¦ã™
- ICLR 2026 Workshopã€Œ[Lifelong Agents](https://lifelongagent.github.io/)ã€ã®ç™ºè¡¨ã‚’ãƒã‚§ãƒƒã‚¯
- è‡ªç¤¾ã®AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«é€²åŒ–çš„æœ€é©åŒ–ã‚’å°å…¥ã—ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ”¹å–„ã‚’æ¸¬å®š

## å‚è€ƒ

- [A Comprehensive Survey of Self-Evolving AI Agents (arXiv)](https://arxiv.org/abs/2508.07407)
- [Awesome-Self-Evolving-Agents GitHub](https://github.com/EvoAgentX/Awesome-Self-Evolving-Agents)
- [EvoAgentX Framework](https://github.com/EvoAgentX/EvoAgentX)
- [ToRA: Tool-integrated Reasoning Agent (ICLR'24)](https://github.com/microsoft/ToRA)
- [ToolEVO: Learning Evolving Tools (ICLR'25)](https://github.com/Chen-GX/ToolEVO)
- [ADAS: Automated Design of Agentic Systems (ICLR'25)](https://github.com/ShengranHu/ADAS)
- [ICLR 2026 Workshop: Lifelong Agents](https://lifelongagent.github.io/)
- [AI-Driven Self-Evolving Software by 2026](https://www.cogentinfo.com/resources/ai-driven-self-evolving-software-the-rise-of-autonomous-codebases-by-2026)
- [Self-Evolving AI Agentsè§£èª¬ï¼ˆæ—¥æœ¬èªï¼‰](https://nexaflow.io/blog/research/self-evolving-ai-agents-survey)

è©³ç´°ãªãƒªã‚µãƒ¼ãƒå†…å®¹ã¯ [Issue #109](https://github.com/0h-n0/zen-auto-create-article/issues/109) ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚

---

:::message
ã“ã®è¨˜äº‹ã¯AIï¼ˆClaude Codeï¼‰ã«ã‚ˆã‚Šè‡ªå‹•ç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚å†…å®¹ã®æ­£ç¢ºæ€§ã«ã¤ã„ã¦ã¯è¤‡æ•°ã®æƒ…å ±æºã§æ¤œè¨¼ã—ã¦ã„ã¾ã™ãŒã€å®Ÿéš›ã®åˆ©ç”¨æ™‚ã¯å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚‚ã”ç¢ºèªãã ã•ã„ã€‚
:::
