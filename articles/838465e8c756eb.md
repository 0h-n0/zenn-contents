---
title: "Azure OpenAI負荷分散設計：API ManagementとPTUスピルオーバーで可用性99.9%を実現する"
emoji: "⚖️"
type: "tech"
topics: ["azure", "openai", "apimanagement", "loadbalancing", "infrastructure"]
published: false
---

# Azure OpenAI負荷分散設計：API ManagementとPTUスピルオーバーで可用性99.9%を実現する

## この記事でわかること

- Azure OpenAIの4つのトポロジ（単一インスタンス〜マルチリージョン）に応じた負荷分散パターンの選び方
- Azure API ManagementのAI Gatewayを活用したバックエンドプール構成とCircuit Breakerの実装方法
- PTU（Provisioned Throughput Units）とPay-as-you-goのスピルオーバー戦略によるコスト最適化
- Global Standard / Data Zoneデプロイメントタイプの使い分けとデータ主権への対応
- 本番運用で発生する429エラー（レート制限）への対処と自動フェイルオーバー設計

## 対象読者

- **想定読者**: 中級〜上級のAzureインフラエンジニア・アーキテクト
- **必要な前提知識**:
  - Azure OpenAI Serviceの基本的なデプロイメントとAPI呼び出し
  - Azure API Managementの概要（ポリシー、バックエンド構成）
  - TPM（Tokens Per Minute）/ RPM（Requests Per Minute）の概念
  - Bicep または ARM テンプレートの基礎

## 結論・成果

Azure OpenAIの負荷分散設計では、**Azure API ManagementのAI Gatewayをコアに据え、PTUとPay-as-you-goのスピルオーバー構成を組み合わせる**ことが2026年時点の定石です。Microsoft公式のリファレンスアーキテクチャによると、この構成を採用した企業では、API定義数を85%削減しつつ、サービス可用性99.99%を達成した事例が報告されています。また、PTUで確保したベースライン容量に対してPay-as-you-goでのバースト対応を組み合わせることで、**プロビジョニング過剰によるコストの無駄を抑えながら、ピーク時のスロットリングを回避**できます。

この記事では、Azure公式アーキテクチャガイドとAPI Managementの最新AI Gateway機能に基づき、トポロジ選定からBicep実装まで段階的に解説します。

## Azure OpenAIの負荷分散が必要になる背景を理解する

Azure OpenAI Serviceは、デプロイメントごとに**TPM（Tokens Per Minute）** と **RPM（Requests Per Minute）** のクォータ制限が設けられています。単一のアプリケーションが単一のデプロイメントを利用する構成では問題になりにくいものの、複数アプリケーションが共有する本番環境では、あるアプリケーションがクォータを使い切り、他のアプリケーションが利用できなくなる事態が発生します。

### クォータ制限の仕組み

Azure OpenAIのクォータには以下の特性があります。

| 項目 | Standard デプロイメント | PTU デプロイメント | Global Standard |
|------|----------------------|-------------------|-----------------|
| **課金モデル** | 従量課金（トークン単位） | 月額固定（PTU単位） | 従量課金 |
| **クォータ管理** | サブスクリプション単位のTPM | デプロイメント単位のスループット | Azure全体の空き容量で自動分散 |
| **レイテンシ保証** | なし（ベストエフォート） | あり（予約済み容量） | なし（ベストエフォート） |
| **429エラー時の挙動** | Retry-Afterヘッダー付きで返却 | Retry-Afterヘッダー付きで返却 | 他リージョンに自動ルーティング |

クォータを超過すると、Azure OpenAIは**HTTP 429 Too Many Requests**を`Retry-After`ヘッダー付きで返します。この応答を適切にハンドリングしない場合、エンドユーザーにエラーが伝搬し、サービス品質の低下につながります。

### 4つのトポロジを把握する

Microsoftの公式アーキテクチャガイドでは、Azure OpenAIのマルチバックエンド構成を以下の4つのトポロジに分類しています。

1. **単一インスタンス・複数モデルデプロイメント**: 1つのAzure OpenAIインスタンスに複数モデル（GPT-4o、GPT-4o-mini等）をデプロイ
2. **単一リージョン・複数インスタンス**: 同一リージョン・同一サブスクリプション内で複数インスタンスを運用
3. **単一リージョン・複数サブスクリプション**: サブスクリプションをまたいで複数インスタンスを運用（Standard クォータ拡大が目的）
4. **マルチリージョン・複数インスタンス**: 異なるリージョンにインスタンスを分散配置

**注意点:** Standardデプロイメントのクォータはサブスクリプション単位で管理されるため、同一サブスクリプション内でインスタンスを増やしてもTPMの合計は増加しません。TPMを実質的に増やすには、サブスクリプションを分けるか、PTUデプロイメントを利用する必要があります。

実際には、多くのエンタープライズ環境ではトポロジ2〜4のいずれかを採用することになります。次のセクションでは、これらのトポロジに対してゲートウェイを導入するパターンを見ていきましょう。

## API ManagementのAI Gatewayでバックエンドプールを構成する

Azure API Managementは2025年以降、**AI Gateway**としての機能を大幅に拡充しました。LLMバックエンドに特化した負荷分散、トークンレート制限、セマンティックキャッシュ、Circuit Breakerなどの機能が組み込まれており、Azure OpenAIの負荷分散における推奨技術として位置づけられています。

### バックエンドプールの負荷分散戦略

API Managementのバックエンドプールは、以下の4つの負荷分散戦略をサポートしています。

| 戦略 | 説明 | 適用場面 |
|------|------|----------|
| **Round-robin** | 均等に順番配分 | 同一スペックのバックエンドが複数ある場合 |
| **Weighted** | 重み付け配分 | PTUとPAYGの容量差に応じた配分 |
| **Priority-based** | 優先度順に使用 | PTU優先→PAYG（スピルオーバー）|
| **Session-aware** | セッション固定 | Assistants APIなどステートフルな操作 |

本番環境では**Priority-based**が採用されることが多く、PTUデプロイメントを最優先にし、クォータ超過時にPay-as-you-goデプロイメントへスピルオーバーさせる構成が定番です。

### Bicepによるバックエンドプール定義

以下は、PTU優先のPriority-based負荷分散をBicepで構成する例です。

```bicep
// backend-pool.bicep
// API Managementバックエンドプール（PTU + PAYGスピルオーバー構成）

resource apimBackendPtu 'Microsoft.ApiManagement/service/backends@2024-06-01-preview' = {
  name: 'aoai-eastus-ptu'
  parent: apimService
  properties: {
    url: 'https://${aoaiPtuName}.openai.azure.com/openai'
    protocol: 'http'
    circuitBreaker: {
      rules: [
        {
          failureCondition: {
            count: 3
            errorReasons: [ 'Server errors' ]
            interval: 'PT10S'
            statusCodeRanges: [
              { min: 429, max: 429 }
              { min: 500, max: 503 }
            ]
          }
          name: 'aoaiPtuBreakerRule'
          tripDuration: 'PT30S'
          acceptRetryAfter: true  // Retry-Afterヘッダーを尊重
        }
      ]
    }
  }
}

resource apimBackendPayg 'Microsoft.ApiManagement/service/backends@2024-06-01-preview' = {
  name: 'aoai-eastus-payg'
  parent: apimService
  properties: {
    url: 'https://${aoaiPaygName}.openai.azure.com/openai'
    protocol: 'http'
    circuitBreaker: {
      rules: [
        {
          failureCondition: {
            count: 3
            errorReasons: [ 'Server errors' ]
            interval: 'PT10S'
            statusCodeRanges: [
              { min: 429, max: 429 }
              { min: 500, max: 503 }
            ]
          }
          name: 'aoaiPaygBreakerRule'
          tripDuration: 'PT30S'
          acceptRetryAfter: true
        }
      ]
    }
  }
}

// バックエンドプール（Priority-based）
resource apimBackendPool 'Microsoft.ApiManagement/service/backends@2024-06-01-preview' = {
  name: 'aoai-backend-pool'
  parent: apimService
  properties: {
    type: 'Pool'
    pool: {
      services: [
        {
          id: apimBackendPtu.id
          priority: 1  // PTUを最優先
          weight: 1
        }
        {
          id: apimBackendPayg.id
          priority: 2  // PAYGはフォールバック
          weight: 1
        }
      ]
    }
  }
}
```

**なぜPriority-basedを選んだか:**
- PTUは予約済み容量のため、使い切らないとコストが無駄になる
- Round-robinではPAYGにも均等配分され、PTUの利用率が下がる
- Priority-basedなら、PTUの容量を最大限消費した後にPAYGへ自動的にスピルオーバーする

**注意点:**
> PTUとPAYGで**同一モデル・同一バージョン**をデプロイしてください。例えばPTU側がGPT-4o、PAYG側がGPT-4o-miniという構成にすると、クライアントに予期しない挙動差が発生します。

### Circuit Breakerの動作原理

Circuit Breakerは、バックエンドが連続して障害を返した場合にそのバックエンドへのリクエスト転送を一時停止する仕組みです。API ManagementのCircuit Breakerには、Azure OpenAIに特化した`acceptRetryAfter`オプションがあります。

```
[正常時]
クライアント → API Management → Azure OpenAI (PTU)
                                    ↓ 200 OK

[429発生時（Circuit Break）]
クライアント → API Management → Azure OpenAI (PTU) → 429 + Retry-After: 30
                    ↓ PTUをCircuit Open
                    → Azure OpenAI (PAYG) → 200 OK

[Retry-After経過後（Circuit Close）]
クライアント → API Management → Azure OpenAI (PTU) → 200 OK（復帰）
```

`acceptRetryAfter: true`を設定すると、Azure OpenAIが返す`Retry-After`ヘッダーの値に基づいてCircuitのOpen期間が動的に調整されます。固定の`tripDuration`ではなく、バックエンドの実際の回復時間に合わせた制御が可能になるため、容量の無駄な待機が減少します。

## トークンレート制限とコスト制御を実装する

複数のアプリケーションやチームがAzure OpenAIを共有する環境では、特定のアプリケーションがクォータを独占するリスクがあります。API ManagementのAI Gatewayは、**LLMトークンレート制限ポリシー**で消費者ごとのトークン使用量を制御できます。

### サブスクリプションキー単位のトークン制限

以下のAPIポリシーは、APIサブスクリプションキーごとにTPMを制限する設定です。

```xml
<!-- api-policy.xml -->
<!-- サブスクリプションキー単位でTPMを制限 -->
<inbound>
    <base />
    <llm-token-limit
        counter-key="@(context.Subscription.Id)"
        tokens-per-minute="10000"
        estimate-prompt-tokens="true"
        remaining-tokens-variable-name="remainingTokens">
    </llm-token-limit>
</inbound>
```

`estimate-prompt-tokens="true"`を有効にすると、API Management側でプロンプトのトークン数を事前推定し、制限を超過するリクエストをバックエンドへ転送せずにブロックします。これにより、Azure OpenAIへの不要なリクエストが削減され、クォータの消費を抑制できます。

### トークンメトリクスの可視化

コスト管理の観点では、誰がどれだけトークンを消費しているかを把握することが重要です。`llm-emit-token-metric`ポリシーでカスタムディメンション付きのメトリクスをAzure Monitorに送信できます。

```xml
<!-- token-metrics-policy.xml -->
<!-- トークン消費メトリクスをAzure Monitorに送信 -->
<outbound>
    <base />
    <llm-emit-token-metric namespace="aoai-usage">
        <dimension name="Subscription" value="@(context.Subscription.Id)" />
        <dimension name="API" value="@(context.Api.Id)" />
        <dimension name="Team" value="@(context.Request.Headers.GetValueOrDefault("x-team-id", "unknown"))" />
    </llm-emit-token-metric>
</outbound>
```

このメトリクスをApplication Insightsのダッシュボードで可視化すると、チーム別・API別のトークン消費量をリアルタイムに追跡でき、**チャージバック（利用部門への費用配賦）** の基盤として活用できます。

**よくある間違い:** 最初はAzure OpenAI側のログだけで消費量を追跡しようと考えがちですが、複数クライアントが同一のMicrosoft Entra IDプリンシパルで認証している場合、Azure OpenAIのアクセスログではクライアントの区別がつきません。API Managementのゲートウェイ層でメトリクスを収集する方が、消費者ごとの正確な追跡が可能です。

## PTUとPay-as-you-goのスピルオーバー戦略を設計する

Azure OpenAIのコスト最適化において中核となるのが、**PTU（Provisioned Throughput Units）とPay-as-you-go（PAYG）の併用戦略**です。

### PTUとPAYGの特性比較

| 特性 | PTU | Pay-as-you-go |
|------|-----|---------------|
| **課金体系** | 月額固定（時間単位課金） | 従量課金（トークン単位） |
| **レイテンシ** | 低い（予約済み容量） | 変動する（空き状況に依存） |
| **適用場面** | 予測可能な定常トラフィック | バースト・変動トラフィック |
| **コスト効率** | 使い切れば安い | 少量なら安い |
| **予約割引** | Azure Reservationsで大幅な割引あり | なし |

### スピルオーバー構成のアーキテクチャ

スピルオーバー戦略の基本方針は、「PTUを若干少なめにプロビジョニングし、超過分をPAYGで吸収する」ことです。

```
[通常時: PTU内に収まるトラフィック]
クライアント → API Management → PTU (Priority 1) → 処理完了

[ピーク時: PTUの容量を超過]
クライアント → API Management → PTU (Priority 1) → 429
                    ↓ Circuit Break
                    → PAYG (Priority 2) → 処理完了

[深夜帯: トラフィック減少]
クライアント → API Management → PTU (Priority 1) → 処理完了
                                 （PAYGは使用されない）
```

**トレードオフ:** PTUを過剰にプロビジョニングすれば429エラーは発生しませんが、利用率が低い時間帯にコストの無駄が生じます。一方、PTUを少なめに設定しすぎると、PAYGへのスピルオーバーが頻発し、レイテンシの増加とPAYGコストの上昇を招きます。最適なPTU量は、[Azure OpenAI Capacity Calculator](https://oai.azure.com/portal/calculator)と実際のトラフィックパターンから算出してください。

### マルチリージョン・スピルオーバーの実装

高可用性が求められる環境では、マルチリージョン構成にスピルオーバーを組み合わせます。以下はAPI Managementのマルチリージョンデプロイメントを活用した構成例です。

```bicep
// multi-region-backend-pool.bicep
// マルチリージョン構成のバックエンドプール

// East USリージョン（プライマリ）
resource backendEastUsPtu 'Microsoft.ApiManagement/service/backends@2024-06-01-preview' = {
  name: 'aoai-eastus-ptu'
  parent: apimService
  properties: {
    url: 'https://aoai-eastus-ptu.openai.azure.com/openai'
    protocol: 'http'
    circuitBreaker: {
      rules: [ circuitBreakerRule ]
    }
  }
}

// East US PAYG（スピルオーバー先）
resource backendEastUsPayg 'Microsoft.ApiManagement/service/backends@2024-06-01-preview' = {
  name: 'aoai-eastus-payg'
  parent: apimService
  properties: {
    url: 'https://aoai-eastus-payg.openai.azure.com/openai'
    protocol: 'http'
    circuitBreaker: {
      rules: [ circuitBreakerRule ]
    }
  }
}

// West US（DRリージョン）
resource backendWestUsPayg 'Microsoft.ApiManagement/service/backends@2024-06-01-preview' = {
  name: 'aoai-westus-payg'
  parent: apimService
  properties: {
    url: 'https://aoai-westus-payg.openai.azure.com/openai'
    protocol: 'http'
    circuitBreaker: {
      rules: [ circuitBreakerRule ]
    }
  }
}

// 3層優先度バックエンドプール
resource backendPool 'Microsoft.ApiManagement/service/backends@2024-06-01-preview' = {
  name: 'aoai-multi-region-pool'
  parent: apimService
  properties: {
    type: 'Pool'
    pool: {
      services: [
        { id: backendEastUsPtu.id, priority: 1, weight: 1 }   // 最優先: PTU
        { id: backendEastUsPayg.id, priority: 2, weight: 1 }  // 次点: 同一リージョンPAYG
        { id: backendWestUsPayg.id, priority: 3, weight: 1 }  // 最終: 別リージョンPAYG
      ]
    }
  }
}
```

**なぜ3層構成にしたか:**
- Priority 1（PTU）: 予約済み容量を最大限活用するため最優先
- Priority 2（同一リージョンPAYG）: レイテンシを抑えつつ容量を拡大
- Priority 3（別リージョンPAYG）: リージョン障害時のDR対応

**制約条件:**
> クロスリージョンのフェイルオーバーではネットワークレイテンシが増加します。East US → West USの場合、通常40-60msの追加レイテンシが発生するため、リアルタイム性が求められるアプリケーションでは、この増加分を許容できるか事前に検証してください。

## Global StandardとData Zoneデプロイメントを使い分ける

2025年以降、Azure OpenAIには**デプロイメントタイプ**の概念が追加され、負荷分散の選択肢が広がりました。自前でバックエンドプールを構成する前に、デプロイメントタイプによる自動分散が要件を満たすか検討してください。

### デプロイメントタイプの比較

| タイプ | データ処理の範囲 | 負荷分散 | クォータ | 適用場面 |
|--------|----------------|---------|---------|----------|
| **Standard** | 同一リージョン | なし（手動で構成） | サブスクリプション・リージョン単位 | データ主権が厳しい環境 |
| **Global Standard** | 全リージョン | Azure側が自動ルーティング | 高い既定クォータ | コスト重視・グローバル展開 |
| **Data Zone Standard** | 指定された地理的ゾーン（EU/US） | ゾーン内で自動ルーティング | ゾーン内の集約クォータ | GDPR等のデータ主権と自動分散を両立 |
| **Provisioned (PTU)** | 同一リージョン | なし（手動で構成） | デプロイメント単位 | レイテンシ保証が必要 |
| **Global Provisioned** | 全リージョン | Azure側が自動ルーティング | 予約済みスループット | レイテンシ保証＋グローバル展開 |

### 判断フローチャート

```
データ主権要件あり？
  ├─ はい → EUまたはUSの規制内？
  │        ├─ はい → Data Zone Standard / Data Zone Provisioned
  │        └─ いいえ → Standard（特定リージョン固定）
  └─ いいえ → レイテンシ保証が必要？
              ├─ はい → PTU / Global Provisioned
              └─ いいえ → Global Standard
```

**ハマりポイント:** Global Standardは便利ですが、ピーク時にリクエストがどのリージョンで処理されるか制御できません。EUのデータ保護規制（GDPR）に該当する場合、Global StandardではEU外でデータが処理される可能性があります。その場合はData Zone Standard（EUゾーン）を選択してください。

Global StandardやData Zoneを選択した場合でも、API Managementのゲートウェイ層で**トークンレート制限・認証・ログ収集**を行う構成は変わりません。デプロイメントタイプによる自動分散と、ゲートウェイ層でのアクセス制御は補完関係にあります。

## 本番運用のトラブルシューティングに備える

負荷分散構成を本番環境に導入した後に発生しやすい問題と、その対処方法をまとめます。

### よくある問題と解決方法

| 問題 | 原因 | 解決方法 |
|------|------|----------|
| 429エラーが頻発する | PTU容量が不足、またはPAYGクォータを超過 | Capacity CalculatorでPTU量を再計算、サブスクリプション分割でクォータ拡大 |
| PAYGへのスピルオーバーが多すぎる | PTUを少なめに設定しすぎている | トラフィックパターンの95パーセンタイルをPTUでカバーするよう調整 |
| Circuit Breakerが頻繁にトリップする | `failureCondition`のカウントが小さすぎる | 閾値を調整（例: 3回→5回）、`interval`を長めに設定 |
| ヘルスプローブが機能しない | Azure OpenAIはカスタムヘルスエンドポイントを提供しない | アプリケーション側のリトライ機構で対応、429/500/503をCircuit Breakerのトリガーとして利用 |
| APIM経由でレイテンシが増加する | ポリシーの処理時間、クロスリージョンのネットワーク遅延 | API ManagementをAzure OpenAIと同一リージョンにデプロイ、不要なポリシーを削除 |
| Assistants APIでセッションが切れる | ラウンドロビンにより別バックエンドに振り分けられた | Session-awareな負荷分散に切り替え、またはCookieベースのピン留めを実装 |

### Front Doorとの組み合わせに関する運用知見

EmotionTech社の事例では、**Azure Front Door + API Management**の組み合わせで運用した際に以下の課題が報告されています。

- **ヘルスプローブの制限**: Azure OpenAIが単純なHTTPリクエストに対して404を返すため、Front Doorの自動障害検知が期待通りに機能しない
- **設定変更のリードタイム**: Origin数が増えるとTerraform適用に20分程度要し、緊急時の対応が遅延する
- **Origin数の上限**: Front Door ProfileあたりのOrigin設定数に上限があり、大規模構成では整理が必要

これらの制約から、Azure OpenAIのプロトコルに最適化されたAPI ManagementのAI Gatewayを直接利用する構成が、2026年時点では推奨されています。Front Doorは**WAF（Web Application Firewall）が必要な場合**や**パブリックインターネットからのアクセスを受け付ける場合**に、API Managementの前段として配置する役割に限定するのが適切です。

### セマンティックキャッシュによるコスト削減

API ManagementのAI Gatewayは、**セマンティックキャッシュ**もサポートしています。過去のプロンプトと類似するリクエストに対してキャッシュ済みの応答を返すことで、バックエンドへの呼び出し回数を削減し、レスポンスタイムの改善とコスト削減を同時に実現できます。

```xml
<!-- semantic-cache-policy.xml -->
<!-- セマンティックキャッシュの設定例 -->
<inbound>
    <base />
    <llm-semantic-cache-lookup
        score-threshold="0.9"
        embeddings-backend-id="embeddings-backend"
        embeddings-backend-auth="system-assigned" />
</inbound>
<outbound>
    <base />
    <llm-semantic-cache-store duration="3600" />
</outbound>
```

**制約条件:** セマンティックキャッシュはAzure Managed Redis（RediSearch対応）が必要です。また、`score-threshold`を低く設定しすぎると、意味的に異なるプロンプトに対して不適切なキャッシュ応答が返る可能性があります。FAQ的な用途（同じ質問が繰り返されるケース）では有効ですが、クリエイティブなテキスト生成タスクには向きません。

## まとめと次のステップ

**まとめ:**
- Azure OpenAIの負荷分散は、**トポロジ（単一インスタンス〜マルチリージョン）に応じてゲートウェイの構成レベルを選定**するのが基本方針
- API ManagementのAI Gatewayが2026年時点の推奨技術であり、**バックエンドプール + Circuit Breaker + トークンレート制限**の3つがコア機能
- PTU + PAYGのPriority-basedスピルオーバー構成が、**コスト最適化と可用性のバランス**を取る定番パターン
- Global Standard / Data Zoneデプロイメントタイプの活用で、自前の負荷分散構成を簡素化できるケースがある
- Front DoorよりもAPI ManagementのAI Gatewayを直接利用する構成が、Azure OpenAIのプロトコルに最適化されている

**次にやるべきこと:**
- [Azure OpenAI Capacity Calculator](https://oai.azure.com/portal/calculator)で現在のトラフィックパターンに基づくPTU量を算出する
- API ManagementのAI Gateway Labsリポジトリ（[azure-samples/ai-gateway](https://github.com/Azure-Samples/ai-gateway)）でハンズオンを実施する
- データ主権要件を確認し、Global Standard / Data Zone / Standardの判断を行う

## 関連する深掘り記事

この記事に関連する1次情報（論文・企業テックブログ）の詳細解説です。

- [Microsoft Production-grade API Gateway Patterns for GenAI Workloads 解説](https://0h-n0.github.io/posts/techblog-microsoft-production-api-gateway-patterns/) — Microsoft Foundry向け5つのAPIゲートウェイパターンの詳細分析
- [Azure API Management Circuit Breaker & Load Balancing 解説](https://0h-n0.github.io/posts/techblog-microsoft-apim-circuit-breaker-lb/) — Circuit Breaker設定とバックエンドプール構成の実装詳細
- [論文解説: Llumnix — Dynamic Scheduling for LLM Inference (arXiv:2401.12843)](https://0h-n0.github.io/posts/paper-2401-12843/) — LLM推論の動的スケジューリングとKVキャッシュライブマイグレーション
- [Azure OpenAI PTU Best Practices 解説](https://0h-n0.github.io/posts/techblog-microsoft-ptu-best-practices/) — PTU容量計画とスピルオーバー戦略の運用ベストプラクティス
- [論文解説: DistServe — Prefill/Decode Disaggregation (arXiv:2403.02310)](https://0h-n0.github.io/posts/paper-2403-02310/) — Prefill/Decode分離によるLLM推論最適化とGoodputメトリクス

## 参考

- [AI gateway in Azure API Management（Microsoft Learn）](https://learn.microsoft.com/en-us/azure/api-management/genai-gateway-capabilities)
- [Use a gateway in front of multiple Azure OpenAI deployments or instances（Azure Architecture Center）](https://learn.microsoft.com/en-us/azure/architecture/ai-ml/guide/azure-openai-gateway-multi-backend)
- [Azure API Management - Unified AI Gateway Design Pattern（Microsoft Community Hub）](https://techcommunity.microsoft.com/blog/integrationsonazureblog/azure-api-management---unified-ai-gateway-design-pattern/4495436)
- [Smart load balancing for OpenAI endpoints and Azure API Management（Microsoft Community Hub）](https://techcommunity.microsoft.com/blog/fasttrackforazureblog/smart-load-balancing-for-openai-endpoints-and-azure-api-management/3991616)
- [Understanding deployment types in Microsoft Foundry Models（Microsoft Learn）](https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-models/concepts/deployment-types)
- [Provisioned throughput unit costs and billing（Microsoft Learn）](https://learn.microsoft.com/en-us/azure/ai-foundry/openai/how-to/provisioned-throughput-onboarding)
- [1年間運用したAzure OpenAI Serviceの負荷分散構成の紹介（EmotionTechテックブログ）](https://tech.emotion-tech.co.jp/entry/2024/10/31/120000)

---

:::message
この記事はAI（Claude Code）により自動生成されました。内容の正確性については複数の情報源で検証していますが、実際の利用時は公式ドキュメントもご確認ください。
:::
