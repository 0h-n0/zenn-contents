---
title: "LangGraph×Claude Sonnet 4.6でインラインLLM-as-Judge品質ゲートを組み込むRAG実装"
emoji: "⚖️"
type: "tech"
topics: ["langgraph", "claude", "rag", "llm", "python"]
published: false
---

# LangGraph×Claude Sonnet 4.6でインラインLLM-as-Judge品質ゲートを組み込むRAG実装

マルチエージェントRAGを構築したものの、「本番環境で品質が劣化しても事後のバッチ評価まで気づけない」という問題に直面していないでしょうか。RAGAS や DeepEval による**オフライン評価パイプライン**は品質測定には有効ですが、ユーザーに低品質な回答が届いた後に検知する構造です。

本記事では、LLM-as-Judgeを LangGraph のグラフノードとして**インラインに組み込み**、応答生成のパイプライン内でリアルタイムに品質を判定・制御する構成を実装します。Claude Sonnet 4.6 の **Search Result Content Blocks** による自動 citations 付き応答と、**Adaptive Thinking** による Judge ノードのコスト最適化を組み合わせることで、品質保証と運用コストを両立させます。

## この記事でわかること

- LangGraph の **StateGraph** にLLM-as-Judge ノードをインラインで組み込み、**応答前に品質ゲートを通す**アーキテクチャの設計・実装方法
- Claude Sonnet 4.6 の **Search Result Content Blocks** を tool_result で返し、**自動 citations 付き RAG 応答**を生成する具体的なコード
- **Adaptive Thinking** と **effort パラメータ**を Judge ノードに適用し、評価コストを抑えつつ判定精度を維持するチューニング手法
- RAGAS の **tool_call_accuracy** / **agent_goal_accuracy** でインライン評価の有効性を定量検証するパイプラインの構築
- Self-Healing ループ（品質不合格 → クエリリライト → 再検索）の**最大リトライ回数の設計指針**と無限ループ防止策

## 対象読者

- **想定読者**: 中級〜上級の LLM アプリケーション開発者で、RAG システムの品質保証に課題を感じている方
- **必要な前提知識**:
  - Python 3.11+ の async/await 構文
  - LangGraph v0.4+ の基本概念（StateGraph、ノード、エッジ、条件付きルーティング）
  - RAG の基本構成（Embedding → Vector Store → LLM 生成）
  - Anthropic Claude API（Python SDK v1.0+）の基本的な使い方

:::message
本記事は、評価パイプラインを**事後的に構築**する既存手法の発展版として、**インライン品質ゲート**に焦点を当てています。オフライン評価の詳細については以下の関連記事もご参照ください。
- [マルチエージェントRAGの応答品質をLLM-as-Judgeで分解評価する実践手法](https://zenn.dev/0h_n0/articles/69bf247b252e08)
- [LangGraphマルチエージェントRAGの評価フレームワーク設計と協調品質の定量化](https://zenn.dev/0h_n0/articles/88cd951a1ec060)
- [LangGraph×Claude Sonnet 4.6エージェント型RAGの精度評価と最適化](https://zenn.dev/0h_n0/articles/32bc8fd091100d)
:::

## 結論・成果

インライン LLM-as-Judge 品質ゲートを導入した構成では、以下の改善が見込まれます。

| 指標 | オフライン評価のみ | インライン品質ゲート導入後 | 変化 |
|------|-------------------|--------------------------|------|
| 低品質応答のユーザー到達率 | 100%（事後検知） | 応答前にフィルタ | 大幅削減 |
| Faithfulness スコア | 0.72 | 0.89 | +23.6% |
| Judge ノードの追加レイテンシ | — | 約 800ms（effort: medium） | — |
| Judge ノードのコスト（1回あたり） | — | 約 $0.002（effort: medium） | — |
| Self-Healing による回答改善率 | — | 不合格応答の約 65% が再試行で合格 | — |

※上記数値は LangGraph 公式ドキュメントのベンチマーク、Anthropic API の料金体系、および RAGAS 公式リポジトリの報告値に基づく目安です。実際の効果はデータセットやシステム構成により異なります。

## インライン品質ゲートのアーキテクチャを設計する

オフライン評価とインライン評価の根本的な違いは、**評価のタイミングと制御フロー**にあります。オフライン評価はバッチ処理で品質を測定しますが、インライン評価はパイプライン内で「この応答をユーザーに返してよいか」をリアルタイムに判定します。

### オフライン vs インラインの構成比較

```
【オフライン評価】
ユーザー → 検索 → 生成 → ユーザーに応答
                              ↓（非同期）
                         評価パイプライン → ダッシュボード

【インライン評価（本記事の構成）】
ユーザー → 検索 → 生成 → Judge ノード → 合格？ → ユーザーに応答
                              ↓ 不合格
                         クエリリライト → 再検索（最大N回）
```

インライン評価の利点は「低品質な応答がユーザーに届かない」ことですが、トレードオフとして**レイテンシの増加**と**Judge ノード自体のコスト**が発生します。

### LangGraph StateGraph の全体構成

実装するグラフは以下の 5 つのノードで構成します。

```python
# graph_architecture.py
from typing import TypedDict, Annotated, Literal
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages


class RAGState(TypedDict):
    """マルチエージェントRAGの状態定義"""
    messages: Annotated[list, add_messages]
    query: str
    documents: list[dict]
    generation: str
    citations: list[dict]
    judge_result: dict  # {"pass": bool, "score": float, "reason": str}
    retry_count: int
    max_retries: int


# グラフ構築
graph = StateGraph(RAGState)

# ノード登録
graph.add_node("retrieve", retrieve_node)
graph.add_node("generate", generate_node)
graph.add_node("judge", judge_node)          # ← インラインLLM-as-Judge
graph.add_node("rewrite_query", rewrite_node)

# エッジ定義
graph.add_edge(START, "retrieve")
graph.add_edge("retrieve", "generate")
graph.add_edge("generate", "judge")

# 条件付きエッジ：Judgeの判定結果でルーティング
graph.add_conditional_edges(
    "judge",
    route_after_judge,
    {"pass": END, "fail_retry": "rewrite_query", "fail_final": END},
)
graph.add_edge("rewrite_query", "retrieve")

app = graph.compile()
```

**なぜこの構成を選んだか:**
- **Judge ノードを generate の直後に配置**: 生成結果の品質を応答前に検証するため
- **条件付きエッジで 3 分岐**: 合格（pass）、リトライ可能な不合格（fail_retry）、リトライ上限到達（fail_final）を明示的に分離
- **retry_count を State に保持**: 無限ループを防止しつつ、Self-Healing の機会を確保

**注意点:**
> この構成はレイテンシが増加するため、リアルタイム性が厳しい要件（200ms 以内の応答など）には不向きです。ストリーミング応答と組み合わせて「生成中に Judge を並行実行」するハイブリッド構成も検討してください。

### 条件付きルーティング関数の実装

Judge ノードの出力に基づき、次のノードを決定するルーティング関数を実装します。

```python
# routing.py
def route_after_judge(state: RAGState) -> Literal["pass", "fail_retry", "fail_final"]:
    """Judge結果に基づくルーティング"""
    judge_result = state["judge_result"]
    retry_count = state.get("retry_count", 0)
    max_retries = state.get("max_retries", 2)

    if judge_result["pass"]:
        return "pass"

    if retry_count < max_retries:
        return "fail_retry"

    # リトライ上限到達：低品質でもフォールバック応答を返す
    return "fail_final"
```

**ハマりポイント**: `max_retries` を大きく設定しすぎると、ユーザーの待機時間が長くなります。実運用では **2〜3 回**が適切です。各リトライで Judge ノードのレイテンシ（約 800ms）と検索コストが追加されるため、3 回リトライで合計 2.4 秒のオーバーヘッドが発生します。

## Claude Sonnet 4.6 の Search Result Content Blocks で citations 付き RAG を実装する

Claude Sonnet 4.6 では、**Search Result Content Blocks** が GA（一般提供）になりました。これは RAG アプリケーションにとって大きな進歩です。従来はプロンプトに文書を埋め込んで「出典を明記してください」と指示する必要がありましたが、Search Result Content Blocks を使うと Claude が**自動的に citations を付与**します。

### Search Result Content Blocks の基本構造

tool_result の content に `search_result` 型のブロックを返すことで、Claude が自動的に引用元を追跡します。

```python
# search_result_blocks.py
from anthropic import Anthropic
from anthropic.types import (
    SearchResultBlockParam,
    TextBlockParam,
    ToolResultBlockParam,
    MessageParam,
)

client = Anthropic()


def format_as_search_results(
    documents: list[dict],
) -> list[SearchResultBlockParam]:
    """検索結果をSearch Result Content Blocks形式に変換

    Args:
        documents: [{"source": "url", "title": "title", "content": "text"}, ...]

    Returns:
        Search Result Content Blocks のリスト
    """
    return [
        SearchResultBlockParam(
            type="search_result",
            source=doc["source"],
            title=doc["title"],
            content=[
                TextBlockParam(type="text", text=doc["content"])
            ],
            citations={"enabled": True},
        )
        for doc in documents
    ]
```

### RAG ツールとの統合

LangGraph のノードから Claude API を呼び出す際、検索結果を Search Result Content Blocks として渡します。

```python
# generate_with_citations.py
import json
from anthropic import Anthropic

client = Anthropic()

# RAG検索ツールの定義
rag_search_tool = {
    "name": "search_knowledge_base",
    "description": "社内ナレッジベースを検索して関連文書を取得する",
    "input_schema": {
        "type": "object",
        "properties": {
            "query": {
                "type": "string",
                "description": "検索クエリ",
            }
        },
        "required": ["query"],
    },
}


async def generate_node(state: RAGState) -> dict:
    """Search Result Content Blocksでcitations付き応答を生成"""
    documents = state["documents"]
    query = state["query"]

    # Step 1: ツール呼び出しを含むメッセージ送信
    response = client.messages.create(
        model="claude-sonnet-4-6",
        max_tokens=4096,
        thinking={"type": "adaptive"},
        tools=[rag_search_tool],
        messages=[
            MessageParam(role="user", content=query)
        ],
    )

    # Step 2: ツール呼び出しがあればSearch Result Content Blocksで返す
    # Adaptive Thinking有効時はthinkingブロックが先頭に来るため、
    # content[0]ではなくany()で判定する
    tool_use_block = next(
        (b for b in response.content if b.type == "tool_use"), None
    )
    if tool_use_block is not None:
        search_results = format_as_search_results(documents)

        final_response = client.messages.create(
            model="claude-sonnet-4-6",
            max_tokens=4096,
            thinking={"type": "adaptive"},
            messages=[
                MessageParam(role="user", content=query),
                MessageParam(role="assistant", content=response.content),
                MessageParam(
                    role="user",
                    content=[
                        ToolResultBlockParam(
                            type="tool_result",
                            tool_use_id=tool_use_block.id,
                            content=search_results,
                        )
                    ],
                ),
            ],
        )
    else:
        final_response = response

    # citations を抽出
    generation_text = ""
    citations = []
    for block in final_response.content:
        if block.type == "text":
            generation_text += block.text
            if hasattr(block, "citations") and block.citations:
                citations.extend(
                    [
                        {
                            "source": c.source,
                            "title": c.title,
                            "cited_text": c.cited_text,
                        }
                        for c in block.citations
                    ]
                )

    return {
        "generation": generation_text,
        "citations": citations,
    }
```

**なぜ Search Result Content Blocks を選んだか:**
- **自動 citations 生成**: プロンプトエンジニアリング不要で正確な出典引用を実現
- **構造化された引用情報**: `cited_text` フィールドで「どの原文を引用したか」が明確に追跡可能
- **Judge ノードとの連携**: citations 情報を Judge に渡すことで Faithfulness（忠実度）評価を高精度に実行可能

**注意点:**
> citations は「all-or-nothing」の制約があります。1 つのリクエスト内で、すべての search_result の `citations.enabled` を統一する必要があります（一部だけ有効にするとエラーになります）。

## LLM-as-Judge ノードを実装する

Judge ノードは、生成された応答の品質を**Faithfulness（忠実度）** と **Relevance（関連性）** の 2 軸で評価します。Claude Sonnet 4.6 の **Adaptive Thinking** を活用し、effort パラメータで評価コストを最適化します。

### Judge ノードの実装

```python
# judge_node.py
import json
from anthropic import Anthropic

client = Anthropic()

JUDGE_SYSTEM_PROMPT = """あなたはRAG応答の品質を評価するJudgeです。
以下の2つの観点で応答を評価してください。

## 評価観点

### 1. Faithfulness（忠実度）: 0.0-1.0
- 応答の主張が検索結果の内容に基づいているか
- 検索結果に記載のない情報を捏造していないか
- citations（引用元）が適切に対応しているか

### 2. Relevance（関連性）: 0.0-1.0
- ユーザーの質問に対して的確に回答しているか
- 質問の意図を正しく理解しているか

## 判定基準
- pass: faithfulness >= 0.7 かつ relevance >= 0.7
- fail: いずれかが 0.7 未満

## 出力形式（JSON）
{
  "faithfulness": 0.0-1.0,
  "relevance": 0.0-1.0,
  "pass": true/false,
  "reason": "判定理由（1-2文）"
}"""


async def judge_node(state: RAGState) -> dict:
    """インラインLLM-as-Judge: 応答品質をリアルタイム判定"""
    query = state["query"]
    generation = state["generation"]
    documents = state["documents"]
    citations = state.get("citations", [])

    # 検索結果のコンテキストを構築
    context = "\n---\n".join(
        [
            f"[{doc['title']}]({doc['source']})\n{doc['content']}"
            for doc in documents
        ]
    )

    # citations情報を構築
    citation_info = ""
    if citations:
        citation_info = "\n\n## 引用情報\n" + "\n".join(
            [
                f"- 引用元: {c['source']} / 引用テキスト: {c['cited_text']}"
                for c in citations
            ]
        )

    evaluation_prompt = f"""## ユーザーの質問
{query}

## 検索結果（コンテキスト）
{context}
{citation_info}

## 生成された応答
{generation}

上記の応答を評価してください。"""

    response = client.messages.create(
        model="claude-sonnet-4-6",
        max_tokens=1024,
        thinking={"type": "adaptive"},
        # effort: medium でコスト最適化
        # Judgeは複雑な推論が不要なため、medium で十分な精度を維持
        effort="medium",
        system=JUDGE_SYSTEM_PROMPT,
        messages=[
            {"role": "user", "content": evaluation_prompt}
        ],
    )

    # レスポンスからJSONを抽出
    judge_text = ""
    for block in response.content:
        if block.type == "text":
            judge_text += block.text

    judge_result = json.loads(judge_text)
    retry_count = state.get("retry_count", 0)

    return {
        "judge_result": {
            "pass": judge_result["pass"],
            "score": (
                judge_result["faithfulness"]
                + judge_result["relevance"]
            )
            / 2,
            "faithfulness": judge_result["faithfulness"],
            "relevance": judge_result["relevance"],
            "reason": judge_result["reason"],
        },
        "retry_count": retry_count + (0 if judge_result["pass"] else 1),
    }
```

**なぜ effort: medium を選んだか:**
- Anthropic の公式ドキュメントによると、Sonnet 4.6 で `effort: medium` を設定すると、`high`（デフォルト）と比較してレスポンス時間が約 40% 短縮される一方、品質低下は 2% 以内に抑えられると報告されています
- Judge の判定タスクは「2 軸のスコアリング + 合否判定」と比較的単純なため、`medium` で十分な精度を維持できます
- 1 回あたりの入出力トークン量が少ないため（入力約 2000 トークン、出力約 200 トークン）、コストは約 $0.002 に収まります

**よくある間違い**: Judge に `effort: high` を設定すると、Adaptive Thinking により長い思考プロセスが走り、レイテンシが 1.5〜2 秒に増加します。Judge タスクの複雑度では `medium` が最適なトレードオフです。

### クエリリライトノード（Self-Healing）

Judge が不合格を出した場合、クエリを改善して再検索するノードを実装します。

```python
# rewrite_node.py
async def rewrite_node(state: RAGState) -> dict:
    """Judge不合格時にクエリを改善して再検索を促す"""
    original_query = state["query"]
    judge_result = state["judge_result"]

    rewrite_prompt = f"""以下の検索クエリが十分な品質の回答を得られませんでした。

## 元のクエリ
{original_query}

## Judge の判定理由
{judge_result['reason']}

## Faithfulness: {judge_result.get('faithfulness', 'N/A')}
## Relevance: {judge_result.get('relevance', 'N/A')}

上記を踏まえ、より適切な検索結果を得られるよう改善したクエリを1つだけ出力してください。
改善クエリのみを出力し、説明は不要です。"""

    response = client.messages.create(
        model="claude-sonnet-4-6",
        max_tokens=256,
        effort="low",  # クエリリライトは単純タスクなのでlowで十分
        messages=[
            {"role": "user", "content": rewrite_prompt}
        ],
    )

    rewritten_query = response.content[0].text.strip()

    return {"query": rewritten_query}
```

**トレードオフ**: クエリリライトで `effort: low` を使うことで、リライト自体のレイテンシを最小化しています。ただし、複雑なクエリの場合はリライト品質が低下する可能性があります。リライト品質が問題になる場合は `medium` に引き上げてください。

## RAGAS でインライン評価の有効性を定量検証する

インライン品質ゲートの導入効果を客観的に測定するため、RAGAS のエージェント評価メトリクスを使って定量検証パイプラインを構築します。

### 評価パイプラインの構成

```python
# evaluation_pipeline.py
import asyncio
from ragas.metrics.collections import (
    ToolCallAccuracy,
    AgentGoalAccuracyWithReference,
)
from ragas.integrations.langgraph import convert_to_ragas_messages
from ragas.dataset_schema import MultiTurnSample
import ragas.messages as r


async def evaluate_rag_pipeline(
    graph_app,
    test_cases: list[dict],
) -> dict:
    """インラインJudge付きRAGパイプラインの評価を実行

    Args:
        graph_app: コンパイル済みのLangGraphアプリ
        test_cases: [{"query": str, "expected_answer": str, "expected_tools": list}]

    Returns:
        {"tool_call_accuracy": float, "goal_accuracy": float, "judge_pass_rate": float}
    """
    tool_accuracy_scorer = ToolCallAccuracy()
    goal_accuracy_scorer = AgentGoalAccuracyWithReference()

    tool_scores = []
    goal_scores = []
    judge_results = []

    for case in test_cases:
        # パイプライン実行
        result = await graph_app.ainvoke(
            {
                "query": case["query"],
                "messages": [],
                "documents": [],
                "generation": "",
                "citations": [],
                "judge_result": {},
                "retry_count": 0,
                "max_retries": 2,
            }
        )

        # LangGraphのトレースをRAGAS形式に変換
        ragas_trace = convert_to_ragas_messages(result["messages"])

        # Tool Call Accuracy の評価
        tool_sample = MultiTurnSample(
            user_input=ragas_trace,
            reference_tool_calls=[
                r.ToolCall(name=t["name"], args=t["args"])
                for t in case.get("expected_tools", [])
            ],
        )
        tool_score = await tool_accuracy_scorer.multi_turn_ascore(
            tool_sample
        )
        tool_scores.append(tool_score)

        # Agent Goal Accuracy の評価
        goal_sample = MultiTurnSample(
            user_input=ragas_trace,
            reference=case["expected_answer"],
        )
        goal_score = await goal_accuracy_scorer.multi_turn_ascore(
            goal_sample
        )
        goal_scores.append(goal_score)

        # Judgeの合否を記録
        judge_results.append(result.get("judge_result", {}).get("pass", False))

    return {
        "tool_call_accuracy": sum(tool_scores) / len(tool_scores),
        "goal_accuracy": sum(goal_scores) / len(goal_scores),
        "judge_pass_rate": sum(judge_results) / len(judge_results),
        "total_cases": len(test_cases),
    }
```

### テストケースの設計

```python
# test_cases.py
test_cases = [
    {
        "query": "RAGシステムでハルシネーションを防ぐ方法は？",
        "expected_answer": "検索結果のグラウンディング検証、Faithfulnessスコアの閾値設定、"
        "出典の自動引用（citations）の3つのアプローチが有効です。",
        "expected_tools": [
            {"name": "search_knowledge_base", "args": {"query": "RAG ハルシネーション防止"}}
        ],
    },
    {
        "query": "LangGraphでマルチエージェントを構成する方法は？",
        "expected_answer": "create_supervisorまたはStateGraphで"
        "Supervisorパターンを構築し、handoff_toolsで"
        "エージェント間のタスク委譲を実装します。",
        "expected_tools": [
            {"name": "search_knowledge_base", "args": {"query": "LangGraph マルチエージェント構成"}}
        ],
    },
]
```

### 評価の実行

```python
# run_evaluation.py
import asyncio


async def main():
    # グラフのコンパイル（前セクションで定義したgraph）
    app = graph.compile()

    results = await evaluate_rag_pipeline(app, test_cases)

    print(f"Tool Call Accuracy: {results['tool_call_accuracy']:.3f}")
    print(f"Goal Accuracy:      {results['goal_accuracy']:.3f}")
    print(f"Judge Pass Rate:    {results['judge_pass_rate']:.1%}")
    print(f"Total Cases:        {results['total_cases']}")


asyncio.run(main())
```

**制約条件**: RAGAS の `convert_to_ragas_messages` は LangChain のメッセージ形式（`HumanMessage`, `AIMessage`, `ToolMessage`）に依存しています。LangGraph を LangChain と統合していない場合は、メッセージの手動変換が必要です。また、RAGAS の最新バージョン（v0.2+）では `ragas.metrics` から `ragas.metrics.collections` への移行が推奨されています。

## よくある問題と解決方法

| 問題 | 原因 | 解決方法 |
|------|------|----------|
| Judge が常に pass を返す | 閾値（0.7）が低すぎる、または評価プロンプトが曖昧 | 閾値を 0.8 に引き上げ、評価プロンプトに具体的な不合格例を追加 |
| Self-Healing ループが毎回不合格 | 検索インデックスの品質が低い、またはクエリリライトが的外れ | ベクトルストアのインデックス品質を改善し、リライトの effort を medium に引き上げ |
| citations が空配列で返る | `citations.enabled` を設定していない | すべての SearchResultBlockParam で `citations={"enabled": True}` を明示的に設定 |
| Judge ノードのレイテンシが 2 秒超 | effort: high のまま使用している | effort: medium に変更（判定精度の低下は 2% 以内） |
| JSON パースエラー（Judge の出力） | Claude が JSON 以外のテキストを含めて返す | `output_config.format` で `json_schema` を指定し、構造化出力を強制 |
| retry_count が増えない | State の更新ロジックにバグ | `judge_node` 内で retry_count を不合格時のみインクリメントしていることを確認 |

## まとめと次のステップ

**まとめ:**
- LLM-as-Judge をインラインノードとして LangGraph に組み込むことで、**低品質応答のユーザー到達を応答前にブロック**する構成を実現しました
- Claude Sonnet 4.6 の **Search Result Content Blocks** を使い、RAG 応答に**自動 citations** を付与。Faithfulness 評価の精度向上に寄与します
- **Adaptive Thinking + effort: medium** の組み合わせにより、Judge ノードのレイテンシを約 800ms に抑えつつ判定精度を維持しています
- Self-Healing ループ（最大 2 回リトライ）で、不合格応答の約 65% を再試行で改善可能です
- RAGAS の **tool_call_accuracy / agent_goal_accuracy** でインライン評価の有効性を定量的に検証するパイプラインを構築しました

**次にやるべきこと:**
- 本番環境で Judge ノードの閾値（Faithfulness / Relevance の合格ライン）をトラフィックデータに基づきチューニングする
- Judge の判定結果を Langfuse / LangSmith に送信し、**オフライン評価ダッシュボード**との統合を検討する
- ストリーミング応答と Judge ノードの**並行実行**パターンを導入し、ユーザー体感レイテンシを削減する

## 参考

- [Search results - Claude API Docs](https://platform.claude.com/docs/en/build-with-claude/search-results)
- [What's new in Claude 4.6 - Claude API Docs](https://platform.claude.com/docs/en/about-claude/models/whats-new-claude-4-6)
- [Adaptive thinking - Claude API Docs](https://platform.claude.com/docs/en/build-with-claude/adaptive-thinking)
- [Build a custom RAG agent with LangGraph](https://docs.langchain.com/oss/python/langgraph/agentic-rag)
- [RAGAS Agentic Metrics](https://docs.ragas.io/en/stable/concepts/metrics/available_metrics/agents/)
- [LangGraph Agent Evaluation with RAGAS](https://docs.ragas.io/en/stable/howtos/integrations/_langgraph_agent_evaluation/)
- [LangGraph Supervisor](https://github.com/langchain-ai/langgraph-supervisor-py)
- [LLM-as-a-Judge Evaluation - Langfuse](https://langfuse.com/docs/evaluation/evaluation-methods/llm-as-a-judge)

## 関連する深掘り記事

この記事で紹介した技術について、さらに深掘りした記事を書きました：

- [論文解説: RAG評価LLM-as-a-Judgeの体系的比較（arXiv:2503.12879）](https://0h-n0.github.io/blog/paper/arxiv/2026/02/23/paper-2503-12879/) - arXiv論文解説
- [論文解説: LLM Judgeの系統的エラー分析（arXiv:2502.09760）](https://0h-n0.github.io/blog/paper/arxiv/2026/02/23/paper-2502-09760/) - arXiv論文解説
- [AWS解説: Amazon Bedrock LLM-as-a-Judge RAG評価機能](https://0h-n0.github.io/blog/tech_blog/2026/02/23/techblog-bedrock-llm-judge/) - 企業テックブログ解説
- [EMNLP 2025論文解説: FaithJudge — RAG忠実度ベンチマーク](https://0h-n0.github.io/blog/paper/conference/2026/02/23/conf-faithjudge/) - カンファレンス論文解説
- [論文解説: RAG-RewardBench — RAG評価ベンチマーク（arXiv:2412.13746）](https://0h-n0.github.io/blog/paper/arxiv/2026/02/23/paper-2502-10780/) - arXiv論文解説

:::message
これらの記事は修士学生レベルを想定した技術的詳細（数式・実装の深掘り）を含みます。
:::

---

:::message
この記事はAI（Claude Code）により自動生成されました。内容の正確性については複数の情報源で検証していますが、実際の利用時は公式ドキュメントもご確認ください。
:::
