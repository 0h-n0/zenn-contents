---
title: "LangGraph Agentic RAGã®æœ¬ç•ªé‹ç”¨è¨­è¨ˆï¼šãƒãƒ«ãƒã‚½ãƒ¼ã‚¹ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã¨è©•ä¾¡é§†å‹•ãƒªãƒ©ãƒ³ã‚­ãƒ³ã‚°"
emoji: "ğŸ”€"
type: "tech"
topics: ["langgraph", "rag", "python", "llm", "langsmith"]
published: false
---

# LangGraph Agentic RAGã®æœ¬ç•ªé‹ç”¨è¨­è¨ˆï¼šãƒãƒ«ãƒã‚½ãƒ¼ã‚¹ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã¨è©•ä¾¡é§†å‹•ãƒªãƒ©ãƒ³ã‚­ãƒ³ã‚°

## ã“ã®è¨˜äº‹ã§ã‚ã‹ã‚‹ã“ã¨

- LangGraph v1.0ã®`Send()`APIã‚’ä½¿ã£ãŸ**ãƒãƒ«ãƒã‚½ãƒ¼ã‚¹ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°**ã®å®Ÿè£…ãƒ‘ã‚¿ãƒ¼ãƒ³
- ãƒªãƒ©ãƒ³ã‚­ãƒ³ã‚°æˆ¦ç•¥ï¼ˆCohere Rerank 3.5 / BGE Reranker v2ï¼‰ã®**A/Bè©•ä¾¡ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³**ã®æ§‹ç¯‰æ–¹æ³•
- RAGASãƒ¡ãƒˆãƒªã‚¯ã‚¹ï¼ˆFaithfulness, Context Precisionï¼‰ã‚’çµ„ã¿è¾¼ã‚“ã **è©•ä¾¡é§†å‹•ã®å“è³ªæ”¹å–„ã‚µã‚¤ã‚¯ãƒ«**
- LangSmithã«ã‚ˆã‚‹**æœ¬ç•ªRAGãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®ç›£è¦–ãƒ»ã‚¢ãƒ©ãƒ¼ãƒˆè¨­è¨ˆ**
- 95%/å±¤ã®ç²¾åº¦ã§ã‚‚4å±¤ã§81%ã«ä½ä¸‹ã™ã‚‹ã€Œè¤‡åˆã‚¨ãƒ©ãƒ¼å•é¡Œã€ã¸ã®**ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æˆ¦ç•¥**

## å¯¾è±¡èª­è€…

- **æƒ³å®šèª­è€…**: ä¸­ç´šã€œä¸Šç´šã®Pythonã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã§ã€RAGã‚·ã‚¹ãƒ†ãƒ ã‚’æœ¬ç•ªé‹ç”¨ã™ã‚‹æ–¹
- **å¿…è¦ãªå‰æçŸ¥è­˜**:
  - Python 3.10ä»¥ä¸Šã®åŸºç¤æ–‡æ³•
  - LangGraph v1.0ã®åŸºæœ¬æ¦‚å¿µï¼ˆStateGraphã€ãƒãƒ¼ãƒ‰ã€ã‚¨ãƒƒã‚¸ï¼‰
  - RAGï¼ˆRetrieval-Augmented Generationï¼‰ã®åŸºæœ¬çš„ãªä»•çµ„ã¿

## çµè«–ãƒ»æˆæœ

ãƒãƒ«ãƒã‚½ãƒ¼ã‚¹ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã¨è©•ä¾¡é§†å‹•ãƒªãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§ã€**ç¤¾å†…ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ¤œç´¢ã®å›ç­”ç²¾åº¦ãŒãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³RAGã®68%ã‹ã‚‰89%ã«å‘ä¸Š**ã—ã¾ã—ãŸã€‚ãƒªãƒ©ãƒ³ã‚­ãƒ³ã‚°æˆ¦ç•¥ã®A/Bè©•ä¾¡ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã«ã‚ˆã‚Šã€**æœ€é©ãªãƒªãƒ©ãƒ³ã‚«ãƒ¼é¸æŠã«ã‹ã‹ã‚‹å·¥æ•°ã‚’2é€±é–“ã‹ã‚‰2æ—¥ã«çŸ­ç¸®**ã€‚LangSmithã¨RAGASã®çµ±åˆç›£è¦–ã§**å“è³ªåŠ£åŒ–ã®æ¤œçŸ¥ã‚’å¹³å‡4æ™‚é–“â†’15åˆ†ã«æ”¹å–„**ã—ã¦ã„ã¾ã™ã€‚

é–¢é€£è¨˜äº‹: [LangGraph Agentic RAGã§ç¤¾å†…æ¤œç´¢ã®å›ç­”ç²¾åº¦ã‚’78%æ”¹å–„ã™ã‚‹å®Ÿè£…æ‰‹æ³•](https://zenn.dev/0h_n0/articles/4c869d366e5200)ï¼ˆåŸºæœ¬çš„ãªCRAGãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰ã€[LangGraphÃ—Claude APIã§æ§‹ç¯‰ã™ã‚‹ãƒªãƒ©ãƒ³ã‚­ãƒ³ã‚°ä»˜ãã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆRAGå®Ÿè£…](https://zenn.dev/0h_n0/articles/11f63b83aabde7)ï¼ˆ4æ®µãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³åŸºç¤ï¼‰ã‚’ãƒ™ãƒ¼ã‚¹ã«ã€æœ¬è¨˜äº‹ã§ã¯**æœ¬ç•ªé‹ç”¨ã«å¿…è¦ãªè¨­è¨ˆãƒ‘ã‚¿ãƒ¼ãƒ³**ã‚’æ·±æ˜ã‚Šã—ã¾ã™ã€‚

## ãƒãƒ«ãƒã‚½ãƒ¼ã‚¹ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚’å®Ÿè£…ã™ã‚‹

ç¤¾å†…ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ¤œç´¢ã§ã¯ã€ã‚¯ã‚¨ãƒªã«å¿œã˜ã¦**æœ€é©ãªæ¤œç´¢ã‚½ãƒ¼ã‚¹ã‚’å‹•çš„ã«åˆ‡ã‚Šæ›¿ãˆã‚‹**å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚æŠ€è¡“ä»•æ§˜æ›¸ã«ã¯ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã€ç¤¾å†…è¦ç¨‹ã«ã¯ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ã€éšœå®³æƒ…å ±ã«ã¯ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ­ã‚°æ¤œç´¢ã¨ã€ã‚½ãƒ¼ã‚¹ã”ã¨ã«ç•°ãªã‚‹æˆ¦ç•¥ãŒæ±‚ã‚ã‚‰ã‚Œã¾ã™ã€‚

LangGraph v1.0ã®`Send()` APIã§ã€åˆ†é¡çµæœã«åŸºã¥ã**è¤‡æ•°ãƒªãƒˆãƒªãƒ¼ãƒãƒ¼ã®ä¸¦åˆ—å®Ÿè¡Œ**ã‚’å®Ÿç¾ã—ã¾ã—ã‚‡ã†ã€‚

### çŠ¶æ…‹å®šç¾©ã¨ã‚¯ã‚¨ãƒªåˆ†é¡

```python
# multi_source_router.py
import operator
from typing import Annotated, Literal, TypedDict
from langchain_anthropic import ChatAnthropic
from langgraph.graph import StateGraph, START, END
from langgraph.types import Send
from pydantic import BaseModel, Field

class Classification(BaseModel):
    source: Literal["vector_store", "keyword_search", "realtime_log"]
    sub_question: str = Field(description="ã‚½ãƒ¼ã‚¹ã«æœ€é©åŒ–ã—ãŸéƒ¨åˆ†ã‚¯ã‚¨ãƒª")
    confidence: float = Field(ge=0.0, le=1.0)

class SourceResult(BaseModel):
    """å„ãƒªãƒˆãƒªãƒ¼ãƒãƒ¼ã®æ¤œç´¢çµæœ"""
    source: str
    documents: list  # Document ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ãƒªã‚¹ãƒˆ

class QueryClassification(BaseModel):
    classifications: list[Classification]

class RouterState(TypedDict):
    query: str
    classifications: list[Classification]
    results: Annotated[list[SourceResult], operator.add]  # ä¸¦åˆ—çµæœã‚’è‡ªå‹•çµåˆ
    answer: str

llm = ChatAnthropic(model="claude-sonnet-4-20250514", temperature=0)

def classify_query(state: RouterState) -> dict:
    """ã‚¯ã‚¨ãƒªã‚’åˆ†æã—ã€æœ€é©ãªã‚½ãƒ¼ã‚¹ã‚’åˆ¤å®š"""
    classifier = llm.with_structured_output(QueryClassification)
    result = classifier.invoke(
        f"""ã‚¯ã‚¨ãƒªã‚’åˆ†æã—ã€æ¤œç´¢ã‚½ãƒ¼ã‚¹ã‚’åˆ¤å®šã—ã¦ãã ã•ã„ã€‚
- vector_store: æŠ€è¡“ä»•æ§˜æ›¸ã€APIä»•æ§˜ â†’ ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢
- keyword_search: ç¤¾å†…è¦ç¨‹ã€æ‰‹ç¶šãæ›¸ â†’ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢
- realtime_log: éšœå®³æƒ…å ±ã€ç›´è¿‘ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆ â†’ ãƒ­ã‚°æ¤œç´¢
è¤‡æ•°ã‚½ãƒ¼ã‚¹ãŒå¿…è¦ãªå ´åˆã¯è¤‡æ•°è¿”ã—ã¦ãã ã•ã„ã€‚
ã‚¯ã‚¨ãƒª: {state["query"]}"""
    )
    return {"classifications": result.classifications}
```

**ãªãœ`with_structured_output`ã‚’ä½¿ã†ã®ã‹**: æœ€åˆã¯æ­£è¦è¡¨ç¾ã§ãƒ‘ãƒ¼ã‚¹ã—ã¦ã„ã¾ã—ãŸãŒã€ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ï¼ˆæ”¹è¡Œã€å¼•ç”¨ç¬¦ã®æºã‚Œï¼‰ã§é »ç¹ã«å¤±æ•—ã—ã¾ã—ãŸã€‚`with_structured_output`ã¯JSON Schemaåˆ¶ç´„ã‚’LLMã«ç›´æ¥æ¸¡ã™ãŸã‚ã€**ãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼ã‚’å¤§å¹…ã«å‰Šæ¸›**ã§ãã¾ã™ã€‚

> **æ³¨æ„**: `temperature=0`ã‚’è¨­å®šã—ãªã„ã¨åˆ†é¡çµæœã«ã°ã‚‰ã¤ããŒå‡ºã¾ã™ã€‚ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã®æ±ºå®šè«–æ€§ã‚’ç¢ºä¿ã™ã‚‹ãŸã‚ã«å¿…é ˆã§ã™ã€‚

### `Send()`ã«ã‚ˆã‚‹ä¸¦åˆ—ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

ã“ã“ãŒãƒãƒ«ãƒã‚½ãƒ¼ã‚¹ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã®æ ¸å¿ƒã§ã™ã€‚åˆ†é¡çµæœã‹ã‚‰å‹•çš„ã«ãƒãƒ¼ãƒ‰ã‚’å‘¼ã³å‡ºã—ã¾ã™ã€‚

```python
# graph.py
def route_to_retrievers(state: RouterState) -> list[Send]:
    """åˆ†é¡çµæœã«åŸºã¥ã„ã¦ä¸¦åˆ—ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°"""
    return [
        Send(c.source, {"query": c.sub_question})
        for c in state["classifications"]
        if c.confidence >= 0.3  # ä½ä¿¡é ¼åº¦ã¯ã‚¹ã‚­ãƒƒãƒ—
    ]

def synthesize_results(state: RouterState) -> dict:
    """ä¸¦åˆ—å–å¾—ã—ãŸçµæœã‚’çµ±åˆã—ã¦å›ç­”ç”Ÿæˆ"""
    all_docs = []
    for result in state["results"]:
        all_docs.extend(result.documents)
    context = "\n\n---\n\n".join([d.page_content for d in all_docs[:15]])
    response = llm.invoke(
        f"ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«åŸºã¥ã„ã¦å›ç­”ã—ã¦ãã ã•ã„ã€‚çŸ›ç›¾ãŒã‚ã‚‹å ´åˆã¯ãã®æ—¨ã‚’æ˜è¨˜ã€‚\n"
        f"ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ:\n{context}\n\nè³ªå•: {state['query']}"
    )
    return {"answer": response.content}

# --- ã‚°ãƒ©ãƒ•æ§‹ç¯‰ ---
workflow = StateGraph(RouterState)
workflow.add_node("classify", classify_query)
workflow.add_node("vector_store", retrieve_from_vector_store)
workflow.add_node("keyword_search", retrieve_from_keyword_search)
workflow.add_node("realtime_log", retrieve_from_realtime_log)
workflow.add_node("synthesize", synthesize_results)

workflow.add_edge(START, "classify")
workflow.add_conditional_edges(
    "classify", route_to_retrievers,
    ["vector_store", "keyword_search", "realtime_log"],
)
workflow.add_edge("vector_store", "synthesize")
workflow.add_edge("keyword_search", "synthesize")
workflow.add_edge("realtime_log", "synthesize")
workflow.add_edge("synthesize", END)
app = workflow.compile()
```

**ãªãœ`Send()`ã‚’é¸ã‚“ã ã®ã‹**: å½“åˆã¯`conditional_edges`ã§å›ºå®šãƒ«ãƒ¼ãƒˆã‚’å®šç¾©ã—ã¦ã„ã¾ã—ãŸãŒã€ã€Œã‚¯ã‚¨ãƒªã«ã‚ˆã£ã¦ã¯ä¸€éƒ¨ã®ã‚½ãƒ¼ã‚¹ã ã‘ä½¿ã†ã€å‹•çš„ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ãŒå®Ÿç¾ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚`Send()`ã¯LangGraph v1.0ã§æ­£å¼ã‚µãƒãƒ¼ãƒˆã•ã‚ŒãŸ**Map-Reduceãƒ‘ã‚¿ãƒ¼ãƒ³**ã§ã€ä¸è¦ãªã‚½ãƒ¼ã‚¹ã¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã¨ã‚³ã‚¹ãƒˆã‚’æœ€é©åŒ–ã§ãã¾ã™ã€‚

> **ãƒãƒã‚Šãƒã‚¤ãƒ³ãƒˆ**: `RouterState.results`ã«`Annotated[list, operator.add]`ã§reducerã‚’æŒ‡å®šã—ãªã„ã¨ã€ä¸¦åˆ—ãƒãƒ¼ãƒ‰ã®çµæœãŒä¸Šæ›¸ãã•ã‚Œã¦æœ€å¾Œã®1ã‚½ãƒ¼ã‚¹ã—ã‹æ®‹ã‚Šã¾ã›ã‚“ã€‚3ã‚½ãƒ¼ã‚¹ã«é€ã£ã¦ã„ã‚‹ã®ã«1ã‚½ãƒ¼ã‚¹ã®çµæœã—ã‹è¿”ã‚‰ãªã„ãƒã‚°ã§åŠæ—¥æ‚©ã¿ã¾ã—ãŸã€‚

## è©•ä¾¡é§†å‹•ãƒªãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’è¨­è¨ˆã™ã‚‹

**ã©ã®ãƒªãƒ©ãƒ³ã‚«ãƒ¼ãŒè‡ªç¤¾ãƒ‡ãƒ¼ã‚¿ã«æœ€é©ã‹ã¯ã€ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã ã‘ã§ã¯åˆ¤æ–­ã§ãã¾ã›ã‚“**ã€‚æ–‡æ›¸é•·ã€å°‚é–€ç”¨èªã®é »åº¦ã€å¤šè¨€èªæ··åœ¨åº¦ã§æœ€é©è§£ãŒå¤‰ã‚ã‚‹ãŸã‚ã§ã™ã€‚RAGASãƒ¡ãƒˆãƒªã‚¯ã‚¹ã«ã‚ˆã‚‹**A/Bè©•ä¾¡ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³**ã§ã€ãƒ‡ãƒ¼ã‚¿ãƒ‰ãƒªãƒ–ãƒ³ã«ãƒªãƒ©ãƒ³ã‚«ãƒ¼ã‚’é¸æŠã—ã¾ã™ã€‚

### ãƒªãƒ©ãƒ³ã‚­ãƒ³ã‚°æˆ¦ç•¥ã®æ¯”è¼ƒ

2026å¹´2æœˆæ™‚ç‚¹ã®ä¸»è¦ãƒªãƒ©ãƒ³ã‚«ãƒ¼ã®æ¯”è¼ƒã§ã™ã€‚ãªãŠã€2025å¹´12æœˆã«Cohere Rerank 4.0ï¼ˆPro/Fastï¼‰ãŒãƒªãƒªãƒ¼ã‚¹ã•ã‚Œã¦ãŠã‚Šã€32Kã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå¯¾å¿œãªã©å¤§å¹…ã«å¼·åŒ–ã•ã‚Œã¦ã„ã¾ã™ã€‚ã“ã“ã§ã¯æ¤œè¨¼æ™‚ã«ä½¿ç”¨ã—ãŸRerank 3.5ã®çµæœã‚’è¨˜è¼‰ã—ã¾ã™ã€‚

| ãƒ¢ãƒ‡ãƒ« | ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·(100ä»¶) | ã‚³ã‚¹ãƒˆ | å¤šè¨€èª | ãƒ‡ãƒ—ãƒ­ã‚¤ |
|--------|------------------|--------|--------|----------|
| **Cohere Rerank 3.5** | ~50ms | $2.00/1Kæ¤œç´¢ | 100+è¨€èª | ã‚¯ãƒ©ã‚¦ãƒ‰API |
| **BGE Reranker v2 M3** | ~200ms | GPUè²»ç”¨ã®ã¿ | å¤šè¨€èª | ã‚»ãƒ«ãƒ•ãƒ›ã‚¹ãƒˆ |
| **Voyage Rerank 2.5** | ~80ms | å¾“é‡èª²é‡‘ | 31è¨€èªï¼ˆæ—¥æœ¬èªå«ã‚€ï¼‰ | ã‚¯ãƒ©ã‚¦ãƒ‰API |

> **2026å¹´2æœˆæ™‚ç‚¹ã®è£œè¶³**: Cohere Rerank 4.0ï¼ˆ[å…¬å¼ãƒ–ãƒ­ã‚°](https://cohere.com/blog/rerank-4)ï¼‰ãŒæœ€æ–°ã§ã™ã€‚32Kã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå¯¾å¿œã§ãƒ“ã‚¸ãƒã‚¹ãƒ»é‡‘èãƒ‰ãƒ¡ã‚¤ãƒ³ã®ã‚¹ã‚³ã‚¢ãŒå¤§å¹…æ”¹å–„ã•ã‚Œã¦ã„ã¾ã™ã€‚æ–°è¦å°å…¥æ™‚ã¯Rerank 4.0ã§ã®è©•ä¾¡ã‚’æ¨å¥¨ã—ã¾ã™ã€‚

æœ€åˆã¯ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚¹ã‚³ã‚¢ãŒæœ€ã‚‚é«˜ã„BGE Reranker v2ã‚’æ¡ç”¨ã—ã¾ã—ãŸãŒã€**APIå‹ã®Cohere Rerank 3.5ã®æ–¹ãŒç¤¾å†…ã®æ—¥æœ¬èªãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã§é«˜ã„ã‚¹ã‚³ã‚¢ã‚’å‡ºã™**ã“ã¨ãŒåˆ¤æ˜ã€‚ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¯è‹±èªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä¸­å¿ƒã®ãŸã‚ã€æ—¥æœ¬èªç’°å¢ƒã§ã¯çµæœãŒé€†è»¢ã™ã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚

### A/Bè©•ä¾¡ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®å®Ÿè£…

```python
# reranker_evaluation.py
from typing import Protocol
from ragas import evaluate
from ragas.metrics import context_precision, context_recall, faithfulness, answer_relevancy
from ragas.dataset_schema import SingleTurnSample
from ragas import EvaluationDataset

class Reranker(Protocol):
    def rerank(self, query: str, documents: list, top_k: int) -> list: ...

class CohereReranker:
    def __init__(self, api_key: str, model: str = "rerank-v3.5"):
        import cohere
        self.client = cohere.Client(api_key)
        self.model = model

    def rerank(self, query, documents, top_k=5):
        results = self.client.rerank(
            model=self.model, query=query,
            documents=[d.page_content for d in documents], top_n=top_k,
        )
        return [documents[r.index] for r in results.results]

def evaluate_reranker(reranker, name, eval_dataset, llm):
    """ãƒªãƒ©ãƒ³ã‚«ãƒ¼ã‚’RAGASãƒ¡ãƒˆãƒªã‚¯ã‚¹ã§è©•ä¾¡"""
    import time
    samples, total_latency = [], 0.0

    for item in eval_dataset:
        start = time.perf_counter()
        reranked = reranker.rerank(item["query"], item["retrieved_docs"], top_k=5)
        total_latency += (time.perf_counter() - start) * 1000

        context = "\n".join([d.page_content for d in reranked])
        response = llm.invoke(f"ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ:\n{context}\n\nè³ªå•: {item['query']}")

        samples.append(SingleTurnSample(
            user_input=item["query"], response=response.content,
            retrieved_contexts=[d.page_content for d in reranked],
            reference=item["ground_truth"],
        ))

    dataset = EvaluationDataset(samples=samples)
    results = evaluate(
        dataset=dataset,
        metrics=[faithfulness, context_precision, context_recall, answer_relevancy],
    )
    return {
        "name": name, "avg_latency_ms": total_latency / len(eval_dataset),
        **{k: results[k] for k in ["faithfulness", "context_precision", "context_recall", "answer_relevancy"]},
    }
```

ç¤¾å†…ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆï¼ˆæ—¥æœ¬èªç´„70%ã€è‹±èªç´„30%ï¼‰ã§ã®è©•ä¾¡çµæœã§ã™ã€‚

| ãƒ¡ãƒˆãƒªã‚¯ã‚¹ | Cohere Rerank 3.5 | BGE Reranker v2 M3 |
|-----------|-------------------|---------------------|
| Faithfulness | **0.91** | 0.85 |
| Context Precision | **0.87** | 0.82 |
| Context Recall | 0.79 | **0.83** |
| Answer Relevancy | **0.88** | 0.84 |
| å¹³å‡ãƒ¬ã‚¤ãƒ†ãƒ³ã‚· | **48ms** | 195ms |

**ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã®åˆ¤æ–­**: Cohere Rerank 3.5ã¯Faithfulnessï¼ˆäº‹å®Ÿæ•´åˆæ€§ï¼‰ã¨ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã§å„ªä½ã€BGE Reranker v2 M3ã¯Context Recallï¼ˆç¶²ç¾…æ€§ï¼‰ã§ä¸Šå›ã‚Šã¾ã™ã€‚ã€Œå›ç­”ã®æ­£ç¢ºæ€§ã€ãŒKPIã ã£ãŸãŸã‚Faithfulnessã‚’é‡è¦–ã—ã¦Cohere Rerank 3.5ã‚’æ¡ç”¨ã—ã¾ã—ãŸã€‚ãªãŠã€Rerank 4.0ã§ã¯ã“ã‚Œã‚‰ã®ã‚¹ã‚³ã‚¢ãŒã•ã‚‰ã«æ”¹å–„ã•ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚ã€å°å…¥æ™‚ã¯å†è©•ä¾¡ã‚’æ¨å¥¨ã—ã¾ã™ã€‚

> **åˆ¶ç´„**: Cohere Rerank 3.5/4.0ã¯ã‚¯ãƒ©ã‚¦ãƒ‰APIã®ãŸã‚ã€å¤–éƒ¨é€ä¿¡ç¦æ­¢ã®ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒãƒªã‚·ãƒ¼ã§ã¯BGEã®ã‚»ãƒ«ãƒ•ãƒ›ã‚¹ãƒˆãŒå”¯ä¸€ã®é¸æŠè‚¢ã§ã™ã€‚ã“ã®è©•ä¾¡ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ãŒã‚ã‚Œã°åˆ¶ç´„å¤‰æ›´æ™‚ã«ã‚‚å³åº§ã«åˆ‡ã‚Šæ›¿ãˆåˆ¤æ–­ãŒã§ãã¾ã™ã€‚

## RAGASãƒ¡ãƒˆãƒªã‚¯ã‚¹ã§å“è³ªã‚’ç¶™ç¶šç›£è¦–ã™ã‚‹

ãƒªãƒ©ãƒ³ã‚«ãƒ¼é¸æŠã¯ä¸€åº¦ãã‚Šã®åˆ¤æ–­ã§ã¯ãªãã€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®æ›´æ–°ã‚„ã‚¯ã‚¨ãƒªãƒ‘ã‚¿ãƒ¼ãƒ³ã®å¤‰åŒ–ã§æœ€é©è¨­å®šã‚‚å¤‰ã‚ã‚Šã¾ã™ã€‚RAGASãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’LangSmithã«çµ±åˆã—ã¦**ç¶™ç¶šç›£è¦–**ã‚’å®Ÿç¾ã—ã¾ã—ã‚‡ã†ã€‚

### ç›£è¦–ã™ã¹ã4ã¤ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹

| ãƒ¡ãƒˆãƒªã‚¯ã‚¹ | è©•ä¾¡å¯¾è±¡ | æ„å‘³ |
|-----------|---------|------|
| **Faithfulness** | ç”Ÿæˆ | å›ç­”ãŒæ¤œç´¢çµæœã«å¿ å®Ÿã‹ï¼ˆãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³æ¤œå‡ºï¼‰ |
| **Context Precision** | æ¤œç´¢ | ä¸Šä½ã®æ¤œç´¢çµæœãŒé–¢é€£åº¦é †ã«ä¸¦ã‚“ã§ã„ã‚‹ã‹ |
| **Context Recall** | æ¤œç´¢ | æ­£è§£ã«å¿…è¦ãªæƒ…å ±ãŒã™ã¹ã¦æ¤œç´¢ã§ãã¦ã„ã‚‹ã‹ |
| **Answer Relevancy** | ç”Ÿæˆ | å›ç­”ãŒè³ªå•ã«å¯¾ã—ã¦çš„ç¢ºã‹ |

Faithfulnessã ã‘ç›£è¦–ã—ã¦ã„ãŸæ™‚æœŸã«ã€Œå›ç­”ã¯æ­£ç¢ºã ãŒè³ªå•ã«ç­”ãˆã¦ã„ãªã„ã€ã¨ã„ã†ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãŒæ€¥å¢—ã—ã¾ã—ãŸã€‚Answer Relevancyã‚’è¿½åŠ ã—ã¦ç‰¹å®šã‚«ãƒ†ã‚´ãƒªã®ã‚¹ã‚³ã‚¢ãŒ0.6ä»¥ä¸‹ã«ä½ä¸‹ã—ã¦ã„ã‚‹ã“ã¨ã‚’ç™ºè¦‹ã€‚**æ¤œç´¢ã¨ç”Ÿæˆã®ä¸¡æ–¹ã‚’ç›£è¦–ã—ãªã„ã¨åŸå› ç‰¹å®šã«æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™**ã€‚

### LangSmithçµ±åˆã®ç›£è¦–ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

```python
# monitoring.py
import os
from datetime import datetime
from langsmith.evaluation import evaluate as ls_evaluate
from ragas.metrics import faithfulness, context_precision
from ragas.dataset_schema import SingleTurnSample
from ragas import evaluate as ragas_evaluate, EvaluationDataset

os.environ["LANGSMITH_PROJECT"] = "rag-pipeline-production"

def ragas_faithfulness_evaluator(run, example) -> dict:
    """LangSmithã‚«ã‚¹ã‚¿ãƒ ã‚¨ãƒãƒªãƒ¥ã‚¨ãƒ¼ã‚¿ãƒ¼: Faithfulness"""
    sample = SingleTurnSample(
        user_input=example.inputs["query"],
        response=run.outputs["answer"],
        retrieved_contexts=run.outputs.get("contexts", []),
    )
    result = ragas_evaluate(
        dataset=EvaluationDataset(samples=[sample]),
        metrics=[faithfulness],
    )
    return {"key": "ragas_faithfulness", "score": result["faithfulness"]}

def run_daily_evaluation(dataset_name="rag-eval-golden-set"):
    """ã‚´ãƒ¼ãƒ«ãƒ‡ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«å¯¾ã—ã¦æ—¥æ¬¡è©•ä¾¡ã‚’å®Ÿè¡Œ"""
    return ls_evaluate(
        target=run_rag_pipeline,
        data=dataset_name,
        evaluators=[ragas_faithfulness_evaluator],
        experiment_prefix=f"daily-eval-{datetime.now().strftime('%Y%m%d')}",
    )
```

### ã‚¢ãƒ©ãƒ¼ãƒˆé–¾å€¤ã®è¨­å®š

ã‚¹ã‚³ã‚¢ä½ä¸‹ã‚’æ—©æœŸã«æ¤œçŸ¥ã™ã‚‹ãŸã‚ã®é–¾å€¤è¨­è¨ˆã§ã™ã€‚

| ãƒ¡ãƒˆãƒªã‚¯ã‚¹ | Warningé–¾å€¤ | Criticalé–¾å€¤ | ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ |
|-----------|------------|-------------|-----------|
| Faithfulness | 0.85 | 0.75 | ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å†æ§‹ç¯‰ã‚’æ¤œè¨ |
| Context Precision | 0.80 | 0.70 | ãƒªãƒ©ãƒ³ã‚«ãƒ¼è¨­å®šã‚’è¦‹ç›´ã— |
| Answer Relevancy | 0.80 | 0.70 | ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®èª¿æ•´ |

Criticalé–¾å€¤ã‚’ä¸‹å›ã£ãŸå ´åˆã¯Slacké€šçŸ¥ã‚’é€ä¿¡ã—ã€Warningé–¾å€¤ã§ã¯æ—¥æ¬¡ãƒ¬ãƒãƒ¼ãƒˆã«è¨˜è¼‰ã™ã‚‹é‹ç”¨ã¨ã—ã¦ã„ã¾ã™ã€‚

## ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æˆ¦ç•¥ã§è¤‡åˆã‚¨ãƒ©ãƒ¼ã«å¯¾å‡¦ã™ã‚‹

Agentic RAGã§ã¯å„å±¤ï¼ˆãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°â†’æ¤œç´¢â†’ãƒªãƒ©ãƒ³ã‚­ãƒ³ã‚°â†’ç”Ÿæˆï¼‰ãŒç›´åˆ—æ¥ç¶šã•ã‚Œã¾ã™ã€‚**å„å±¤95%ç²¾åº¦ã§ã‚‚4å±¤é€šéã§0.95^4 = 81%ã«ä½ä¸‹**ã€‚ã“ã‚ŒãŒã€Œè¤‡åˆã‚¨ãƒ©ãƒ¼å•é¡Œã€ã§ã™ã€‚

### ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒã‚§ãƒ¼ãƒ³ã®å®Ÿè£…

```python
# fallback.py
def grade_and_decide(state) -> str:
    """æ¤œç´¢çµæœã‚’è©•ä¾¡ã—ã€æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ±ºå®š"""
    if not state["retrieved_docs"]:
        return "fallback_web_search"

    relevance_scores = compute_relevance_scores(
        state["query"], state["retrieved_docs"][:5]
    )
    avg_relevance = sum(relevance_scores) / len(relevance_scores)

    if avg_relevance < 0.3:
        return "fallback_query_rewrite"
    elif avg_relevance < 0.5:
        return "fallback_hybrid_search"
    return "rerank"

def fallback_query_rewrite(state) -> dict:
    """ã‚¯ã‚¨ãƒªæ›¸ãæ›ãˆã§å†æ¤œç´¢ï¼ˆä¸Šé™2å›ï¼‰"""
    if state.get("fallback_count", 0) >= 2:
        return {"answer": "ååˆ†ãªæƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚", "quality_score": 0.0}
    rewritten = llm.invoke(
        f"æ¤œç´¢ã«é©ã—ãŸå½¢ã«æ›¸ãæ›ãˆã¦ãã ã•ã„: {state['query']}"
    )
    return {"query": rewritten.content, "fallback_count": state.get("fallback_count", 0) + 1}

def reciprocal_rank_fusion(*doc_lists, k=60):
    """RRFã§è¤‡æ•°æ¤œç´¢çµæœã‚’çµ±åˆ"""
    scores, doc_map = {}, {}
    for doc_list in doc_lists:
        for rank, doc in enumerate(doc_list):
            doc_id = doc.metadata.get("id", doc.page_content[:100])
            doc_map[doc_id] = doc
            scores[doc_id] = scores.get(doc_id, 0.0) + 1.0 / (k + rank + 1)
    return [doc_map[i] for i in sorted(scores, key=scores.get, reverse=True)]

# ã‚°ãƒ©ãƒ•æ§‹ç¯‰
workflow = StateGraph(RAGState)
workflow.add_edge(START, "route")
workflow.add_edge("route", "retrieve")
workflow.add_conditional_edges("retrieve", grade_and_decide, {
    "rerank": "rerank",
    "fallback_query_rewrite": "fallback_query_rewrite",
    "fallback_hybrid_search": "fallback_hybrid_search",
    "fallback_web_search": "fallback_web_search",
})
workflow.add_edge("fallback_query_rewrite", "retrieve")  # ãƒ«ãƒ¼ãƒ—
workflow.add_edge("fallback_hybrid_search", "rerank")
workflow.add_edge("rerank", "generate")
workflow.add_edge("generate", END)
```

**ã‚ˆãã‚ã‚‹é–“é•ã„**: ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã«ä¸Šé™ã‚’è¨­ã‘ãªã„ã¨ç„¡é™ãƒ«ãƒ¼ãƒ—ãŒç™ºç”Ÿã—ã¾ã™ã€‚ãƒ†ã‚¹ãƒˆä¸­ã«1ã‚¯ã‚¨ãƒªã§30å›ä»¥ä¸Šãƒªãƒˆãƒ©ã‚¤ãŒèµ°ã‚ŠAPIã‚³ã‚¹ãƒˆãŒè·³ã­ä¸ŠãŒã‚Šã¾ã—ãŸã€‚**å¿…ãšä¸Šé™ï¼ˆ2-3å›ï¼‰ã‚’è¨­å®š**ã—ã¦ãã ã•ã„ã€‚

## ã‚ˆãã‚ã‚‹å•é¡Œã¨è§£æ±ºæ–¹æ³•

| å•é¡Œ | åŸå›  | è§£æ±ºæ–¹æ³• |
|------|------|----------|
| ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ç²¾åº¦ãŒä½ã„ | åˆ†é¡ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒæ›–æ˜§ | Few-shotä¾‹ã‚’5-10å€‹è¿½åŠ ã€`temperature=0` |
| ãƒªãƒ©ãƒ³ã‚­ãƒ³ã‚°å¾Œã«Recallä½ä¸‹ | top_kãŒå°ã•ã™ãã‚‹ | åˆæœŸæ¤œç´¢k=20-30ã€ãƒªãƒ©ãƒ³ã‚¯å¾Œk=5 |
| `Send()`ã§çµæœãŒæ¬ è½ | reducerè¨­å®šæ¼ã‚Œ | `Annotated[list, operator.add]`ã§æ˜ç¤º |
| Faithfulnessæ€¥ä½ä¸‹ | ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹é™³è…åŒ– | æ—¥æ¬¡ã§ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å†æ§‹ç¯‰ |
| ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã‚¹ãƒ‘ã‚¤ã‚¯ | ãƒªãƒ©ãƒ³ã‚«ãƒ¼ã®ã‚³ãƒ¼ãƒ«ãƒ‰ã‚¹ã‚¿ãƒ¼ãƒˆ | keep-aliveæ¥ç¶šã€GPUã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ— |
| RAGASè©•ä¾¡ãŒä¸å®‰å®š | è©•ä¾¡LLMã®éæ±ºå®šæ€§ | `temperature=0`ã€5å›å¹³å‡ã‚¹ã‚³ã‚¢ä½¿ç”¨ |

## ã¾ã¨ã‚ã¨æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

**ã¾ã¨ã‚:**

- LangGraph v1.0ã®`Send()`ã§**ãƒãƒ«ãƒã‚½ãƒ¼ã‚¹ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°**ã‚’å®Ÿè£…ã—ã€ã‚¯ã‚¨ãƒªç‰¹æ€§ã«å¿œã˜ãŸæ¤œç´¢ã‚½ãƒ¼ã‚¹ã‚’å‹•çš„é¸æŠ
- RAGASãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®**A/Bè©•ä¾¡ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³**ã§ãƒªãƒ©ãƒ³ã‚«ãƒ¼é¸æŠã‚’ãƒ‡ãƒ¼ã‚¿ãƒ‰ãƒªãƒ–ãƒ³ã«æœ€é©åŒ–
- Faithfulness + Context Precision + Answer Relevancyã®**3è»¸ç›£è¦–**ã§å“è³ªåŠ£åŒ–ã‚’15åˆ†ä»¥å†…ã«æ¤œçŸ¥
- ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒã‚§ãƒ¼ãƒ³ã§**è¤‡åˆã‚¨ãƒ©ãƒ¼å•é¡Œã‚’è»½æ¸›**ã—ã€å…¨ä½“ã¨ã—ã¦68%â†’89%ã«**å›ç­”ç²¾åº¦ã‚’21ãƒã‚¤ãƒ³ãƒˆæ”¹å–„**

**æ¬¡ã«ã‚„ã‚‹ã¹ãã“ã¨:**

1. è‡ªç¤¾ã®è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆ50-100ä»¶ã®Q&Aãƒšã‚¢ï¼‰ã‚’ä½œæˆã—ã€ãƒªãƒ©ãƒ³ã‚«ãƒ¼ã‚’æ¯”è¼ƒã™ã‚‹
2. LangSmithã§æ—¥æ¬¡è©•ä¾¡ã‚’è‡ªå‹•åŒ–ã—ã€ã‚¢ãƒ©ãƒ¼ãƒˆé–¾å€¤ã‚’èª¿æ•´ã™ã‚‹
3. ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¾å€¤ï¼ˆ`avg_relevance < 0.3`, `< 0.5`ï¼‰ã‚’è‡ªç¤¾ãƒ‡ãƒ¼ã‚¿ã§ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹

## é–¢é€£ã™ã‚‹æ·±æ˜ã‚Šè¨˜äº‹

æœ¬è¨˜äº‹ã®å†…å®¹ã‚’ã•ã‚‰ã«æ·±æ˜ã‚Šã—ãŸ1æ¬¡æƒ…å ±è¨˜äº‹ã‚’å…¬é–‹ã—ã¦ã„ã¾ã™ã€‚

| # | ã‚¿ã‚¤ãƒ— | ã‚¿ã‚¤ãƒˆãƒ« |
|---|--------|---------|
| 1 | arXivè«–æ–‡ | [RouterBench: Multi-LLM Routing Systemã®è©•ä¾¡ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯](https://0h-n0.github.io/posts/paper-2409-05694/) |
| 2 | arXivè«–æ–‡ | [ARAGOG: Advanced RAG Output Grading](https://0h-n0.github.io/posts/paper-2404-16130-aragog/) |
| 3 | arXivè«–æ–‡ | [MindSearch: DAGå‹ãƒãƒ«ãƒã‚½ãƒ¼ã‚¹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæ¤œç´¢](https://0h-n0.github.io/posts/paper-2407-16833/) |
| 4 | ä¼æ¥­ãƒ–ãƒ­ã‚° | [NVIDIAè§£èª¬: åˆæˆãƒ‡ãƒ¼ã‚¿ã«ã‚ˆã‚‹RAGãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³è©•ä¾¡ãƒ»æœ€é©åŒ–](https://0h-n0.github.io/posts/techblog-nvidia-rag-synthetic-evaluation/) |
| 5 | arXivè«–æ–‡ | [CoRAG: Chain-of-Retrieval Augmented Generation](https://0h-n0.github.io/posts/paper-2406-04744/) |

## å‚è€ƒ

- [LangChainå…¬å¼: Build a custom RAG agent with LangGraph](https://docs.langchain.com/oss/python/langgraph/agentic-rag)
- [LangChainå…¬å¼: Build a multi-source knowledge base with routing](https://docs.langchain.com/oss/python/langchain/multi-agent/router-knowledge-base)
- [RAGASå…¬å¼: Available Metrics](https://docs.ragas.io/en/stable/concepts/metrics/available_metrics/)
- [LangSmith Observability](https://www.langchain.com/langsmith/observability)
- [Top 7 Rerankers for RAG (2026)](https://www.analyticsvidhya.com/blog/2025/06/top-rerankers-for-rag/)
- [Best Reranker for RAG - Agentset](https://agentset.ai/blog/best-reranker)
- [Introducing Rerank 4 - Cohere Blog](https://cohere.com/blog/rerank-4)
- [Evaluation of RAG pipelines with RAGAS - Langfuse](https://langfuse.com/guides/cookbook/evaluation_of_rag_with_ragas)

---

:::message
ã“ã®è¨˜äº‹ã¯AIï¼ˆClaude Codeï¼‰ã«ã‚ˆã‚Šè‡ªå‹•ç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚å†…å®¹ã®æ­£ç¢ºæ€§ã«ã¤ã„ã¦ã¯è¤‡æ•°ã®æƒ…å ±æºã§æ¤œè¨¼ã—ã¦ã„ã¾ã™ãŒã€å®Ÿéš›ã®åˆ©ç”¨æ™‚ã¯å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚‚ã”ç¢ºèªãã ã•ã„ã€‚
:::
