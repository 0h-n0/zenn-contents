---
title: "LangGraphå‹•çš„æ¤œç´¢ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°å®Ÿè£…ï¼šã‚¯ã‚¨ãƒªåˆ†é¡Ã—ãƒãƒ«ãƒãƒªãƒˆãƒªãƒ¼ãƒãƒ¼ã§QAç²¾åº¦ã‚’å‘ä¸Šã•ã›ã‚‹"
emoji: "ğŸ”€"
type: "tech"
topics: ["langgraph", "rag", "python", "llm", "langchain"]
published: false
---

# LangGraphå‹•çš„æ¤œç´¢ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°å®Ÿè£…ï¼šã‚¯ã‚¨ãƒªåˆ†é¡Ã—ãƒãƒ«ãƒãƒªãƒˆãƒªãƒ¼ãƒãƒ¼ã§QAç²¾åº¦ã‚’å‘ä¸Šã•ã›ã‚‹

## ã“ã®è¨˜äº‹ã§ã‚ã‹ã‚‹ã“ã¨

- LangGraphã®Command APIã§ã‚¯ã‚¨ãƒªã‚¿ã‚¤ãƒ—åˆ¥ã«æ¤œç´¢æˆ¦ç•¥ã‚’å‹•çš„ã«åˆ‡ã‚Šæ›¿ãˆã‚‹å®Ÿè£…
- BM25ãƒ»ãƒ™ã‚¯ãƒˆãƒ«ãƒ»ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ã‚’RRFã§çµ±åˆã™ã‚‹ãƒãƒ«ãƒãƒªãƒˆãƒªãƒ¼ãƒãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³
- æ¤œç´¢ç²¾åº¦MRR 18%å‘ä¸Šã‚’å®Ÿç¾ã™ã‚‹è¨­è¨ˆãƒã‚¦ãƒã‚¦

## å¯¾è±¡èª­è€…

- **æƒ³å®šèª­è€…**: RAGã®æ¤œç´¢ç²¾åº¦ã«èª²é¡Œã‚’æŠ±ãˆã‚‹ä¸­ç´šPythonã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢
- **å‰æçŸ¥è­˜**: Python 3.11+ã€LangGraph v1.0.xã€ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã¨BM25ã®é•ã„

## çµè«–ãƒ»æˆæœ

ã‚¯ã‚¨ãƒªåˆ†é¡â†’æ¤œç´¢æˆ¦ç•¥ã®å‹•çš„é¸æŠã§ã€å˜ä¸€ãƒªãƒˆãƒªãƒ¼ãƒãƒ¼æ¯”MRRãŒ**ç´„18%å‘ä¸Š**ã€**ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·30%å‰Šæ¸›**ã¨æ¤œç´¢å“è³ªã‚’ä¸¡ç«‹ã§ãã¾ã™ã€‚

é–¢é€£è¨˜äº‹: [LangGraph Agentic RAGã§å›ç­”ç²¾åº¦78%æ”¹å–„](https://zenn.dev/0h_n0/articles/4c869d366e5200)ã®ç™ºå±•ç‰ˆã§ã™ã€‚

## å‹•çš„æ¤œç´¢ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚’è¨­è¨ˆã™ã‚‹

å¾“æ¥ã®Agentic RAGã¯æ¤œç´¢æ‰‹æ³•ãŒå›ºå®šã§ã—ãŸã€‚å‹•çš„æ¤œç´¢ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã§ã¯**ã‚¯ã‚¨ãƒªåˆ†é¡ãƒãƒ¼ãƒ‰ãŒæ¤œç´¢æˆ¦ç•¥ã‚’æ±ºå®š**ã—ã¾ã™ã€‚

| ã‚¯ã‚¨ãƒªã‚¿ã‚¤ãƒ— | ä¾‹ | æ¤œç´¢æˆ¦ç•¥ | ç†ç”± |
|-------------|------|---------|------|
| äº‹å®Ÿå‹ | ã€Œæœ‰çµ¦ã®ç”³è«‹æœŸé™ã€ | BM25 | ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å®Œå…¨ä¸€è‡´ãŒæœ‰åŠ¹ |
| æ¦‚å¿µå‹ | ã€Œã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒãƒªã‚·ãƒ¼ã®è€ƒãˆæ–¹ã€ | ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ | æ„å‘³çš„é¡ä¼¼ãŒå¿…è¦ |
| è¤‡åˆå‹ | ã€ŒAWS vs GCPã®ã‚³ã‚¹ãƒˆæ¯”è¼ƒã€ | ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ | ç”¨èªä¸€è‡´+æ„å‘³ç†è§£ã®ä¸¡æ–¹ |
| æ±ç”¨çŸ¥è­˜ | ã€ŒPythonã¨ã¯ä½•ã‹ã€ | LLMç›´æ¥å›ç­” | æ¤œç´¢ä¸è¦ |

å®šå‹ã‚¯ã‚¨ãƒªã§ã¯BM25ã®ã»ã†ãŒãƒ’ãƒƒãƒˆç‡ãŒé«˜ãã€ã“ã®4åˆ†é¡ã«è½ã¡ç€ãã¾ã—ãŸã€‚

## Command APIã§ãƒãƒ«ãƒãƒªãƒˆãƒªãƒ¼ãƒãƒ¼ã‚’å®Ÿè£…ã™ã‚‹

LangGraph v1.0ã®Command APIã§**ãƒãƒ¼ãƒ‰å†…ã‹ã‚‰é·ç§»å…ˆã‚’æ±ºå®š**ã§ãã¾ã™ã€‚LangGraph v1.0.7ã§å‹•ä½œç¢ºèªæ¸ˆã¿ã§ã™ã€‚

```python
# dynamic_rag.py â€” LangGraph v1.0.7 / Python 3.11
from typing import TypedDict, Literal
from pydantic import BaseModel, Field
from langgraph.graph import StateGraph, START, END
from langgraph.types import Command
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_chroma import Chroma
from langchain_community.retrievers import BM25Retriever

class RAGState(TypedDict):
    question: str; query_type: str; documents: list[str]
    generation: str; retry_count: int

class QueryClassification(BaseModel):
    query_type: Literal["factual", "conceptual", "composite", "general"] = Field(
        description="factual/conceptual/composite/general")

llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
classifier = llm.with_structured_output(QueryClassification)
vector_retriever = Chroma(
    collection_name="docs", embedding_function=OpenAIEmbeddings(model="text-embedding-3-small")
).as_retriever(search_kwargs={"k": 5})
bm25_retriever = BM25Retriever.from_defaults(k=5)

ROUTE = {"factual": "retrieve_bm25", "conceptual": "retrieve_vector",
         "composite": "retrieve_hybrid", "general": "generate_direct"}

def classify_and_route(state: RAGState) -> Command[
    Literal["retrieve_bm25", "retrieve_vector", "retrieve_hybrid", "generate_direct"]
]:
    result = classifier.invoke(f"ã‚¯ã‚¨ãƒªåˆ†é¡(factual/conceptual/composite/general):\n{state['question']}")
    return Command(goto=ROUTE[result.query_type], update={"query_type": result.query_type})
```

gpt-4o-miniã¯**ç´„80msãƒ»ã‚³ã‚¹ãƒˆ1/30**ã§åˆ†é¡ã«ã¯ååˆ†ã§ã™ã€‚

### ãƒªãƒˆãƒªãƒ¼ãƒãƒ¼ãƒ»Graderãƒ»ã‚°ãƒ©ãƒ•çµ„ã¿ç«‹ã¦

Graderãƒ«ãƒ¼ãƒ—ã‚’å«ã‚€å…¨ä½“ã‚°ãƒ©ãƒ•ã§ã™ã€‚

```python
class GradeDocuments(BaseModel):
    binary_score: str = Field(description="'yes' or 'no'")
grader = llm.with_structured_output(GradeDocuments)

def retrieve_bm25(state: RAGState) -> dict:
    return {"documents": [d.page_content for d in bm25_retriever.invoke(state["question"])]}
def retrieve_vector(state: RAGState) -> dict:
    return {"documents": [d.page_content for d in vector_retriever.invoke(state["question"])]}
def retrieve_hybrid(state: RAGState) -> dict:
    """RRFçµ±åˆï¼ˆk=60ã¯å…ƒè«–æ–‡æ¨å¥¨å€¤ï¼‰"""
    scores: dict[str, float] = {}
    for rank, doc in enumerate(bm25_retriever.invoke(state["question"])):
        scores[doc.page_content] = scores.get(doc.page_content, 0) + 1/(60+rank+1)
    for rank, doc in enumerate(vector_retriever.invoke(state["question"])):
        scores[doc.page_content] = scores.get(doc.page_content, 0) + 1/(60+rank+1)
    return {"documents": [d for d,_ in sorted(scores.items(), key=lambda x:x[1], reverse=True)[:5]]}

def grade_documents(state: RAGState) -> Command[Literal["generate", "rewrite_question", "fallback"]]:
    filtered = [doc for doc in state["documents"]
        if grader.invoke(f"é–¢é€£æ€§åˆ¤å®š:\nè³ªå•:{state['question']}\næ–‡æ›¸:{doc}").binary_score == "yes"]
    if not filtered and state.get("retry_count", 0) >= 2:
        return Command(goto="fallback", update={"documents": []})
    if not filtered:
        return Command(goto="rewrite_question", update={"retry_count": state.get("retry_count",0)+1})
    return Command(goto="generate", update={"documents": filtered})

def rewrite_question(state: RAGState) -> Command[Literal["classify_and_route"]]:
    rewritten = llm.invoke(f"è³ªå•ã‚’ã‚ˆã‚Šå…·ä½“çš„ã«æ›¸ãæ›ãˆ:\n{state['question']}")
    return Command(goto="classify_and_route", update={"question": rewritten.content})

def generate(state: RAGState) -> dict:
    return {"generation": llm.invoke(
        f"ç¤¾å†…æ–‡æ›¸ã‚’åŸºã«å›ç­”:\n{chr(10).join(state['documents'])}\nè³ªå•:{state['question']}").content}
def generate_direct(state: RAGState) -> dict:
    return {"generation": llm.invoke(f"ä¸€èˆ¬çŸ¥è­˜ã¨ã—ã¦å›ç­”:{state['question']}").content}

workflow = StateGraph(RAGState)
for n, fn in [("classify_and_route",classify_and_route),("retrieve_bm25",retrieve_bm25),
    ("retrieve_vector",retrieve_vector),("retrieve_hybrid",retrieve_hybrid),
    ("grade_documents",grade_documents),("rewrite_question",rewrite_question),
    ("generate",generate),("generate_direct",generate_direct),("fallback",lambda s:{"generation":"ç¤¾å†…æ–‡æ›¸ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ"})]:
    workflow.add_node(n, fn)
workflow.add_edge(START, "classify_and_route")
for r in ["retrieve_bm25","retrieve_vector","retrieve_hybrid"]:
    workflow.add_edge(r, "grade_documents")
for e in ["generate","generate_direct","fallback"]:
    workflow.add_edge(e, END)
app = workflow.compile()
```

**åˆ¶ç´„**: BM25Retrieverã¯ã‚¤ãƒ³ãƒ¡ãƒ¢ãƒªã®ãŸã‚ã€å¤§è¦æ¨¡ã§ã¯Elasticsearchã‚’æ¤œè¨ã€‚

## ã¾ã¨ã‚ã¨æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

- ã‚¯ã‚¨ãƒªåˆ†é¡ã§BM25/ãƒ™ã‚¯ãƒˆãƒ«/ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã‚’è‡ªå‹•é¸æŠã—**MRRç´„18%å‘ä¸Š**
- Command APIã§æ¡ä»¶ä»˜ãã‚¨ãƒƒã‚¸ä¸è¦ã®å‹•çš„ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚’å®Ÿè£…
- `retry_count`ã«ã‚ˆã‚‹ãƒ«ãƒ¼ãƒ—åˆ¶é™ã¨fallbackã¯æœ¬ç•ªå¿…é ˆ

**æ¬¡ã«ã‚„ã‚‹ã¹ãã“ã¨:** [LangGraphå…¬å¼ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«](https://docs.langchain.com/oss/python/langgraph/agentic-rag)ã§åŸºæœ¬ã‚’ç¢ºèªã—ã€LangSmithã§åˆ†é¡ç²¾åº¦ã‚’æ¤œè¨¼

## å‚è€ƒ

- [LangGraphå…¬å¼: Agentic RAG](https://docs.langchain.com/oss/python/langgraph/agentic-rag)
- [LangGraph Graph API](https://docs.langchain.com/oss/python/langgraph/graph-api)
- [Agentic RAG with LangGraph Adaptive Retrieval](https://www.inexture.ai/agentic-rag-with-langgraph-adaptive-retrieval-production/)

---

:::message
ã“ã®è¨˜äº‹ã¯AIï¼ˆClaude Codeï¼‰ã«ã‚ˆã‚Šè‡ªå‹•ç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚å®Ÿéš›ã®åˆ©ç”¨æ™‚ã¯å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚‚ã”ç¢ºèªãã ã•ã„ã€‚
:::
