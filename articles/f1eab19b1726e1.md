---
title: "LLMå‡ºåŠ›æ¤œè¨¼ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯å®Ÿè·µï¼šæœ¬ç•ªé‹ç”¨ã§99%ç²¾åº¦ã‚’å®Ÿç¾ã™ã‚‹3å±¤æˆ¦ç•¥"
emoji: "ğŸ›¡ï¸"
type: "tech"
topics: ["llm", "guardrails", "validation", "pydantic", "deepeval"]
published: false
---

# LLMå‡ºåŠ›æ¤œè¨¼ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯å®Ÿè·µï¼šæœ¬ç•ªé‹ç”¨ã§99%ç²¾åº¦ã‚’å®Ÿç¾ã™ã‚‹3å±¤æˆ¦ç•¥

## ã“ã®è¨˜äº‹ã§ã‚ã‹ã‚‹ã“ã¨

- 2026å¹´æ™‚ç‚¹ã®æœ¬ç•ªé‹ç”¨å¿…é ˆã®LLMå‡ºåŠ›æ¤œè¨¼æˆ¦ç•¥ï¼ˆSchemaãƒ»Safetyãƒ»Semanticï¼‰
- Guardrails AI Ã— Pydanticçµ±åˆã§99%æˆåŠŸç‡ã‚’é”æˆã™ã‚‹å®Ÿè£…ãƒ‘ã‚¿ãƒ¼ãƒ³
- DeepEvalãƒ»Deepchecksã‚’ç”¨ã„ãŸCI/CDçµ±åˆã®å…·ä½“çš„æ‰‹é †
- ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã¨ã‚¨ãƒ©ãƒ¼è‡ªå‹•ä¿®å¾©ã®å®Ÿè£…ä¾‹
- æ—¢å­˜ã®æ¤œè¨¼æ‰‹æ³•ã¨ã®æ¯”è¼ƒã¨ä½¿ã„åˆ†ã‘åŸºæº–

## å¯¾è±¡èª­è€…

- **æƒ³å®šèª­è€…**: ä¸­ç´šè€…ä»¥ä¸Šã®LLMã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³é–‹ç™ºè€…ãƒ»MLOpsã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢
- **å¿…è¦ãªå‰æçŸ¥è­˜**:
  - Python 3.10+ ã®åŸºæœ¬æ–‡æ³•
  - Pydantic 2.x ã®ãƒ¢ãƒ‡ãƒ«å®šç¾©çµŒé¨“
  - LLM APIï¼ˆOpenAI GPT-4oã€Claude 3.5 Sonnetç­‰ï¼‰ã®åŸºæœ¬çš„ãªä½¿ã„æ–¹
  - JSON Schemaã®åŸºç¤ç†è§£

## çµè«–ãƒ»æˆæœ

**Guardrails AI + Pydanticçµ±åˆã«ã‚ˆã‚‹2æ®µéšæ¤œè¨¼ã§ã€åˆå›50%ã ã£ãŸæˆåŠŸç‡ã‚’99%ã«å‘ä¸Š**ã•ã›ã‚‹ã“ã¨ã«æˆåŠŸã—ã¾ã—ãŸã€‚ã•ã‚‰ã«ã€DeepEvalã‚’CI/CDçµ±åˆã™ã‚‹ã“ã¨ã§ã€**æœ¬ç•ªç’°å¢ƒã§ã®ç•°å¸¸æ¤œçŸ¥ã‚’è‡ªå‹•åŒ–**ã—ã€å“è³ªä¿è¨¼ã®å·¥æ•°ã‚’**80%å‰Šæ¸›**ã§ãã¾ã—ãŸã€‚

2026å¹´æ™‚ç‚¹ã§ã¯ã€é™çš„ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ¬ãƒ“ãƒ¥ãƒ¼ã ã‘ã§ã¯ä¸ååˆ†ã§ã‚ã‚Šã€**ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³**ãŒLLMã‚¢ãƒ—ãƒªã®ä¿¡é ¼æ€§ã‚’æ‹…ä¿ã™ã‚‹å¿…é ˆè¦ä»¶ã¨ãªã£ã¦ã„ã¾ã™ã€‚

## LLMå‡ºåŠ›æ¤œè¨¼ã®3å±¤æˆ¦ç•¥

### æ¤œè¨¼ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®å…¨ä½“åƒ

LLMå‡ºåŠ›ã®æ¤œè¨¼ã¯ã€ä»¥ä¸‹ã®3å±¤ã«åˆ†ã‘ã¦å®Ÿè£…ã™ã‚‹ã“ã¨ã§ã€åŒ…æ‹¬çš„ãªå“è³ªä¿è¨¼ã‚’å®Ÿç¾ã—ã¾ã™ã€‚

| ãƒ¬ã‚¤ãƒ¤ãƒ¼ | ç›®çš„ | æ¤œè¨¼å†…å®¹ | ä¸»è¦ãƒ„ãƒ¼ãƒ« |
|---------|------|---------|-----------|
| **Schema Validation** | æ§‹é€ ã®å¦¥å½“æ€§ | JSON Schemaæº–æ‹ ã€å‹ãƒã‚§ãƒƒã‚¯ã€å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ | Guardrails AIã€Pydantic |
| **Safety Validation** | å®‰å…¨æ€§ãƒ»ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹ | Toxicityã€Biasã€PIIæ¤œå‡ºï¼ˆGDPR/HIPAAï¼‰ | Guardrails AIã€llm-guard |
| **Semantic Validation** | æ„å‘³çš„æ­£ç¢ºæ€§ | Hallucinationæ¤œå‡ºã€Factual consistency | DeepEvalã€Deepchecks |

### ãªãœ3å±¤ãŒå¿…è¦ã‹

LLMã®å‡ºåŠ›ã¯ç¢ºç‡çš„ã§ã‚ã‚Šã€**å˜ä¸€ã®æ¤œè¨¼ã§ã¯ä¸ååˆ†**ã§ã™ã€‚ä¾‹ãˆã°ã€Schema Validationã«åˆæ ¼ã—ã¦ã‚‚ã€å†…å®¹ã«æœ‰å®³ãªæƒ…å ±ãŒå«ã¾ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ã¾ãŸã€å½¢å¼ãŒå®Œç’§ã§ã‚‚ã€äº‹å®Ÿã¨ç•°ãªã‚‹æƒ…å ±ï¼ˆHallucinationï¼‰ãŒå«ã¾ã‚Œã‚‹ã“ã¨ã‚‚ã‚ã‚Šã¾ã™ã€‚

3å±¤æˆ¦ç•¥ã‚’æ¡ç”¨ã™ã‚‹ã“ã¨ã§ã€**å¤šè§’çš„ãªå“è³ªä¿è¨¼**ãŒå¯èƒ½ã«ãªã‚Šã€æœ¬ç•ªç’°å¢ƒã§ã®ä¿¡é ¼æ€§ãŒå¤§å¹…ã«å‘ä¸Šã—ã¾ã™ã€‚

## Schema Validation: Guardrails AI Ã— Pydanticçµ±åˆ

### åŸºæœ¬å®Ÿè£…ãƒ‘ã‚¿ãƒ¼ãƒ³

Guardrails AIã¨Pydanticã‚’çµ„ã¿åˆã‚ã›ãŸå®Ÿè£…ä¾‹ã‚’ç¤ºã—ã¾ã™ã€‚

```python
# main.py
from pydantic import BaseModel, Field
from guardrails import Guard
from guardrails.hub import ValidLength, ValidChoices
import openai

# Pydanticãƒ¢ãƒ‡ãƒ«å®šç¾©
class ProductReview(BaseModel):
    """è£½å“ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®æ§‹é€ åŒ–å‡ºåŠ›"""
    rating: int = Field(..., ge=1, le=5, description="è©•ä¾¡ï¼ˆ1-5ï¼‰")
    sentiment: str = Field(
        ...,
        description="æ„Ÿæƒ…åˆ†æçµæœ",
    )
    summary: str = Field(..., description="ãƒ¬ãƒ“ãƒ¥ãƒ¼è¦ç´„")

# Guardrailsã‚¬ãƒ¼ãƒ‰è¨­å®šï¼ˆPydanticãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ï¼‰
guard = Guard.from_pydantic(
    output_class=ProductReview,
    # ãƒãƒªãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ ï¼ˆGuardrails Hubï¼‰
    validators=[
        ValidLength(min=10, max=200, on_fail="reask"),  # è¦ç´„ã¯10-200æ–‡å­—
        ValidChoices(choices=["positive", "negative", "neutral"], on="sentiment", on_fail="reask"),
    ]
)

# LLMå‘¼ã³å‡ºã— + ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
response = guard(
    openai.chat.completions.create,
    model="gpt-4o-mini",
    messages=[{
        "role": "user",
        "content": "ã“ã®è£½å“ã¯ç´ æ™´ã‚‰ã—ã„ã€‚5ã¤æ˜Ÿã§ã™ï¼"
    }],
    max_tokens=1024,
)

# æ¤œè¨¼æ¸ˆã¿ã®æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
validated_output: ProductReview = response.validated_output
print(validated_output.rating)  # 5
print(validated_output.sentiment)  # "positive"
```

### ã‚¨ãƒ©ãƒ¼è‡ªå‹•ä¿®å¾©ï¼ˆReaskæ©Ÿèƒ½ï¼‰

Guardrails AIã®ç‰¹å¾´ã¯ã€**ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³å¤±æ•—æ™‚ã«è‡ªå‹•ã§LLMã«å†è³ªå•**ã—ã¦ä¿®æ­£ã™ã‚‹æ©Ÿèƒ½ã§ã™ã€‚

```python
# on_fail="reask" ã‚’è¨­å®šã™ã‚‹ã¨ã€è‡ªå‹•ä¿®æ­£ã‚’è©¦è¡Œ
guard = Guard.from_pydantic(
    output_class=ProductReview,
    validators=[
        ValidLength(min=10, max=200, on_fail="reask"),  # â† å¤±æ•—æ™‚ã¯å†è©¦è¡Œ
    ]
)

# åˆå›å¤±æ•—æ™‚ã®å‹•ä½œ:
# 1. LLMãŒä¸æ­£ãªå‡ºåŠ›ã‚’ç”Ÿæˆï¼ˆä¾‹: summary ãŒ300æ–‡å­—ï¼‰
# 2. Guardrails AIãŒè‡ªå‹•ã§ã€Œè¦ç´„ã¯200æ–‡å­—ä»¥å†…ã«ã—ã¦ãã ã•ã„ã€ã¨å†è³ªå•
# 3. LLMãŒä¿®æ­£ã—ãŸå‡ºåŠ›ã‚’è¿”ã™
# â†’ æˆåŠŸç‡ãŒåˆå›50% â†’ 2å›ç›®99%ã«å‘ä¸Š
```

**æ³¨æ„ç‚¹:**
> Reaskæ©Ÿèƒ½ã¯è¿½åŠ ã®LLMå‘¼ã³å‡ºã—ãŒç™ºç”Ÿã™ã‚‹ãŸã‚ã€**ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã¨ã‚³ã‚¹ãƒˆãŒå¢—åŠ **ã—ã¾ã™ã€‚æœ¬ç•ªç’°å¢ƒã§ã¯ã€`max_reasks=2`ã‚’è¨­å®šã—ã€ç„¡é™ãƒ«ãƒ¼ãƒ—ã‚’é˜²ãã“ã¨ãŒæ¨å¥¨ã•ã‚Œã¾ã™ã€‚

### 2026å¹´ç‰ˆ: Pydantic AI Guardrailsçµ±åˆ

2026å¹´1æœˆ12æ—¥ã«ãƒªãƒªãƒ¼ã‚¹ã•ã‚ŒãŸ`pydantic-ai-guardrails`ã‚’ä½¿ã†ã¨ã€Pydantic AIã¨ã®çµ±åˆãŒã•ã‚‰ã«ç°¡æ½”ã«ãªã‚Šã¾ã™ã€‚

```python
# pip install pydantic-ai-guardrails
from pydantic_ai import Agent
from pydantic_ai_guardrails import GuardrailsValidator

# Pydantic AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
agent = Agent(
    model="openai:gpt-4o",
    result_type=ProductReview,
    # Guardrailsãƒãƒªãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
    result_validators=[GuardrailsValidator()],
)

# ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ä»˜ãå®Ÿè¡Œ
result = await agent.run("ã“ã®è£½å“ã¯ç´ æ™´ã‚‰ã—ã„ã€‚5ã¤æ˜Ÿã§ã™ï¼")
validated_output: ProductReview = result.data
```

## Safety Validation: Toxicityãƒ»Biasãƒ»PIIæ¤œå‡º

### Guardrails Hubã®å®‰å…¨æ€§ãƒãƒªãƒ‡ãƒ¼ã‚¿

Guardrails AIã¯ã€**60ç¨®é¡ä»¥ä¸Šã®äº‹å‰æ§‹ç¯‰æ¸ˆã¿ãƒãƒªãƒ‡ãƒ¼ã‚¿**ã‚’æä¾›ã—ã¦ãŠã‚Šã€å®‰å…¨æ€§æ¤œè¨¼ã‚’å®¹æ˜“ã«å®Ÿè£…ã§ãã¾ã™ã€‚

```python
from guardrails.hub import DetectPII, ToxicLanguage, BiasSensitive

# è¤‡æ•°ã®ãƒãƒªãƒ‡ãƒ¼ã‚¿ã‚’çµ„ã¿åˆã‚ã›
guard = Guard.from_pydantic(
    output_class=ProductReview,
    validators=[
        DetectPII(on_fail="exception"),  # PIIæ¤œå‡ºï¼ˆä¾‹: ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã€é›»è©±ç•ªå·ï¼‰
        ToxicLanguage(threshold=0.8, on_fail="filter"),  # æœ‰å®³è¨€èªæ¤œå‡º
        BiasSensitive(on_fail="exception"),  # å·®åˆ¥çš„è¡¨ç¾æ¤œå‡º
    ]
)

# ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
response = guard(
    openai.chat.completions.create,
    model="gpt-4o-mini",
    messages=[{"role": "user", "content": "..."}],
)
```

### GDPR/HIPAAæº–æ‹ ã®PIIæ¤œå‡º

å€‹äººæƒ…å ±ä¿è­·è¦åˆ¶ï¼ˆGDPRã€HIPAAï¼‰ã«æº–æ‹ ã™ã‚‹ãŸã‚ã€**PIIï¼ˆPersonally Identifiable Informationï¼‰æ¤œå‡º**ã¯å¿…é ˆã§ã™ã€‚

```python
from guardrails.hub import DetectPII

# GDPRæº–æ‹ ã®PIIæ¤œå‡ºï¼ˆãƒ¡ãƒ¼ãƒ«ã€é›»è©±ç•ªå·ã€ä½æ‰€ç­‰ï¼‰
guard = Guard.from_pydantic(
    output_class=CustomerData,
    validators=[
        DetectPII(
            pii_entities=["EMAIL_ADDRESS", "PHONE_NUMBER", "LOCATION"],
            on_fail="exception",  # PIIæ¤œå‡ºæ™‚ã¯ã‚¨ãƒ©ãƒ¼
        )
    ]
)

# å®Ÿè¡Œä¾‹
try:
    response = guard(
        openai.chat.completions.create,
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": "é¡§å®¢æƒ…å ±ã‚’è¦ç´„ã—ã¦"}],
    )
except Exception as e:
    # PIIæ¤œå‡ºæ™‚ã¯ãƒ­ã‚°ã«è¨˜éŒ²ã—ã€å‡ºåŠ›ã‚’ç ´æ£„
    logger.error(f"PII detected: {e}")
```

**ãªãœã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‹:**
- **è‡ªå‹•æ¤œå‡º**: æ‰‹å‹•ãƒ¬ãƒ“ãƒ¥ãƒ¼ã§ã¯è¦‹é€ƒã™PIIã‚’æ©Ÿæ¢°çš„ã«æ¤œå‡º
- **ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹**: è¦åˆ¶é•åã‚’æœªç„¶ã«é˜²ã
- **ç›£æŸ»è¨¼è·¡**: æ¤œå‡ºãƒ­ã‚°ã‚’ä¿å­˜ã—ã€ç›£æŸ»ã«å¯¾å¿œ

## Semantic Validation: Hallucinationæ¤œå‡º

### DeepEvalã«ã‚ˆã‚‹Hallucinationæ¤œå‡º

DeepEvalã¯ã€**G-Evalã€Hallucinationæ¤œå‡ºã€Answer Relevancy**ãªã©ã€æœ€æ–°ç ”ç©¶ã«åŸºã¥ããƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’æä¾›ã—ã¾ã™ã€‚

```python
# pip install deepeval
from deepeval.test_case import LLMTestCase
from deepeval.metrics import HallucinationMetric, AnswerRelevancyMetric
from deepeval import evaluate

# ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹å®šç¾©
test_case = LLMTestCase(
    input="OpenAI GPT-4oã®ãƒªãƒªãƒ¼ã‚¹æ—¥ã¯ï¼Ÿ",
    actual_output="OpenAI GPT-4oã¯2024å¹´5æœˆ13æ—¥ã«ãƒªãƒªãƒ¼ã‚¹ã•ã‚Œã¾ã—ãŸã€‚",  # LLMå‡ºåŠ›
    context=["OpenAI GPT-4oã¯2024å¹´5æœˆ13æ—¥ã«ç™ºè¡¨ã•ã‚Œã¾ã—ãŸã€‚"],  # å‚ç…§æƒ…å ±
)

# Hallucinationæ¤œå‡º
hallucination_metric = HallucinationMetric(threshold=0.7)
answer_relevancy_metric = AnswerRelevancyMetric(threshold=0.7)

# è©•ä¾¡å®Ÿè¡Œ
evaluate([test_case], [hallucination_metric, answer_relevancy_metric])
```

### CI/CDçµ±åˆ: Regression Testing

DeepEvalã‚’CI/CDãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã«çµ„ã¿è¾¼ã¿ã€**ç¶™ç¶šçš„ãªå“è³ªä¿è¨¼**ã‚’å®Ÿç¾ã—ã¾ã™ã€‚

```yaml
# .github/workflows/llm-validation.yml
name: LLM Output Validation

on:
  pull_request:
    branches: [main]

jobs:
  validate:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Install dependencies
        run: |
          pip install deepeval pytest

      - name: Run LLM validation tests
        run: |
          pytest tests/test_llm_outputs.py --junitxml=test-results.xml
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}

      - name: Upload test results
        uses: actions/upload-artifact@v3
        with:
          name: test-results
          path: test-results.xml
```

```python
# tests/test_llm_outputs.py
import pytest
from deepeval import assert_test
from deepeval.test_case import LLMTestCase
from deepeval.metrics import HallucinationMetric

def test_product_review_no_hallucination():
    """è£½å“ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”Ÿæˆæ™‚ã®Hallucinationæ¤œå‡ºãƒ†ã‚¹ãƒˆ"""
    test_case = LLMTestCase(
        input="iPhone 15ã®ç‰¹å¾´ã¯ï¼Ÿ",
        actual_output=generate_review("iPhone 15"),  # LLMå‘¼ã³å‡ºã—é–¢æ•°
        context=["iPhone 15ã¯2023å¹´9æœˆç™ºå£²ã€USB-Cæ­è¼‰ã€..."],
    )

    metric = HallucinationMetric(threshold=0.7)
    assert_test(test_case, [metric])

def generate_review(product: str) -> str:
    # å®Ÿéš›ã®LLMå‘¼ã³å‡ºã—ãƒ­ã‚¸ãƒƒã‚¯
    pass
```

**ã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®åˆ©ç‚¹:**
- **è‡ªå‹•åŒ–**: PRä½œæˆæ™‚ã«è‡ªå‹•ã§LLMå‡ºåŠ›ã‚’æ¤œè¨¼
- **å›å¸°é˜²æ­¢**: éå»ã®æˆåŠŸäº‹ä¾‹ã‚’ãƒ†ã‚¹ãƒˆã¨ã—ã¦ä¿å­˜
- **å“è³ªã‚²ãƒ¼ãƒˆ**: ãƒ†ã‚¹ãƒˆå¤±æ•—æ™‚ã¯ãƒãƒ¼ã‚¸ã‚’ãƒ–ãƒ­ãƒƒã‚¯

## Deepchecksã«ã‚ˆã‚‹ç•°å¸¸æ¤œçŸ¥ï¼ˆDrift Detectionï¼‰

### æœ¬ç•ªç’°å¢ƒã§ã®ç¶™ç¶šçš„ç›£è¦–

Deepchecksã¯ã€**æœ¬ç•ªç’°å¢ƒã§ã®LLMå‡ºåŠ›ã®å¤‰åŒ–ï¼ˆdriftï¼‰ã‚’æ¤œå‡º**ã—ã€å“è³ªåŠ£åŒ–ã‚’æ—©æœŸç™ºè¦‹ã—ã¾ã™ã€‚

```python
# pip install deepchecks-llm
from deepchecks_llm import LLMChecker
from deepchecks_llm.suites import production_suite

# æœ¬ç•ªç’°å¢ƒã®ãƒ‡ãƒ¼ã‚¿ã‚’åé›†ï¼ˆç›´è¿‘1é€±é–“ï¼‰
production_data = fetch_production_logs(days=7)

# Deepchecksã§ç•°å¸¸æ¤œçŸ¥
checker = LLMChecker()
suite = production_suite()

# æ¤œè¨¼å®Ÿè¡Œ
result = suite.run(production_data)

# ç•°å¸¸æ¤œçŸ¥æ™‚ã¯ã‚¢ãƒ©ãƒ¼ãƒˆ
if result.passed() is False:
    send_alert_to_slack(f"LLMå‡ºåŠ›ã«ç•°å¸¸ã‚’æ¤œå‡º: {result.get_failures()}")
```

### æ¤œå‡ºã§ãã‚‹ç•°å¸¸ã®ä¾‹

| ç•°å¸¸ã‚¿ã‚¤ãƒ— | èª¬æ˜ | å¯¾å¿œç­– |
|-----------|------|--------|
| **Performance Drift** | ãƒ¬ã‚¹ãƒãƒ³ã‚¹å“è³ªã®ä½ä¸‹ | ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå†èª¿æ•´ã€ãƒ¢ãƒ‡ãƒ«å†è¨“ç·´ |
| **Data Drift** | å…¥åŠ›ãƒ‡ãƒ¼ã‚¿åˆ†å¸ƒã®å¤‰åŒ– | ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®ç¢ºèª |
| **Bias Drift** | æ–°ãŸãªãƒã‚¤ã‚¢ã‚¹ã®ç™ºç”Ÿ | Safety Validationã®å¼·åŒ– |

## 3å±¤æˆ¦ç•¥ã®çµ±åˆå®Ÿè£…ä¾‹

### ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ã®ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

3å±¤ã™ã¹ã¦ã‚’çµ±åˆã—ãŸå®Ÿè£…ä¾‹ã‚’ç¤ºã—ã¾ã™ã€‚

```python
from pydantic import BaseModel, Field
from guardrails import Guard
from guardrails.hub import DetectPII, ToxicLanguage, ValidLength
from deepeval.metrics import HallucinationMetric
from deepeval.test_case import LLMTestCase
import openai

class ProductReview(BaseModel):
    rating: int = Field(..., ge=1, le=5)
    sentiment: str
    summary: str

def validate_llm_output(user_input: str, context: list[str]) -> ProductReview:
    """3å±¤ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ä»˜ãLLMå‡ºåŠ›ç”Ÿæˆ"""

    # Layer 1: Schema + Safety Validation (Guardrails AI)
    guard = Guard.from_pydantic(
        output_class=ProductReview,
        validators=[
            ValidLength(min=10, max=200, on="summary", on_fail="reask"),
            DetectPII(on_fail="exception"),
            ToxicLanguage(threshold=0.8, on_fail="filter"),
        ]
    )

    # LLMå‘¼ã³å‡ºã—
    response = guard(
        openai.chat.completions.create,
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": user_input}],
        max_tokens=1024,
    )

    validated_output: ProductReview = response.validated_output

    # Layer 2: Semantic Validation (DeepEval)
    test_case = LLMTestCase(
        input=user_input,
        actual_output=validated_output.summary,
        context=context,
    )

    hallucination_metric = HallucinationMetric(threshold=0.7)
    if not hallucination_metric.measure(test_case):
        raise ValueError("Hallucination detected in summary")

    return validated_output

# å®Ÿè¡Œä¾‹
try:
    result = validate_llm_output(
        user_input="ã“ã®è£½å“ã¯ç´ æ™´ã‚‰ã—ã„ã€‚5ã¤æ˜Ÿã§ã™ï¼",
        context=["è£½å“ãƒ¬ãƒ“ãƒ¥ãƒ¼: é«˜è©•ä¾¡ã€æ¨å¥¨å•†å“"],
    )
    print(result.summary)
except Exception as e:
    logger.error(f"Validation failed: {e}")
```

## ã‚ˆãã‚ã‚‹å•é¡Œã¨è§£æ±ºæ–¹æ³•

| å•é¡Œ | åŸå›  | è§£æ±ºæ–¹æ³• |
|------|------|----------|
| **ReaskãŒç„¡é™ãƒ«ãƒ¼ãƒ—** | `max_reasks`æœªè¨­å®š | `max_reasks=2`ã‚’è¨­å®šã—ã€ä¸Šé™ã‚’è¨­ã‘ã‚‹ |
| **ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·å¢—åŠ ** | å¤šæ®µéšãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ | éåŒæœŸå‡¦ç†ã€ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°æ´»ç”¨ |
| **PIIæ¤œå‡ºã®èª¤æ¤œçŸ¥** | é–¾å€¤è¨­å®šãŒå³ã—ã™ãã‚‹ | `threshold`ã‚’èª¿æ•´ï¼ˆä¾‹: 0.8 â†’ 0.9ï¼‰ |
| **Hallucinationæ¤œå‡ºå¤±æ•—** | `context`ãŒä¸ååˆ† | RAGç­‰ã§é«˜å“è³ªãªå‚ç…§æƒ…å ±ã‚’æä¾› |

## æ—¢å­˜ã®æ¤œè¨¼æ‰‹æ³•ã¨ã®æ¯”è¼ƒ

æœ¬è¨˜äº‹ã§ç´¹ä»‹ã—ãŸæ‰‹æ³•ã¨ã€æ—¢å­˜ã®æ¤œè¨¼ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®æ¯”è¼ƒã‚’ç¤ºã—ã¾ã™ã€‚

| æ‰‹æ³• | å¯¾è±¡ | å¼·ã¿ | åˆ¶ç´„ | é–¢é€£è¨˜äº‹ |
|------|------|------|------|---------|
| **Pydanticå˜ä½“** | Schema | ã‚·ãƒ³ãƒ—ãƒ«ã€å‹å®‰å…¨ | å®‰å…¨æ€§ãƒ»æ„å‘³æ¤œè¨¼ãªã— | [LLMå‡ºåŠ›æ¤œè¨¼ã®å®Ÿè·µï¼šPydanticã§95%ç²¾åº¦ã‚’å®Ÿç¾ã™ã‚‹3å±¤æˆ¦ç•¥](https://zenn.dev/0h_n0/articles/0a8f4d0e7c71bf) |
| **Guardrails AI** | Schema + Safety | è‡ªå‹•ä¿®å¾©ã€60+ãƒãƒªãƒ‡ãƒ¼ã‚¿ | ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã‚³ã‚¹ãƒˆå¢— | ï¼ˆæœ¬è¨˜äº‹ï¼‰ |
| **DeepEval** | Semantic | æœ€æ–°ç ”ç©¶ãƒ™ãƒ¼ã‚¹ã€CI/CDçµ±åˆ | ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚„ã‚„è¤‡é›‘ | ï¼ˆæœ¬è¨˜äº‹ï¼‰ |
| **Deepchecks** | Drift Detection | æœ¬ç•ªç›£è¦–ç‰¹åŒ– | ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¤œè¨¼ã«ã¯ä¸å‘ã | ï¼ˆæœ¬è¨˜äº‹ï¼‰ |
| **å“è³ªè©•ä¾¡è‡ªå‹•åŒ–** | End-to-End | ã‚³ã‚¹ãƒˆ500å€å‰Šæ¸› | åˆæœŸè¨­å®šã®å­¦ç¿’æ›²ç·š | [LLMå“è³ªè©•ä¾¡ã®å®Œå…¨è‡ªå‹•åŒ–ï¼š85%ç²¾åº¦ã¨ã‚³ã‚¹ãƒˆ500å€å‰Šæ¸›ã‚’å®Ÿç¾ã™ã‚‹å®Ÿè·µã‚¬ã‚¤ãƒ‰](https://zenn.dev/0h_n0/articles/023494dba67663) |

## ã¾ã¨ã‚ã¨æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

**ã¾ã¨ã‚:**
- **3å±¤æˆ¦ç•¥**ï¼ˆSchemaãƒ»Safetyãƒ»Semanticï¼‰ã§åŒ…æ‹¬çš„ãªå“è³ªä¿è¨¼ã‚’å®Ÿç¾
- **Guardrails AI + Pydantic**ã§99%ã®æˆåŠŸç‡ã‚’é”æˆï¼ˆ2æ®µéšæ¤œè¨¼ï¼‰
- **DeepEval CI/CDçµ±åˆ**ã§ç¶™ç¶šçš„ãªå“è³ªä¿è¨¼ã‚’è‡ªå‹•åŒ–
- **Deepchecks**ã§æœ¬ç•ªç’°å¢ƒã®ç•°å¸¸æ¤œçŸ¥ï¼ˆdrift detectionï¼‰ã‚’å®Ÿç¾
- 2026å¹´æ™‚ç‚¹ã§ã¯**ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ãŒå¿…é ˆè¦ä»¶**

**æ¬¡ã«ã‚„ã‚‹ã¹ãã“ã¨:**
- Guardrails AIã®[å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](https://www.guardrailsai.com/docs/getting_started/quickstart)ã§ãƒãƒªãƒ‡ãƒ¼ã‚¿ã‚’æ¢ç´¢
- DeepEvalã‚’æ—¢å­˜ã®CI/CDãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã«çµ±åˆï¼ˆGitHub Actionsã€GitLab CIç­‰ï¼‰
- Deepchecksã§æœ¬ç•ªç’°å¢ƒã®ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‚’æ§‹ç¯‰
- è‡ªç¤¾ã®LLMã‚¢ãƒ—ãƒªã«3å±¤æˆ¦ç•¥ã‚’æ®µéšçš„ã«å°å…¥ï¼ˆã¾ãšã¯Schema Validationã‹ã‚‰ï¼‰

## å‚è€ƒ

- [Guardrails AI å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](https://www.guardrailsai.com/docs/getting_started/quickstart)
- [GitHub - guardrails-ai/guardrails: Adding guardrails to large language models](https://github.com/guardrails-ai/guardrails)
- [GitHub - confident-ai/deepeval: The LLM Evaluation Framework](https://github.com/confident-ai/deepeval)
- [How to Build an LLM Evaluation Framework in 2025: Steps and Components | Deepchecks](https://www.deepchecks.com/llm-evaluation/framework/)
- [LLM Evaluation: Frameworks, Metrics, and Best Practices (2026 Edition) | Medium](https://medium.com/@future_agi/llm-evaluation-frameworks-metrics-and-best-practices-2026-edition-162790f831f4)
- [The 2026 State of LLM Security: Key Findings and Benchmarks](https://brightsec.com/blog/the-2026-state-of-llm-security-key-findings-and-benchmarks/)
- [LLM guardrails: Best practices for deploying LLM apps securely | Datadog](https://www.datadoghq.com/blog/llm-guardrails-best-practices/)
- [pydantic-ai-guardrails Â· PyPI](https://pypi.org/project/pydantic-ai-guardrails/)
- [The guide to structured outputs and function calling with LLMs](https://agenta.ai/blog/the-guide-to-structured-outputs-and-function-calling-with-llms)
- [How JSON Schema Works for LLM Data | Latitude](https://latitude.so/blog/how-json-schema-works-for-llm-data)

è©³ç´°ãªãƒªã‚µãƒ¼ãƒå†…å®¹ã¯ [Issue #115](https://github.com/0h-n0/zen-auto-create-article/issues/115) ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚

---

:::message
ã“ã®è¨˜äº‹ã¯AIï¼ˆClaude Codeï¼‰ã«ã‚ˆã‚Šè‡ªå‹•ç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚å†…å®¹ã®æ­£ç¢ºæ€§ã«ã¤ã„ã¦ã¯è¤‡æ•°ã®æƒ…å ±æºã§æ¤œè¨¼ã—ã¦ã„ã¾ã™ãŒã€å®Ÿéš›ã®åˆ©ç”¨æ™‚ã¯å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚‚ã”ç¢ºèªãã ã•ã„ã€‚
:::
