---
title: "LangGraph Store APIã§å®Ÿè£…ã™ã‚‹ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆRAGã®å…±æœ‰ãƒ¡ãƒ¢ãƒªã¨é•·æœŸè¨˜æ†¶"
emoji: "ğŸ§ "
type: "tech"
topics: ["langgraph", "rag", "claude", "python", "llm"]
published: false
---

# LangGraph Store APIã§å®Ÿè£…ã™ã‚‹ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆRAGã®å…±æœ‰ãƒ¡ãƒ¢ãƒªã¨é•·æœŸè¨˜æ†¶

## ã“ã®è¨˜äº‹ã§ã‚ã‹ã‚‹ã“ã¨

- LangGraphã®Store APIã‚’ä½¿ã£ãŸ**ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆé–“ãƒ¡ãƒ¢ãƒªå…±æœ‰**ã®åå‰ç©ºé–“è¨­è¨ˆãƒ‘ã‚¿ãƒ¼ãƒ³
- Checkpointerï¼ˆçŸ­æœŸãƒ¡ãƒ¢ãƒªï¼‰ã¨Storeï¼ˆé•·æœŸãƒ¡ãƒ¢ãƒªï¼‰ã®**2å±¤ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£**ã‚’RAGã«é©ç”¨ã™ã‚‹æ–¹æ³•
- LangMem SDKã«ã‚ˆã‚‹**ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒ»ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ãƒ»æ‰‹ç¶šãè¨˜æ†¶**ã®è‡ªå‹•æŠ½å‡ºã¨ç®¡ç†
- PostgresStore + pgvectorã‚’ä½¿ã£ãŸ**ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ä»˜ãé•·æœŸè¨˜æ†¶**ã®æœ¬ç•ªå®Ÿè£…
- Claude Sonnet 4.6ã®context compactionã¨çµ„ã¿åˆã‚ã›ãŸ**ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ã®æœ€é©åŒ–**æ‰‹æ³•

## å¯¾è±¡èª­è€…

- **æƒ³å®šèª­è€…**: ä¸­ç´šã€œä¸Šç´šã®Pythonã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã§LLMã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆé–‹ç™ºçµŒé¨“è€…
- **å¿…è¦ãªå‰æçŸ¥è­˜**:
  - Python 3.11+ã®éåŒæœŸãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ï¼ˆasync/awaitï¼‰
  - LangGraph 1.0ã®åŸºæœ¬æ¦‚å¿µï¼ˆStateGraphã€ãƒãƒ¼ãƒ‰ã€ã‚¨ãƒƒã‚¸ï¼‰
  - RAGï¼ˆRetrieval-Augmented Generationï¼‰ã®åŸºæœ¬ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£
  - Claude APIã®åŸºæœ¬çš„ãªåˆ©ç”¨çµŒé¨“

:::message
æœ¬è¨˜äº‹ã¯[LangGraphÃ—Claude Sonnet 4.6ã§Long-running Agentã®ãƒ¡ãƒ¢ãƒªç®¡ç†ã¨çŠ¶æ…‹å¾©å…ƒã‚’å®Ÿè£…ã™ã‚‹](https://zenn.dev/0h_n0/articles/fd7bc0dd19ca69)ã®ç™ºå±•ç‰ˆã§ã™ã€‚å‰å›ã¯å˜ä¸€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒ¡ãƒ¢ãƒªç®¡ç†ã‚’æ‰±ã„ã¾ã—ãŸãŒã€æœ¬è¨˜äº‹ã§ã¯**ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆRAG**ã«ãŠã‘ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆé–“ãƒ¡ãƒ¢ãƒªå…±æœ‰ã¨é•·æœŸè¨˜æ†¶ç®¡ç†ã«ç„¦ç‚¹ã‚’å½“ã¦ã¾ã™ã€‚ã¾ãŸ[LangGraphÃ—Claude APIãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆRAGã®æœ¬ç•ªé‹ç”¨ã¨ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·æœ€é©åŒ–](https://zenn.dev/0h_n0/articles/dd3f1cd035e262)ã§ã®Stateç®¡ç†ã®çŸ¥è¦‹ã‚‚ãƒ™ãƒ¼ã‚¹ã«ã—ã¦ã„ã¾ã™ã€‚
:::

## çµè«–ãƒ»æˆæœ

LangGraph 1.0ã®Store APIã¨LangMem SDKã‚’çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§ã€ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆRAGã«**ã‚¯ãƒ­ã‚¹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆé•·æœŸè¨˜æ†¶**ã‚’å®Ÿè£…ã§ãã¾ã™ã€‚å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«ã‚ˆã‚‹ã¨ã€Store APIã®åå‰ç©ºé–“ãƒ™ãƒ¼ã‚¹è¨­è¨ˆã«ã‚ˆã‚Šã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆé–“ã®ãƒ¡ãƒ¢ãƒªåˆ†é›¢ã¨å…±æœ‰ã‚’æŸ”è»Ÿã«åˆ¶å¾¡å¯èƒ½ã§ã™ã€‚

æœ¬è¨˜äº‹ã§æ§‹ç¯‰ã™ã‚‹ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®ç‰¹å¾´ã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™ã€‚

| æŒ‡æ¨™ | å¾“æ¥ï¼ˆStateå…±æœ‰ã®ã¿ï¼‰ | Store API + LangMemå°å…¥å¾Œ |
|------|---------------------|--------------------------|
| ãƒ¡ãƒ¢ãƒªã‚¹ã‚³ãƒ¼ãƒ— | ã‚¹ãƒ¬ãƒƒãƒ‰å†…ã®ã¿ | ã‚¯ãƒ­ã‚¹ã‚¹ãƒ¬ãƒƒãƒ‰ãƒ»ã‚¯ãƒ­ã‚¹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ |
| ãƒ¡ãƒ¢ãƒªæ°¸ç¶šæ€§ | ã‚°ãƒ©ãƒ•å®Ÿè¡Œä¸­ã®ã¿ | PostgreSQL/MongoDBã§æ°¸ç¶šåŒ– |
| æ¤œç´¢æ–¹å¼ | ã‚­ãƒ¼å®Œå…¨ä¸€è‡´ | ãƒ™ã‚¯ãƒˆãƒ«é¡ä¼¼åº¦æ¤œç´¢ + ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ«ã‚¿ |
| ãƒ¡ãƒ¢ãƒªã‚¿ã‚¤ãƒ— | ä¼šè©±å±¥æ­´ã®ã¿ | ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒ»ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ãƒ»æ‰‹ç¶šãã®3ç¨® |
| è‡ªå‹•æŠ½å‡º | ãªã— | LangMemãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ |

> **åˆ¶ç´„**: Store APIã¯LangGraph 1.0ä»¥é™ã§åˆ©ç”¨å¯èƒ½ã§ã™ã€‚0.xç³»ã‹ã‚‰ã®ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§ã¯ `langgraph.prebuilt` ãŒéæ¨å¥¨ã¨ãªã‚Š `langchain.agents` ã«ç§»è¡Œã•ã‚Œã¦ã„ã‚‹ç‚¹ã«æ³¨æ„ã—ã¦ãã ã•ã„ã€‚ã¾ãŸã€ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã«ã¯pgvectoræ‹¡å¼µï¼ˆPostgresStoreï¼‰ã¾ãŸã¯Atlas Vector Searchï¼ˆMongoDBStoreï¼‰ãŒå¿…è¦ã§ã™ã€‚

## ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆRAGã®ãƒ¡ãƒ¢ãƒªã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’è¨­è¨ˆã™ã‚‹

ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆRAGã§ã¯ã€è¤‡æ•°ã®å°‚é–€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼ˆQuery Analyzerã€Retrieverã€Verifierã€Synthesizerç­‰ï¼‰ãŒå”èª¿ã—ã¦å›ç­”ã‚’ç”Ÿæˆã—ã¾ã™ã€‚ã“ã®ã¨ãã€**ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆé–“ã§ã©ã®æƒ…å ±ã‚’å…±æœ‰ã—ã€ã©ã®æƒ…å ±ã‚’åˆ†é›¢ã™ã‚‹ã‹**ãŒã‚·ã‚¹ãƒ†ãƒ ã®å“è³ªã‚’å·¦å³ã—ã¾ã™ã€‚

### 2å±¤ãƒ¡ãƒ¢ãƒªã®å½¹å‰²åˆ†æ‹…ã‚’ç†è§£ã™ã‚‹

LangGraphã¯**çŸ­æœŸãƒ¡ãƒ¢ãƒªï¼ˆCheckpointerï¼‰**ã¨**é•·æœŸãƒ¡ãƒ¢ãƒªï¼ˆStoreï¼‰**ã‚’æ˜ç¢ºã«åˆ†é›¢ã—ãŸ2å±¤ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’æ¡ç”¨ã—ã¦ã„ã¾ã™ã€‚å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«ã‚ˆã‚‹ã¨ã€ã€ŒCheckpointerã¯ã‚°ãƒ©ãƒ•ã®ã‚¹ãƒ¼ãƒ‘ãƒ¼ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã«ã‚¹ãƒ†ãƒ¼ãƒˆã®ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã‚’ä¿å­˜ã™ã‚‹ã€ä»•çµ„ã¿ã§ã™ã€‚

```python
# memory_architecture.py
from langgraph.checkpoint.postgres import PostgresSaver
from langgraph.store.postgres import PostgresStore
from langchain_anthropic import ChatAnthropic

# çŸ­æœŸãƒ¡ãƒ¢ãƒª: ã‚¹ãƒ¬ãƒƒãƒ‰ã‚¹ã‚³ãƒ¼ãƒ—ã®ä¼šè©±çŠ¶æ…‹
# 1ã¤ã®RAGã‚»ãƒƒã‚·ãƒ§ãƒ³å†…ã®ã‚¯ã‚¨ãƒªå±¥æ­´ãƒ»æ¤œç´¢çµæœã‚’ä¿æŒ
checkpointer = PostgresSaver.from_conn_string(
    "postgresql://user:pass@localhost:5432/rag_memory"
)

# é•·æœŸãƒ¡ãƒ¢ãƒª: ã‚¯ãƒ­ã‚¹ã‚¹ãƒ¬ãƒƒãƒ‰ãƒ»ã‚¯ãƒ­ã‚¹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®æ°¸ç¶šè¨˜æ†¶
# éå»ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã§å­¦ã‚“ã çŸ¥è­˜ãƒ»ãƒ¦ãƒ¼ã‚¶ãƒ¼å—œå¥½ãƒ»æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ä¿æŒ
store = PostgresStore.from_conn_string(
    "postgresql://user:pass@localhost:5432/rag_memory",
    index={
        "dims": 1024,
        "embed": lambda texts: anthropic_embed(texts),  # å¾Œè¿°ã®å®Ÿè£…
        "fields": ["content", "metadata.summary"],
    },
)

llm = ChatAnthropic(
    model="claude-sonnet-4-6-20250514",
    max_tokens=8192,
)
```

**ãªãœ2å±¤ã«åˆ†é›¢ã™ã‚‹ã®ã‹:**
- **çŸ­æœŸãƒ¡ãƒ¢ãƒªï¼ˆCheckpointerï¼‰**: 1å›ã®RAGã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ä¸­é–“çŠ¶æ…‹ï¼ˆã‚¯ã‚¨ãƒªè§£æçµæœã€æ¤œç´¢ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆï¼‰ã‚’ä¿æŒã€‚ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ‚äº†å¾Œã¯ä¸è¦
- **é•·æœŸãƒ¡ãƒ¢ãƒªï¼ˆStoreï¼‰**: ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’è·¨ã„ã§æœ‰ç”¨ãªçŸ¥è­˜ï¼ˆæ¤œç´¢å‚¾å‘ã€ã‚¯ã‚¨ãƒªæ›¸ãæ›ãˆãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰ã‚’è“„ç©

> æœ€åˆã¯çŸ­æœŸãƒ¡ãƒ¢ãƒªã ã‘ã§ååˆ†ã¨è€ƒãˆã¾ã—ãŸãŒã€RAGã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’é‡ã­ã‚‹ã†ã¡ã«ã€ŒåŒã˜ã‚¯ã‚¨ãƒªãƒ‘ã‚¿ãƒ¼ãƒ³ã§åŒã˜å¤±æ•—ã‚’ç¹°ã‚Šè¿”ã™ã€å•é¡ŒãŒç™ºç”Ÿã—ã¾ã™ã€‚é•·æœŸãƒ¡ãƒ¢ãƒªã«æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è“„ç©ã™ã‚‹ã“ã¨ã§å›é¿ã§ãã¾ã™ã€‚

### åå‰ç©ºé–“è¨­è¨ˆã§ãƒ¡ãƒ¢ãƒªã®åˆ†é›¢ã¨å…±æœ‰ã‚’åˆ¶å¾¡ã™ã‚‹

Store APIã®åå‰ç©ºé–“ã¯ã‚¿ãƒ—ãƒ«ãƒ™ãƒ¼ã‚¹ã®éšå±¤æ§‹é€ ã‚’æ¡ç”¨ã—ã¦ã„ã¾ã™ã€‚ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆRAGã§ã¯ã€ã“ã®åå‰ç©ºé–“è¨­è¨ˆãŒ**ãƒ¡ãƒ¢ãƒªã®å¯è¦–æ€§åˆ¶å¾¡**ã®éµã«ãªã‚Šã¾ã™ã€‚

```python
# namespace_design.py
from langgraph.store.base import BaseStore

def design_rag_namespaces(user_id: str, session_id: str) -> dict[str, tuple[str, ...]]:
    """ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆRAGã®åå‰ç©ºé–“è¨­è¨ˆ

    3å±¤ã®åå‰ç©ºé–“ã§ãƒ¡ãƒ¢ãƒªã®å¯è¦–æ€§ã‚’åˆ¶å¾¡:
    - ã‚°ãƒ­ãƒ¼ãƒãƒ«: å…¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒèª­ã¿æ›¸ãå¯èƒ½
    - ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå›ºæœ‰: ç‰¹å®šã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ã¿èª­ã¿æ›¸ãå¯èƒ½
    - ãƒ¦ãƒ¼ã‚¶ãƒ¼å›ºæœ‰: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã”ã¨ã«åˆ†é›¢ã•ã‚ŒãŸå€‹äººè¨­å®š
    """
    return {
        # å…¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå…±æœ‰: æ¤œç´¢çµæœã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
        "shared_knowledge": ("rag", "shared", "knowledge"),
        # å…¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå…±æœ‰: ã‚¯ã‚¨ãƒªæ›¸ãæ›ãˆæˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³
        "shared_patterns": ("rag", "shared", "query_patterns"),
        # Query Analyzerå°‚ç”¨: ã‚¯ã‚¨ãƒªåˆ†é¡ãƒ«ãƒ¼ãƒ«
        "query_analyzer": ("rag", "agents", "query_analyzer"),
        # Retrieverå°‚ç”¨: ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹é¸æŠå±¥æ­´
        "retriever": ("rag", "agents", "retriever"),
        # Verifierå°‚ç”¨: æ¤œè¨¼åŸºæº–ãƒ»é–¾å€¤
        "verifier": ("rag", "agents", "verifier"),
        # Synthesizerå°‚ç”¨: å›ç­”ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ»ãƒˆãƒ¼ãƒ³è¨­å®š
        "synthesizer": ("rag", "agents", "synthesizer"),
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼å›ºæœ‰: æ¤œç´¢å—œå¥½ãƒ»ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯å±¥æ­´
        "user_preferences": ("rag", "users", user_id, "preferences"),
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³å›ºæœ‰: ç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ãƒ¡ãƒ¢ãƒªï¼ˆTTLã§è‡ªå‹•å‰Šé™¤ï¼‰
        "session_cache": ("rag", "sessions", session_id),
    }
```

**ãªãœ3å±¤ã®åå‰ç©ºé–“ãŒå¿…è¦ã‹:**

| å±¤ | ã‚¹ã‚³ãƒ¼ãƒ— | ç”¨é€” | TTL |
|----|---------|------|-----|
| ã‚°ãƒ­ãƒ¼ãƒãƒ«å…±æœ‰ | å…¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ | æ¤œç´¢ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã€æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³ | ãªã—ï¼ˆæ°¸ç¶šï¼‰ |
| ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå›ºæœ‰ | å„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ | å°‚é–€çŸ¥è­˜ã€ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ | ãªã—ï¼ˆæ°¸ç¶šï¼‰ |
| ãƒ¦ãƒ¼ã‚¶ãƒ¼å›ºæœ‰ | ãƒ¦ãƒ¼ã‚¶ãƒ¼ã”ã¨ | æ¤œç´¢å—œå¥½ã€ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ | 90æ—¥ |
| ã‚»ãƒƒã‚·ãƒ§ãƒ³å›ºæœ‰ | ã‚»ãƒƒã‚·ãƒ§ãƒ³ã”ã¨ | ä¸­é–“è¨ˆç®—çµæœã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ | 24æ™‚é–“ |

**æ³¨æ„ç‚¹:**
> åå‰ç©ºé–“ã®ã‚¿ãƒ—ãƒ«ã«ã¯ç©ºæ–‡å­—ã‚„ãƒ‰ãƒƒãƒˆã‚’å«ã‚ã‚‹ã“ã¨ã¯ã§ãã¾ã›ã‚“ã€‚ã¾ãŸã€`("langgraph",)` ã§å§‹ã¾ã‚‹ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã¯ã‚·ã‚¹ãƒ†ãƒ äºˆç´„ã•ã‚Œã¦ã„ã‚‹ãŸã‚ä½¿ç”¨ã§ãã¾ã›ã‚“ã€‚å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«æ˜è¨˜ã•ã‚Œã¦ã„ã‚‹åˆ¶ç´„ã§ã™ã€‚

## Store APIã§ã‚¯ãƒ­ã‚¹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ¡ãƒ¢ãƒªå…±æœ‰ã‚’å®Ÿè£…ã™ã‚‹

å®Ÿéš›ã«Store APIã‚’ä½¿ã£ã¦ã€ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆRAGã®å„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒãƒ¡ãƒ¢ãƒªã‚’èª­ã¿æ›¸ãã™ã‚‹å®Ÿè£…ã‚’è¦‹ã¦ã„ãã¾ã—ã‚‡ã†ã€‚

### ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå…±æœ‰ãƒ¡ãƒ¢ãƒªã®èª­ã¿æ›¸ããƒ‘ã‚¿ãƒ¼ãƒ³

```python
# shared_memory.py
from typing import Annotated, TypedDict
from langgraph.store.base import BaseStore
from langgraph.graph import StateGraph
from langchain_core.runnables import RunnableConfig
import uuid

class RAGState(TypedDict):
    """ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆRAGã®å…±æœ‰State"""
    query: str
    rewritten_query: str
    search_results: list[dict]
    verified_results: list[dict]
    answer: str
    quality_score: float

async def query_analyzer_node(
    state: RAGState,
    config: RunnableConfig,
    *,
    store: BaseStore,
) -> dict:
    """Query Analyzerãƒãƒ¼ãƒ‰: ã‚¯ã‚¨ãƒªã‚’è§£æã—ã€éå»ã®æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ´»ç”¨"""
    query = state["query"]

    # å…±æœ‰ãƒ¡ãƒ¢ãƒªã‹ã‚‰éå»ã®ã‚¯ã‚¨ãƒªæ›¸ãæ›ãˆãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œç´¢ï¼ˆã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢ï¼‰
    past_patterns = await store.asearch(
        ("rag", "shared", "query_patterns"),
        query=query,
        limit=5,
    )

    # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå›ºæœ‰ãƒ¡ãƒ¢ãƒªã‹ã‚‰ã‚¯ã‚¨ãƒªåˆ†é¡ãƒ«ãƒ¼ãƒ«ã‚’å–å¾—
    classification_rules = await store.aget(
        ("rag", "agents", "query_analyzer"),
        "classification_rules",
    )

    # Claude Sonnet 4.6ã§ã‚¯ã‚¨ãƒªã‚’è§£æãƒ»æ›¸ãæ›ãˆ
    rewritten = await analyze_and_rewrite(
        query=query,
        past_patterns=[p.value for p in past_patterns],
        rules=classification_rules.value if classification_rules else None,
        llm=llm,
    )

    return {"rewritten_query": rewritten}


async def retriever_node(
    state: RAGState,
    config: RunnableConfig,
    *,
    store: BaseStore,
) -> dict:
    """Retrieverãƒãƒ¼ãƒ‰: æ¤œç´¢ã‚’å®Ÿè¡Œã—ã€çµæœã‚’ãƒ¡ãƒ¢ãƒªã«ä¿å­˜"""
    rewritten_query = state["rewritten_query"]

    # å…±æœ‰ãƒ¡ãƒ¢ãƒªã‹ã‚‰ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æ¤œç´¢
    cached_docs = await store.asearch(
        ("rag", "shared", "knowledge"),
        query=rewritten_query,
        limit=3,
    )

    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆç‡ãŒé«˜ã„å ´åˆã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æ´»ç”¨
    if cached_docs and cached_docs[0].score > 0.9:
        results = [doc.value for doc in cached_docs]
    else:
        # ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã‹ã‚‰æ¤œç´¢ã‚’å®Ÿè¡Œ
        results = await vector_store_search(rewritten_query)

        # æ¤œç´¢çµæœã‚’å…±æœ‰ãƒ¡ãƒ¢ãƒªã«ä¿å­˜ï¼ˆæ¬¡å›ä»¥é™ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼‰
        for doc in results:
            await store.aput(
                ("rag", "shared", "knowledge"),
                str(uuid.uuid4()),
                {
                    "content": doc["content"][:500],  # å…ˆé ­500æ–‡å­—ã‚’ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
                    "metadata": {
                        "source": doc["source"],
                        "summary": doc.get("summary", ""),
                        "retrieved_at": "2026-02-23",
                    },
                },
            )

    return {"search_results": results}


async def synthesizer_node(
    state: RAGState,
    config: RunnableConfig,
    *,
    store: BaseStore,
) -> dict:
    """Synthesizerãƒãƒ¼ãƒ‰: æ¤œç´¢çµæœã‹ã‚‰å›ç­”ã‚’ç”Ÿæˆã—ã€æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è¨˜éŒ²"""
    verified_results = state["verified_results"]
    original_query = state["query"]
    rewritten_query = state["rewritten_query"]

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼å›ºæœ‰ãƒ¡ãƒ¢ãƒªã‹ã‚‰å›ç­”ã‚¹ã‚¿ã‚¤ãƒ«è¨­å®šã‚’å–å¾—
    user_id = config.get("configurable", {}).get("user_id", "default")
    user_prefs = await store.aget(
        ("rag", "users", user_id, "preferences"),
        "answer_style",
    )

    answer = await generate_answer(
        query=original_query,
        results=verified_results,
        style=user_prefs.value if user_prefs else None,
        llm=llm,
    )

    # æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å…±æœ‰ãƒ¡ãƒ¢ãƒªã«ä¿å­˜ï¼ˆä»–ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚‚æ´»ç”¨å¯èƒ½ï¼‰
    if state.get("quality_score", 0) > 0.8:
        await store.aput(
            ("rag", "shared", "query_patterns"),
            str(uuid.uuid4()),
            {
                "content": f"Original: {original_query} -> Rewritten: {rewritten_query}",
                "metadata": {
                    "quality_score": state["quality_score"],
                    "result_count": len(verified_results),
                },
            },
        )

    return {"answer": answer}
```

**ãªãœã“ã®å®Ÿè£…ã‚’é¸ã‚“ã ã‹:**
- `store.asearch()` ã§ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢ã‚’ä½¿ã†ã“ã¨ã§ã€**å®Œå…¨ä¸€è‡´ã§ã¯ãªãæ„å‘³çš„ã«é¡ä¼¼ã—ãŸéå»ãƒ‘ã‚¿ãƒ¼ãƒ³**ã‚’ç™ºè¦‹ã§ãã¾ã™
- åå‰ç©ºé–“ã®åˆ†é›¢ã«ã‚ˆã‚Šã€å„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯è‡ªåˆ†ã®å°‚é–€ãƒ¡ãƒ¢ãƒªã«ã®ã¿æ›¸ãè¾¼ã¿ã€å…±æœ‰ãƒ¡ãƒ¢ãƒªã‹ã‚‰ã¯èª­ã¿å–ã‚Šã‚’è¡Œã†**Read-Heavy / Write-Selective**ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å®Ÿç¾ã—ã¾ã™
- `uuid.uuid4()` ã‚’ã‚­ãƒ¼ã«ä½¿ã†ã“ã¨ã§ã€åŒä¸€åå‰ç©ºé–“ã«è¤‡æ•°ã®ãƒ¡ãƒ¢ãƒªã‚’è“„ç©ã§ãã¾ã™

### ã‚°ãƒ©ãƒ•ã®ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã¨Storeæ³¨å…¥

```python
# graph_compile.py
from langgraph.graph import StateGraph, END

def build_rag_graph() -> StateGraph:
    """ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆRAGã‚°ãƒ©ãƒ•ã‚’æ§‹ç¯‰"""
    graph = StateGraph(RAGState)

    graph.add_node("query_analyzer", query_analyzer_node)
    graph.add_node("retriever", retriever_node)
    graph.add_node("verifier", verifier_node)  # å®Ÿè£…çœç•¥
    graph.add_node("synthesizer", synthesizer_node)

    graph.set_entry_point("query_analyzer")
    graph.add_edge("query_analyzer", "retriever")
    graph.add_edge("retriever", "verifier")
    graph.add_edge("verifier", "synthesizer")
    graph.add_edge("synthesizer", END)

    return graph

# Checkpointer + Store ã®ä¸¡æ–¹ã‚’æ³¨å…¥ã—ã¦ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«
app = build_rag_graph().compile(
    checkpointer=checkpointer,  # çŸ­æœŸãƒ¡ãƒ¢ãƒªï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ï¼‰
    store=store,                # é•·æœŸãƒ¡ãƒ¢ãƒªï¼ˆã‚¯ãƒ­ã‚¹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå…±æœ‰ï¼‰
)

# å®Ÿè¡Œæ™‚ã«thread_idã¨user_idã‚’æŒ‡å®š
result = await app.ainvoke(
    {"query": "LangGraphã®Store APIã§ãƒ¡ãƒ¢ãƒªå…±æœ‰ã™ã‚‹ã«ã¯ï¼Ÿ"},
    config={
        "configurable": {
            "thread_id": "session-001",
            "user_id": "user-abc",
        }
    },
)
```

**æ³¨æ„ç‚¹:**
> `compile()` æ™‚ã« `store` ã‚’æ¸¡ã™ã¨ã€ã™ã¹ã¦ã®ãƒãƒ¼ãƒ‰é–¢æ•°ã§ `store: BaseStore` å¼•æ•°ãŒåˆ©ç”¨å¯èƒ½ã«ãªã‚Šã¾ã™ã€‚ã“ã®ä¾å­˜æ³¨å…¥ãƒ‘ã‚¿ãƒ¼ãƒ³ã«ã‚ˆã‚Šã€ãƒ†ã‚¹ãƒˆæ™‚ã«ã¯ `InMemoryStore` ã«å·®ã—æ›¿ãˆã‚‹ã“ã¨ã§å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãªã—ã§ãƒ†ã‚¹ãƒˆã§ãã¾ã™ã€‚

## LangMem SDKã§ãƒ¡ãƒ¢ãƒªã®è‡ªå‹•æŠ½å‡ºã¨ç®¡ç†ã‚’å®Ÿè£…ã™ã‚‹

Store APIã¯ä½ãƒ¬ãƒ™ãƒ«ã®èª­ã¿æ›¸ãã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã§ã™ãŒã€**ä½•ã‚’ãƒ¡ãƒ¢ãƒªã¨ã—ã¦ä¿å­˜ã™ã¹ãã‹**ã®åˆ¤æ–­ã¯ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å´ã§å®Ÿè£…ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚LangMem SDKï¼ˆv0.0.30ï¼‰ã¯ã“ã®åˆ¤æ–­ã‚’è‡ªå‹•åŒ–ã™ã‚‹ãƒ„ãƒ¼ãƒ«ã‚­ãƒƒãƒˆã§ã™ã€‚

### 3ç¨®é¡ã®ãƒ¡ãƒ¢ãƒªã‚¿ã‚¤ãƒ—ã‚’ä½¿ã„åˆ†ã‘ã‚‹

LangMem SDKã¯äººé–“ã®è¨˜æ†¶ãƒ¢ãƒ‡ãƒ«ã«åŸºã¥ãã€3ç¨®é¡ã®ãƒ¡ãƒ¢ãƒªã‚¿ã‚¤ãƒ—ã‚’æä¾›ã—ã¦ã„ã¾ã™ã€‚

| ãƒ¡ãƒ¢ãƒªã‚¿ã‚¤ãƒ— | å†…å®¹ | RAGã§ã®ç”¨é€” | ä¿å­˜å…ˆåå‰ç©ºé–“ä¾‹ |
|------------|------|-----------|----------------|
| **ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯è¨˜æ†¶** | äº‹å®Ÿãƒ»æ¦‚å¿µãƒ»çŸ¥è­˜ | ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã€ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£æƒ…å ± | `("rag", "semantic", entity_type)` |
| **ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰è¨˜æ†¶** | éå»ã®çµŒé¨“ãƒ»ã‚¤ãƒ™ãƒ³ãƒˆ | æˆåŠŸã—ãŸæ¤œç´¢ãƒ‘ã‚¿ãƒ¼ãƒ³ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼è³ªå•å±¥æ­´ | `("rag", "episodic", user_id)` |
| **æ‰‹ç¶šãè¨˜æ†¶** | æ“ä½œæ‰‹é †ãƒ»ãƒ«ãƒ¼ãƒ« | ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æ”¹å–„ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‹•ä½œãƒ«ãƒ¼ãƒ« | `("rag", "procedural", agent_id)` |

```python
# langmem_integration.py
from langmem import create_manage_memory_tool, create_search_memory_tool
from langgraph.store.memory import InMemoryStore
from langchain.agents import create_react_agent

# é–‹ç™ºç’°å¢ƒ: InMemoryStoreï¼ˆæœ¬ç•ªã§ã¯PostgresStoreã«å·®ã—æ›¿ãˆï¼‰
memory_store = InMemoryStore(
    index={
        "dims": 1024,
        "embed": embed_fn,  # Voyage AI or OpenAI embedding
        "fields": ["content"],
    }
)

# ãƒ¡ãƒ¢ãƒªç®¡ç†ãƒ„ãƒ¼ãƒ«: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒä¼šè©±ä¸­ã«ãƒ¡ãƒ¢ãƒªã‚’ä¿å­˜
manage_memory = create_manage_memory_tool(
    namespace=("rag", "semantic", "entities"),
)

# ãƒ¡ãƒ¢ãƒªæ¤œç´¢ãƒ„ãƒ¼ãƒ«: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒéå»ã®ãƒ¡ãƒ¢ãƒªã‚’æ¤œç´¢
search_memory = create_search_memory_tool(
    namespace=("rag", "semantic", "entities"),
)

# RAGã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ãƒ¡ãƒ¢ãƒªãƒ„ãƒ¼ãƒ«ã‚’è¿½åŠ 
rag_agent = create_react_agent(
    model=llm,
    tools=[retrieve_tool, manage_memory, search_memory],
    store=memory_store,
    checkpointer=checkpointer,
)
```

### ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ãƒ¡ãƒ¢ãƒªãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã§éåŒæœŸæŠ½å‡ºã‚’å®Ÿè£…ã™ã‚‹

RAGã®å¿œç­”ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã‚’æ‚ªåŒ–ã•ã›ãšã«ãƒ¡ãƒ¢ãƒªã‚’è“„ç©ã™ã‚‹ã«ã¯ã€**ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å‡¦ç†**ãŒæœ‰åŠ¹ã§ã™ã€‚LangMem SDKã®ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã¯ã€ä¼šè©±çµ‚äº†å¾Œã«éåŒæœŸã§ãƒ¡ãƒ¢ãƒªã‚’æŠ½å‡ºãƒ»çµ±åˆã—ã¾ã™ã€‚

```python
# background_memory.py
from langmem import BackgroundMemoryManager

# ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ãƒ¡ãƒ¢ãƒªãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã®è¨­å®š
memory_manager = BackgroundMemoryManager(
    store=store,
    model=llm,
    # ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯è¨˜æ†¶: ä¼šè©±ã‹ã‚‰äº‹å®Ÿãƒ»ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã‚’è‡ªå‹•æŠ½å‡º
    semantic_namespace=("rag", "semantic", "auto_extracted"),
    # ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰è¨˜æ†¶: æ¤œç´¢ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®è¦ç´„ã‚’ä¿å­˜
    episodic_namespace=("rag", "episodic", "sessions"),
    # æ‰‹ç¶šãè¨˜æ†¶: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‹•ä½œã®æ”¹å–„ãƒ«ãƒ¼ãƒ«ã‚’è“„ç©
    procedural_namespace=("rag", "procedural", "improvements"),
)

async def on_session_complete(
    session_messages: list[dict],
    session_metadata: dict,
) -> None:
    """RAGã‚»ãƒƒã‚·ãƒ§ãƒ³å®Œäº†æ™‚ã«ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§ãƒ¡ãƒ¢ãƒªæŠ½å‡º"""
    await memory_manager.process(
        messages=session_messages,
        metadata={
            "session_id": session_metadata["session_id"],
            "user_id": session_metadata["user_id"],
            "quality_score": session_metadata.get("quality_score"),
        },
    )
```

**ãªãœãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å‡¦ç†ã‚’é¸ã‚“ã ã‹:**
- Hot Pathã§ãƒ¡ãƒ¢ãƒªã‚’æ›¸ãè¾¼ã‚€ã¨LLMã¸ã®è¿½åŠ å‘¼ã³å‡ºã—ã§**ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãŒ200-500mså¢—åŠ **ã—ã¾ã™
- ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§ã¯å¿œç­”å®Œäº†å¾Œã«éåŒæœŸå‡¦ç†ã™ã‚‹ãŸã‚**ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã«å½±éŸ¿ã—ã¾ã›ã‚“**
- ãŸã ã—ã€ä¿å­˜ãƒ¡ãƒ¢ãƒªãŒæ¬¡ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã§å³åº§ã«åˆ©ç”¨ã§ããªã„å ´åˆãŒã‚ã‚Šã¾ã™ã€‚ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ€§ãŒå¿…è¦ãªã‚‰Hot Pathã¨ã®ä½µç”¨ã‚’æ¤œè¨ã—ã¦ãã ã•ã„

## PostgresStore + pgvectorã§æœ¬ç•ªç’°å¢ƒã®é•·æœŸè¨˜æ†¶ã‚’æ§‹ç¯‰ã™ã‚‹

é–‹ç™ºç’°å¢ƒã®`InMemoryStore`ã¯ãƒ—ãƒ­ã‚»ã‚¹çµ‚äº†ã§ãƒ‡ãƒ¼ã‚¿ãŒæ¶ˆå¤±ã™ã‚‹ãŸã‚ã€æœ¬ç•ªç’°å¢ƒã§ã¯**PostgresStore**ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚pgvectoræ‹¡å¼µã«ã‚ˆã‚‹ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ãŒçµ„ã¿è¾¼ã¾ã‚Œã¦ãŠã‚Šã€ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒ¡ãƒ¢ãƒªã®æ¤œç´¢ã«é©ã—ã¦ã„ã¾ã™ã€‚

### æœ¬ç•ªç”¨PostgresStoreã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

```python
# production_store.py
from langgraph.store.postgres import AsyncPostgresStore
import psycopg

# éåŒæœŸç‰ˆPostgresStoreã®åˆæœŸåŒ–ï¼ˆæœ¬ç•ªæ¨å¥¨ï¼‰
async def create_production_store() -> AsyncPostgresStore:
    """æœ¬ç•ªç’°å¢ƒç”¨ã®PostgresStoreã‚’ä½œæˆ

    PostgreSQL 15+ ã¨ pgvector æ‹¡å¼µãŒå¿…è¦:
    CREATE EXTENSION IF NOT EXISTS vector;
    """
    store = AsyncPostgresStore.from_conn_string(
        "postgresql://rag_user:secure_pass@db.example.com:5432/rag_memory",
        index={
            # Voyage AI embedding (1024æ¬¡å…ƒ)
            "dims": 1024,
            "embed": voyage_embed_fn,
            # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å¯¾è±¡ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰
            "fields": ["content", "metadata.summary"],
        },
    )
    # ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ»ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®è‡ªå‹•ä½œæˆ
    await store.setup()
    return store
```

### ãƒ™ã‚¯ãƒˆãƒ«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®é¸æŠåŸºæº–

PostgresStoreã¯pgvectorã®3ç¨®é¡ã®ANNã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™ã€‚å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«ã‚ˆã‚‹ã¨ã€ç”¨é€”ã«å¿œã˜ãŸé¸æŠåŸºæº–ã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™ã€‚

| ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ | æ§‹ç¯‰é€Ÿåº¦ | æ¤œç´¢ç²¾åº¦ï¼ˆRecallï¼‰ | ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ | æ¨å¥¨ç”¨é€” |
|------------|---------|------------------|------------|---------|
| **HNSW** | é…ã„ | é«˜ã„ï¼ˆ99%+ï¼‰ | å¤šã„ | **å¤§åŠã®RAGã‚¢ãƒ—ãƒª**ï¼ˆæ¨å¥¨ï¼‰ |
| **IVFFlat** | é€Ÿã„ | ä¸­ç¨‹åº¦ï¼ˆ95%ç¨‹åº¦ï¼‰ | å°‘ãªã„ | ãƒ¡ãƒ¢ãƒªæ•°100ä¸‡ä»¶ä»¥ä¸Š |
| **Flat** | ãªã— | 100%ï¼ˆå®Œå…¨ä¸€è‡´ï¼‰ | æœ€å° | ãƒ¡ãƒ¢ãƒªæ•°1ä¸‡ä»¶ä»¥ä¸‹ |

**æ³¨æ„ç‚¹:**
> HNSWã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã® `m` ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ16ï¼‰ã¨ `ef_construction`ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ64ï¼‰ã¯ã€ãƒ¡ãƒ¢ãƒªæ•°ãŒ10ä¸‡ä»¶ã‚’è¶…ãˆã‚‹å ´åˆã«ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãŒå¿…è¦ã§ã™ã€‚`m` ã‚’å¢—ã‚„ã™ã¨æ¤œç´¢ç²¾åº¦ã¯å‘ä¸Šã—ã¾ã™ãŒã€ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚µã‚¤ã‚ºãŒå¢—å¤§ã—ã¾ã™ã€‚æœ¬ç•ªæŠ•å…¥å‰ã«ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’å–ã‚‹ã“ã¨ã‚’æ¨å¥¨ã—ã¾ã™ã€‚

### TTLã«ã‚ˆã‚‹ãƒ¡ãƒ¢ãƒªã®è‡ªå‹•ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—

é•·æœŸè¨˜æ†¶ã¯ç„¡åˆ¶é™ã«è“„ç©ã™ã‚‹ã¨ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚³ã‚¹ãƒˆã¨æ¤œç´¢ç²¾åº¦ã®ä¸¡æ–¹ã«æ‚ªå½±éŸ¿ã‚’ä¸ãˆã¾ã™ã€‚PostgresStoreã®TTLæ©Ÿèƒ½ã§ã€ç”¨é€”ã«å¿œã˜ãŸè‡ªå‹•ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚’è¨­å®šã—ã¾ã™ã€‚

```python
# ttl_management.py
# ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚­ãƒ£ãƒƒã‚·ãƒ¥: 24æ™‚é–“ã§è‡ªå‹•å‰Šé™¤
await store.aput(
    ("rag", "sessions", "session-001"),
    "intermediate_results",
    {"rewritten_query": "...", "top_docs": [...]},
    ttl_minutes=1440,
)

# ãƒ¦ãƒ¼ã‚¶ãƒ¼å—œå¥½: 90æ—¥ã§è‡ªå‹•å‰Šé™¤
await store.aput(
    ("rag", "users", "user-abc", "preferences"),
    "answer_style",
    {"tone": "technical", "length": "detailed"},
    ttl_minutes=129600,
)

# å…±æœ‰çŸ¥è­˜: æ°¸ç¶šä¿å­˜ï¼ˆttl_minutesçœç•¥ï¼‰
await store.aput(
    ("rag", "shared", "knowledge"),
    "doc-metadata-001",
    {"content": "LangGraph Store APIã®æ¦‚è¦...", "metadata": {"source": "official_docs"}},
)
```

## Claude Sonnet 4.6ã®context compactionã¨ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ã‚’æœ€é©åŒ–ã™ã‚‹

ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆRAGãŒé•·æ™‚é–“ç¨¼åƒã™ã‚‹ã¨ã€è“„ç©ã•ã‚ŒãŸãƒ¡ãƒ¢ãƒªãŒã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚’åœ§è¿«ã—ã¾ã™ã€‚Claude Sonnet 4.6ã®**context compaction**ï¼ˆãƒ™ãƒ¼ã‚¿ï¼‰ã¯ã€å¤ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’è‡ªå‹•è¦ç´„ã—ã¦æœ‰åŠ¹ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·ã‚’æ‹¡å¤§ã™ã‚‹æ©Ÿèƒ½ã§ã™ã€‚

### ãƒ¡ãƒ¢ãƒªéšå±¤ã¨context compactionã®é€£æº

```python
# context_optimization.py
from langchain_anthropic import ChatAnthropic

# Claude Sonnet 4.6: 200Kæ¨™æº– / 1Mãƒ™ãƒ¼ã‚¿
llm = ChatAnthropic(
    model="claude-sonnet-4-6-20250514",
    max_tokens=8192,
    # context compactionã‚’æœ‰åŠ¹åŒ–ï¼ˆãƒ™ãƒ¼ã‚¿ï¼‰
    model_kwargs={
        "metadata": {"context_compaction": True},
    },
)

async def memory_aware_generation(
    store: AsyncPostgresStore,
    query: str,
    user_id: str,
) -> str:
    """ãƒ¡ãƒ¢ãƒªéšå±¤ã‚’æ´»ç”¨ã—ãŸå›ç­”ç”Ÿæˆ

    ãƒ¡ãƒ¢ãƒªã®å„ªå…ˆé †ä½:
    1. ã‚»ãƒƒã‚·ãƒ§ãƒ³å†…ãƒ¡ãƒ¢ãƒªï¼ˆCheckpointerçµŒç”±ã€æœ€é«˜å„ªå…ˆåº¦ï¼‰
    2. ãƒ¦ãƒ¼ã‚¶ãƒ¼å›ºæœ‰ãƒ¡ãƒ¢ãƒªï¼ˆStoreæ¤œç´¢ã€ä¸­å„ªå…ˆåº¦ï¼‰
    3. ã‚°ãƒ­ãƒ¼ãƒãƒ«å…±æœ‰ãƒ¡ãƒ¢ãƒªï¼ˆStoreæ¤œç´¢ã€ä½å„ªå…ˆåº¦ï¼‰
    """
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼å›ºæœ‰ã®ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰è¨˜æ†¶ã‚’æ¤œç´¢
    user_episodes = await store.asearch(
        ("rag", "episodic", user_id),
        query=query,
        limit=3,
    )

    # ã‚°ãƒ­ãƒ¼ãƒãƒ«å…±æœ‰ã®ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯è¨˜æ†¶ã‚’æ¤œç´¢
    shared_knowledge = await store.asearch(
        ("rag", "semantic", "auto_extracted"),
        query=query,
        limit=5,
    )

    # ãƒ¡ãƒ¢ãƒªã‚’ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«çµ„ã¿è¾¼ã¿ï¼ˆå„ªå…ˆåº¦é †ï¼‰
    memory_context = format_memories(
        user_episodes=[e.value for e in user_episodes],
        shared_knowledge=[k.value for k in shared_knowledge],
    )

    # Claude Sonnet 4.6ã®context compactionãŒå¤ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’è‡ªå‹•åœ§ç¸®
    response = await llm.ainvoke(
        [
            {"role": "system", "content": build_system_prompt(memory_context)},
            {"role": "user", "content": query},
        ]
    )

    return response.content


def format_memories(
    user_episodes: list[dict],
    shared_knowledge: list[dict],
) -> str:
    """ãƒ¡ãƒ¢ãƒªã‚’æ§‹é€ åŒ–ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›"""
    sections = []
    if user_episodes:
        episodes = "\n".join(f"- {ep.get('content', '')}" for ep in user_episodes)
        sections.append(f"## éå»ã®é–¢é€£ã‚»ãƒƒã‚·ãƒ§ãƒ³\n{episodes}")
    if shared_knowledge:
        knowledge = "\n".join(f"- {kn.get('content', '')}" for kn in shared_knowledge)
        sections.append(f"## é–¢é€£çŸ¥è­˜\n{knowledge}")
    return "\n\n".join(sections)
```

**æ³¨æ„ç‚¹:**
> context compactionã¯ãƒ™ãƒ¼ã‚¿æ©Ÿèƒ½ã§ã‚ã‚Šã€æœ¬ç•ªç’°å¢ƒã§ã®åˆ©ç”¨ã¯æ…é‡ã«æ¤œè¨ã—ã¦ãã ã•ã„ã€‚å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«ã‚ˆã‚‹ã¨ã€ã€Œå¤ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’è‡ªå‹•è¦ç´„ã—ã¦æœ‰åŠ¹ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·ã‚’æ‹¡å¤§ã™ã‚‹ã€æ©Ÿèƒ½ã§ã™ãŒã€è¦ç´„æ™‚ã«æƒ…å ±ãŒå¤±ã‚ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚é‡è¦ãªãƒ¡ãƒ¢ãƒªã¯Store APIã«æ°¸ç¶šåŒ–ã—ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã«ã¯æœ€æ–°ãƒ»æœ€é–¢é€£ã®æƒ…å ±ã®ã¿ã‚’æ¸¡ã™è¨­è¨ˆãŒå®‰å…¨ã§ã™ã€‚

## ã‚ˆãã‚ã‚‹å•é¡Œã¨è§£æ±ºæ–¹æ³•

ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆRAGã®ãƒ¡ãƒ¢ãƒªå…±æœ‰ã§é »å‡ºã™ã‚‹å•é¡Œã¨ãã®å¯¾å‡¦æ³•ã‚’æ•´ç†ã—ã¾ã™ã€‚

| å•é¡Œ | åŸå›  | è§£æ±ºæ–¹æ³• |
|------|------|----------|
| ãƒ¡ãƒ¢ãƒªæ¤œç´¢ãŒé…ã„ï¼ˆ>100msï¼‰ | pgvectorã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æœªä½œæˆ | `CREATE INDEX` ã§HNSWã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆ |
| ç•°ãªã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒåŒã˜ãƒ¡ãƒ¢ãƒªã‚’é‡è¤‡ä¿å­˜ | åå‰ç©ºé–“è¨­è¨ˆã®ä¸å‚™ | ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã”ã¨ã®æ›¸ãè¾¼ã¿åå‰ç©ºé–“ã‚’åˆ†é›¢ |
| å¤ã„ãƒ¡ãƒ¢ãƒªãŒæ¤œç´¢ä¸Šä½ã«è¡¨ç¤ºã•ã‚Œã‚‹ | TTLæœªè¨­å®š | `ttl_minutes` ã§ãƒ¡ãƒ¢ãƒªã®æœ‰åŠ¹æœŸé™ã‚’è¨­å®š |
| ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢ã®ç²¾åº¦ãŒä½ã„ | embeddingæ¬¡å…ƒãƒ»ãƒ¢ãƒ‡ãƒ«ã®ä¸ä¸€è‡´ | `IndexConfig` ã®dims/embedã‚’çµ±ä¸€ |
| `InMemoryStore` ã§ãƒ‡ãƒ¼ã‚¿ãŒæ¶ˆãˆã‚‹ | ãƒ—ãƒ­ã‚»ã‚¹å†èµ·å‹• | æœ¬ç•ªã¯ `PostgresStore` / `MongoDBStore` ã‚’ä½¿ç”¨ |
| Storeæ³¨å…¥å¾Œã«ãƒãƒ¼ãƒ‰ã§storeãŒå–å¾—ã§ããªã„ | `compile(store=...)` æœªæŒ‡å®š | ã‚°ãƒ©ãƒ•ã® `compile()` æ™‚ã«storeã‚’æ¸¡ã™ |

### ãƒ¡ãƒ¢ãƒªã®ç«¶åˆã‚’é˜²ãè¨­è¨ˆæŒ‡é‡

ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒä¸¦åˆ—å®Ÿè¡Œã•ã‚Œã‚‹å ´åˆã€åŒä¸€åå‰ç©ºé–“ã¸ã®åŒæ™‚æ›¸ãè¾¼ã¿ã§ç«¶åˆãŒç™ºç”Ÿã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚

```python
# conflict_prevention.py
import uuid
from datetime import datetime, timezone

async def safe_memory_write(
    store: AsyncPostgresStore,
    namespace: tuple[str, ...],
    value: dict,
    agent_id: str,
) -> None:
    """Append-onlyãƒ‘ã‚¿ãƒ¼ãƒ³ã§ç«¶åˆã‚’é˜²ããƒ¡ãƒ¢ãƒªæ›¸ãè¾¼ã¿"""
    key = f"{agent_id}_{uuid.uuid4().hex[:12]}"
    value_with_metadata = {
        **value,
        "_metadata": {
            "agent_id": agent_id,
            "created_at": datetime.now(timezone.utc).isoformat(),
        },
    }
    await store.aput(namespace, key, value_with_metadata)
```

**ãªãœAppend-onlyãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¡ç”¨ã™ã‚‹ã‹:**
- `put()` ã¯åŒä¸€ã‚­ãƒ¼ã§ä¸Šæ›¸ãã™ã‚‹ãŸã‚ã€è¤‡æ•°ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒåŒã˜ã‚­ãƒ¼ã«æ›¸ãè¾¼ã‚€ã¨**æœ€å¾Œã®æ›¸ãè¾¼ã¿ã®ã¿ãŒæ®‹ã‚Šã¾ã™**
- UUIDãƒ™ãƒ¼ã‚¹ã®ã‚­ãƒ¼ã«ã‚ˆã‚Šå„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒ¡ãƒ¢ãƒªãŒç‹¬ç«‹ã—ã¦è“„ç©ã•ã‚Œã¾ã™
- Store APIã¯ç¾æ™‚ç‚¹ã§CASæ“ä½œã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ãªã„ãŸã‚ã€Append-onlyãŒæœ€ã‚‚ã‚·ãƒ³ãƒ—ãƒ«ã§ã™

## ã¾ã¨ã‚ã¨æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

**ã¾ã¨ã‚:**
- LangGraph 1.0ã®Store APIã¯ã€**åå‰ç©ºé–“ãƒ™ãƒ¼ã‚¹ã®éšå±¤è¨­è¨ˆ**ã§ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆé–“ã®ãƒ¡ãƒ¢ãƒªåˆ†é›¢ã¨å…±æœ‰ã‚’æŸ”è»Ÿã«åˆ¶å¾¡ã§ãã¾ã™
- **Checkpointerï¼ˆçŸ­æœŸï¼‰+ Storeï¼ˆé•·æœŸï¼‰**ã®2å±¤ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã«ã‚ˆã‚Šã€ã‚»ãƒƒã‚·ãƒ§ãƒ³å†…çŠ¶æ…‹ã¨ã‚¯ãƒ­ã‚¹ã‚»ãƒƒã‚·ãƒ§ãƒ³çŸ¥è­˜ã‚’æ˜ç¢ºã«åˆ†é›¢ã§ãã¾ã™
- LangMem SDKï¼ˆv0.0.30ï¼‰ã¯**ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒ»ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ãƒ»æ‰‹ç¶šãè¨˜æ†¶**ã®è‡ªå‹•æŠ½å‡ºãƒ»ç®¡ç†ãƒ»æ¤œç´¢ã‚’æä¾›ã—ã€ãƒ¡ãƒ¢ãƒªç®¡ç†ã®å®Ÿè£…ã‚³ã‚¹ãƒˆã‚’å‰Šæ¸›ã—ã¾ã™
- PostgresStore + pgvectorã®**HNSWã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹**ãŒå¤§åŠã®RAGã‚¢ãƒ—ãƒªã«æ¨å¥¨ã•ã‚Œã€TTLã«ã‚ˆã‚‹è‡ªå‹•ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã§ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚³ã‚¹ãƒˆã‚’åˆ¶å¾¡ã§ãã¾ã™
- Claude Sonnet 4.6ã®**context compaction**ã¨çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§ã€é•·æ™‚é–“ç¨¼åƒã™ã‚‹RAGã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ã‚’ç¶­æŒã§ãã¾ã™

**æ¬¡ã«ã‚„ã‚‹ã¹ãã“ã¨:**
- LangGraphå…¬å¼ã®[Memory Overview](https://docs.langchain.com/oss/python/langgraph/memory)ã§Store APIã®å…¨ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ç¢ºèªã™ã‚‹
- `InMemoryStore` ã§åå‰ç©ºé–“è¨­è¨ˆã®ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ã‚’ä½œæˆã—ã€ãƒ¡ãƒ¢ãƒªã®å¯è¦–æ€§åˆ¶å¾¡ã‚’ãƒ†ã‚¹ãƒˆã™ã‚‹
- PostgresStore + pgvectorã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’å–å¾—ã—ã€HNSWãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆm, ef_constructionï¼‰ã‚’æœ€é©åŒ–ã™ã‚‹

## å‚è€ƒ

- [LangGraph Memory Overviewï¼ˆå…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆï¼‰](https://docs.langchain.com/oss/python/langgraph/memory)
- [LangGraph Store Systemï¼ˆDeepWikiï¼‰](https://deepwiki.com/langchain-ai/langgraph/4.3-store-system)
- [Powering Long-Term Memory For Agents With LangGraph And MongoDB](https://www.mongodb.com/company/blog/product-release-announcements/powering-long-term-memory-for-agents-langgraph)
- [LangGraph & Redis: Build smarter AI agents with memory & persistence](https://redis.io/blog/langgraph-redis-build-smarter-ai-agents-with-memory-persistence/)
- [LangMem SDKå…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](https://langchain-ai.github.io/langmem/)
- [LangMem SDK Launch Blog](https://blog.langchain.com/langmem-sdk-launch/)
- [Launching Long-Term Memory Support in LangGraph](https://blog.langchain.com/launching-long-term-memory-support-in-langgraph/)
- [LangGraph PyPIï¼ˆv1.0.7ï¼‰](https://pypi.org/project/langgraph/)
- [Claude Sonnet 4.6 Context Windows](https://platform.claude.com/docs/en/build-with-claude/context-windows)

---

:::message
ã“ã®è¨˜äº‹ã¯AIï¼ˆClaude Codeï¼‰ã«ã‚ˆã‚Šè‡ªå‹•ç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚å†…å®¹ã®æ­£ç¢ºæ€§ã«ã¤ã„ã¦ã¯è¤‡æ•°ã®æƒ…å ±æºã§æ¤œè¨¼ã—ã¦ã„ã¾ã™ãŒã€å®Ÿéš›ã®åˆ©ç”¨æ™‚ã¯å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚‚ã”ç¢ºèªãã ã•ã„ã€‚
:::
