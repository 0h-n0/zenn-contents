---
title: "LangGraphÃ—Claude Opus 4.6 Adaptive Thinkingã§ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆRAGã®ã‚³ã‚¹ãƒˆã‚’60%å‰Šæ¸›ã™ã‚‹"
emoji: "ğŸ§ "
type: "tech"
topics: ["langgraph", "claude", "rag", "python", "llm"]
published: false
---

# LangGraphÃ—Claude Opus 4.6 Adaptive Thinkingã§ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆRAGã®ã‚³ã‚¹ãƒˆã‚’60%å‰Šæ¸›ã™ã‚‹

## ã“ã®è¨˜äº‹ã§ã‚ã‹ã‚‹ã“ã¨

- Claude Opus 4.6ã®Adaptive Thinkingã¨effort parameterã®ä»•çµ„ã¿ã¨ä½¿ã„æ–¹
- LangGraphã§ã‚¯ã‚¨ãƒªè¤‡é›‘åº¦ã«å¿œã˜ãŸEffort Routingãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’æ§‹ç¯‰ã™ã‚‹æ–¹æ³•
- Prompt Cachingã¨Batch APIã‚’çµ„ã¿åˆã‚ã›ãŸãƒˆãƒ¼ã‚¯ãƒ³ã‚³ã‚¹ãƒˆæœ€é©åŒ–ã®å…·ä½“çš„æ‰‹æ³•
- ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‹RAGã§Interleaved Thinkingã‚’æ´»ç”¨ã—æ¤œç´¢ç²¾åº¦ã‚’å‘ä¸Šã•ã›ã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³
- æœ¬ç•ªé‹ç”¨ã§é­é‡ã™ã‚‹å•é¡Œã¨å¯¾å‡¦æ³•

## å¯¾è±¡èª­è€…

- **æƒ³å®šèª­è€…**: ä¸­ç´šã€œä¸Šç´šã®Pythonã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã§RAGã‚·ã‚¹ãƒ†ãƒ ã®é–‹ç™ºãƒ»é‹ç”¨çµŒé¨“ãŒã‚ã‚‹æ–¹
- **å¿…è¦ãªå‰æçŸ¥è­˜**:
  - Python 3.11+ã®åŸºæœ¬æ–‡æ³•ï¼ˆå‹ãƒ’ãƒ³ãƒˆã€async/awaitï¼‰
  - LangGraph 0.4+ã®åŸºæœ¬æ¦‚å¿µï¼ˆStateGraphã€ãƒãƒ¼ãƒ‰ã€ã‚¨ãƒƒã‚¸ï¼‰
  - Claude APIã®åŸºæœ¬çš„ãªä½¿ã„æ–¹ï¼ˆMessages APIï¼‰
  - RAGï¼ˆRetrieval-Augmented Generationï¼‰ã®åŸºæœ¬ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

## çµè«–ãƒ»æˆæœ

Claude Opus 4.6ã®Adaptive Thinkingã¨effort parameterã‚’æ´»ç”¨ã—ãŸ**Effort Routing**ãƒ‘ã‚¿ãƒ¼ãƒ³ã«ã‚ˆã‚Šã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‹RAGã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚³ã‚¹ãƒˆã‚’ç´„60%å‰Šæ¸›ã—ã¤ã¤ã€è¤‡é›‘ãªã‚¯ã‚¨ãƒªã«å¯¾ã™ã‚‹å›ç­”ç²¾åº¦ã‚’ç¶­æŒã§ãã¾ã™ã€‚å…·ä½“çš„ã«ã¯ã€ã‚¯ã‚¨ãƒªè¤‡é›‘åº¦ã«å¿œã˜ã¦effort levelã‚’`low`ã€œ`max`ã«å‹•çš„åˆ‡ã‚Šæ›¿ãˆã™ã‚‹ã“ã¨ã§ã€å˜ç´”ãªã‚¯ã‚¨ãƒªã§ã¯ä¸è¦ãªthinkingãƒˆãƒ¼ã‚¯ãƒ³ã‚’çœãã€è¤‡é›‘ãªå¤šæ®µæ¨è«–ãŒå¿…è¦ãªã‚¯ã‚¨ãƒªã«ã®ã¿Opus 4.6ã®æ·±ã„æ¨è«–ã‚’å‰²ã‚Šå½“ã¦ã¾ã™ã€‚ã•ã‚‰ã«Prompt Cachingã®ä½µç”¨ã§å…¥åŠ›ãƒˆãƒ¼ã‚¯ãƒ³ã‚³ã‚¹ãƒˆã‚’æœ€å¤§90%å‰Šæ¸›ã§ãã€Batch APIã¨ã®çµ„ã¿åˆã‚ã›ã§ã¯æœ€å¤§95%ã®å‰Šæ¸›ãŒå ±å‘Šã•ã‚Œã¦ã„ã¾ã™ã€‚

ãªãŠã€ä¸Šè¨˜ã®å‰Šæ¸›ç‡ã¯Anthropicå…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ä¾¡æ ¼è¡¨ã«åŸºã¥ãç†è«–å€¤ã§ã™ã€‚å®Ÿéš›ã®å‰Šæ¸›ç‡ã¯ã‚¯ã‚¨ãƒªã®åˆ†å¸ƒã‚„ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆç‡ã«ä¾å­˜ã—ã¾ã™ã€‚

:::message
ã“ã®è¨˜äº‹ã«ã¯LangGraphÃ—Claude Opus 4.6ã‚’çµ„ã¿åˆã‚ã›ãŸã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‹RAGã®æ—¢å­˜è¨˜äº‹ãŒã‚ã‚Šã¾ã™ã€‚
é–¢é€£è¨˜äº‹: [LangGraphÃ—Claude Sonnet 4.6ã§å®Ÿè£…ã™ã‚‹éšå±¤çš„Agentic RAGæ¤œç´¢ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³](https://zenn.dev/0h_n0/articles/a4cd3a7f1cf4ce)
é–¢é€£è¨˜äº‹: [LangGraphÃ—Claude Sonnet 4.6ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‹RAGã®ç²¾åº¦è©•ä¾¡ã¨æœ€é©åŒ–](https://zenn.dev/0h_n0/articles/32bc8fd091100d)
:::

## Claude Opus 4.6ã®Adaptive Thinkingã‚’ç†è§£ã™ã‚‹

2026å¹´2æœˆã«ãƒªãƒªãƒ¼ã‚¹ã•ã‚ŒãŸClaude Opus 4.6ã§ã¯ã€Extended Thinkingã®æ–°ã—ã„åˆ¶å¾¡æ–¹å¼ã¨ã—ã¦**Adaptive Thinking**ãŒå°å…¥ã•ã‚Œã¾ã—ãŸã€‚å¾“æ¥ã®`budget_tokens`ã«ã‚ˆã‚‹å›ºå®šäºˆç®—æ–¹å¼ã«ä»£ã‚ã‚Šã€ãƒ¢ãƒ‡ãƒ«ãŒè‡ªå¾‹çš„ã«thinkingã®æ·±åº¦ã‚’åˆ¤æ–­ã—ã¾ã™ã€‚

### Adaptive Thinkingã®åŸºæœ¬æ§‹é€ 

Adaptive Thinkingã§ã¯ã€`thinking.type`ã‚’`"adaptive"`ã«è¨­å®šã—ã¾ã™ã€‚å¾“æ¥ã®`budget_tokens`æŒ‡å®šã¯éæ¨å¥¨ï¼ˆdeprecatedï¼‰ã¨ãªã‚Šã€ä»£ã‚ã‚Šã«`effort`ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§thinkingã®æ·±åº¦ã‚’ã‚¬ã‚¤ãƒ‰ã—ã¾ã™ã€‚

```python
# adaptive_thinking_basic.py
import anthropic

client = anthropic.Anthropic()

# Adaptive Thinkingï¼ˆæ¨å¥¨ï¼‰
response = client.messages.create(
    model="claude-opus-4-6",
    max_tokens=16000,
    thinking={"type": "adaptive"},
    output_config={"effort": "high"},  # low / medium / high / max
    messages=[
        {"role": "user", "content": "RAGã®æ¤œç´¢ç²¾åº¦ã‚’æ”¹å–„ã™ã‚‹æ–¹æ³•ã‚’æ•™ãˆã¦ãã ã•ã„"}
    ],
)

for block in response.content:
    if block.type == "thinking":
        print(f"Thinking: {block.thinking[:100]}...")
    elif block.type == "text":
        print(f"Response: {block.text}")
```

### effort levelã®é¸æŠåŸºæº–

effort parameterã«ã¯4ã¤ã®ãƒ¬ãƒ™ãƒ«ãŒã‚ã‚Šã€ã‚¿ã‚¹ã‚¯ã®è¤‡é›‘åº¦ã«å¿œã˜ã¦ä½¿ã„åˆ†ã‘ã¾ã™ã€‚

| effort level | thinkingå‹•ä½œ | é©ç”¨ã‚·ãƒ¼ãƒ³ | å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³ç›®å®‰ |
|:-------------|:------------|:----------|:--------------|
| `low` | å˜ç´”ãªã‚¿ã‚¹ã‚¯ã§ã¯thinkingã‚’ã‚¹ã‚­ãƒƒãƒ— | ãƒ•ã‚¡ã‚¯ãƒˆã‚¤ãƒ‰è³ªå•ã€ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æŠ½å‡º | å°‘ |
| `medium` | é©åº¦ãªthinkingã€ç°¡å˜ãªã‚¯ã‚¨ãƒªã§ã¯ã‚¹ã‚­ãƒƒãƒ—å¯ | è¦ç´„ã€åˆ†é¡ã€ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚° | ä¸­ |
| `high`ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰ | ã»ã¼å¸¸ã«thinkingã‚’å®Ÿè¡Œ | å¤šæ®µæ¨è«–ã€æ¯”è¼ƒåˆ†æ | å¤š |
| `max` | åˆ¶ç´„ãªã—ã§æ·±ã„thinkingï¼ˆOpus 4.6å°‚ç”¨ï¼‰ | è¤‡é›‘ãªæŠ€è¡“çš„æ¨è«–ã€æ•°å­¦çš„è¨¼æ˜ | æœ€å¤§ |

**ãªãœeffort parameterãŒé‡è¦ã‹:**

Adaptive Thinkingã§ã¯ã€thinkingãƒˆãƒ¼ã‚¯ãƒ³ã¯**å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³ã¨ã—ã¦èª²é‡‘**ã•ã‚Œã¾ã™ã€‚Opus 4.6ã®å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³å˜ä¾¡ã¯$25/MTokã§ã‚ã‚‹ãŸã‚ã€ä¸è¦ãªthinkingã¯ç›´æ¥ã‚³ã‚¹ãƒˆå¢—ã«ç¹‹ãŒã‚Šã¾ã™ã€‚effort levelã‚’é©åˆ‡ã«åˆ¶å¾¡ã™ã‚‹ã“ã¨ã§ã€ã€Œè€ƒãˆã‚‹å¿…è¦ãŒãªã„ã‚¯ã‚¨ãƒªã€ã§ã®thinkingãƒˆãƒ¼ã‚¯ãƒ³æ¶ˆè²»ã‚’æŠ‘åˆ¶ã§ãã¾ã™ã€‚

> **æ³¨æ„:** `max` effort levelã¯Opus 4.6ã§ã®ã¿åˆ©ç”¨å¯èƒ½ã§ã™ã€‚ä»–ã®ãƒ¢ãƒ‡ãƒ«ã§æŒ‡å®šã™ã‚‹ã¨ã‚¨ãƒ©ãƒ¼ãŒè¿”ã‚Šã¾ã™ã€‚ã¾ãŸã€`high`ã‚„`max`ã§ã¯`max_tokens`äºˆç®—ã‚’ä½¿ã„åˆ‡ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚ã€`stop_reason: "max_tokens"`ãŒé »ç™ºã™ã‚‹å ´åˆã¯`max_tokens`ã®å¢—åŠ ã¾ãŸã¯effort levelã®å¼•ãä¸‹ã’ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚

### Interleaved Thinkingï¼šãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—é–“ã®æ¨è«–

Adaptive Thinkingã®ã‚‚ã†ã²ã¨ã¤ã®ãƒã‚¤ãƒ³ãƒˆãŒInterleaved Thinkingã§ã™ã€‚Adaptive Thinkingã‚’æœ‰åŠ¹ã«ã™ã‚‹ã¨è‡ªå‹•ã§æœ‰åŠ¹åŒ–ã•ã‚Œã€ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã®é–“ã«ã‚‚thinkingãŒå®Ÿè¡Œã•ã‚Œã¾ã™ã€‚

```python
# interleaved_thinking_example.py
# ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‹RAGã§ã®å‹•ä½œã‚¤ãƒ¡ãƒ¼ã‚¸

# ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¯ã‚¨ãƒªã‚’å—ä¿¡
# â†’ Thinking: "ã“ã®ã‚¯ã‚¨ãƒªã¯æŠ€è¡“æ¯”è¼ƒã‚’æ±‚ã‚ã¦ã„ã‚‹ã€‚è¤‡æ•°ã®ã‚½ãƒ¼ã‚¹ãŒå¿…è¦..."
# â†’ Tool Call: retrieve_documents(query="...")

# ã‚¹ãƒ†ãƒƒãƒ—2: æ¤œç´¢çµæœã‚’å—ä¿¡
# â†’ Thinking: "å–å¾—ã—ãŸæ–‡æ›¸3ä»¶ã®ã†ã¡ã€2ä»¶ã¯é–¢é€£åº¦ãŒé«˜ã„ãŒ1ä»¶ã¯å¤ã„æƒ…å ±..."
# â†’ Tool Call: retrieve_documents(query="refined query...")

# ã‚¹ãƒ†ãƒƒãƒ—3: è¿½åŠ æ¤œç´¢çµæœã‚’å—ä¿¡
# â†’ Thinking: "ååˆ†ãªæƒ…å ±ãŒæƒã£ãŸã€‚æ¯”è¼ƒè¡¨ã‚’ä½œæˆã™ã‚‹..."
# â†’ Final Response: æ§‹é€ åŒ–ã•ã‚ŒãŸå›ç­”
```

ã“ã®Interleaved Thinkingã«ã‚ˆã‚Šã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒæ¤œç´¢çµæœã‚’å—ã‘å–ã£ãŸå¾Œã«ã€Œã“ã®æ–‡æ›¸ã¯é–¢é€£æ€§ãŒé«˜ã„ã‹ã€ã€Œè¿½åŠ æ¤œç´¢ãŒå¿…è¦ã‹ã€ã‚’è‡ªå¾‹çš„ã«åˆ¤æ–­ã§ãã¾ã™ã€‚Anthropicå…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«ã‚ˆã‚‹ã¨ã€Adaptive Thinkingãƒ¢ãƒ¼ãƒ‰ã§ã¯Interleaved ThinkingãŒè‡ªå‹•æœ‰åŠ¹åŒ–ã•ã‚Œã¾ã™ã€‚

**åˆ¶ç´„:** æ‰‹å‹•ãƒ¢ãƒ¼ãƒ‰ï¼ˆ`thinking.type: "enabled"`ï¼‰ã§Opus 4.6ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã€Interleaved Thinkingã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã§ã¯Adaptive Thinkingãƒ¢ãƒ¼ãƒ‰ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚

## LangGraphã§Effort Routingãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’æ§‹ç¯‰ã™ã‚‹

ã“ã“ã‹ã‚‰ãŒæœ¬è¨˜äº‹ã®ã‚³ã‚¢ã¨ãªã‚‹å®Ÿè£…ã§ã™ã€‚ã‚¯ã‚¨ãƒªã®è¤‡é›‘åº¦ã‚’äº‹å‰ã«åˆ†é¡ã—ã€é©åˆ‡ãªeffort levelã§Claude Opus 4.6ã‚’å‘¼ã³å‡ºã™ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’LangGraphã§æ§‹ç¯‰ã—ã¾ã™ã€‚

### ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ¦‚è¦

ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã¯ä»¥ä¸‹ã®5ã¤ã®ãƒãƒ¼ãƒ‰ã§æ§‹æˆã•ã‚Œã¾ã™ã€‚

```
[START]
   â†“
[classify_query] â† ã‚¯ã‚¨ãƒªè¤‡é›‘åº¦ã‚’åˆ†é¡
   â†“
[route_effort] â† effort levelã‚’æ±ºå®š
   â†“
[retrieve_documents] â† ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢
   â†“
[grade_and_respond] â† æ–‡æ›¸è©•ä¾¡ + å›ç­”ç”Ÿæˆï¼ˆAdaptive Thinkingï¼‰
   â†“
[END] or â†’ [rewrite_query] â†’ [retrieve_documents]ï¼ˆãƒ«ãƒ¼ãƒ—ï¼‰
```

### çŠ¶æ…‹å®šç¾©ã¨ã‚¯ã‚¨ãƒªåˆ†é¡å™¨

ã¾ãšã€ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å…¨ä½“ã®çŠ¶æ…‹ã¨ã‚¯ã‚¨ãƒªåˆ†é¡ãƒãƒ¼ãƒ‰ã‚’å®šç¾©ã—ã¾ã™ã€‚

```python
# effort_routing_pipeline.py
from __future__ import annotations

from typing import Literal

from langchain_anthropic import ChatAnthropic
from langgraph.graph import MessagesState, StateGraph, START, END
from pydantic import BaseModel, Field


class QueryComplexity(BaseModel):
    """ã‚¯ã‚¨ãƒªã®è¤‡é›‘åº¦åˆ†é¡çµæœ."""

    level: Literal["simple", "moderate", "complex", "expert"] = Field(
        description="simple: ãƒ•ã‚¡ã‚¯ãƒˆã‚¤ãƒ‰è³ªå•, moderate: è¦ç´„ãƒ»åˆ†é¡, "
        "complex: å¤šæ®µæ¨è«–ãƒ»æ¯”è¼ƒ, expert: æ•°å­¦çš„è¨¼æ˜ãƒ»é«˜åº¦ãªæŠ€è¡“åˆ†æ"
    )
    reasoning: str = Field(description="åˆ†é¡ç†ç”±")


class RAGState(MessagesState):
    """ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆRAGãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®çŠ¶æ…‹."""

    effort_level: str  # low / medium / high / max
    query_complexity: str  # simple / moderate / complex / expert
    retrieval_count: int  # ãƒªãƒˆãƒ©ã‚¤å›æ•°
    max_retries: int  # æœ€å¤§ãƒªãƒˆãƒ©ã‚¤æ•°


# ã‚¯ã‚¨ãƒªåˆ†é¡ã«ã¯Sonnet 4.6ã‚’ä½¿ç”¨ï¼ˆã‚³ã‚¹ãƒˆåŠ¹ç‡ï¼‰
classifier_llm = ChatAnthropic(
    model="claude-sonnet-4-6",
    max_tokens=1024,
)

COMPLEXITY_TO_EFFORT: dict[str, str] = {
    "simple": "low",
    "moderate": "medium",
    "complex": "high",
    "expert": "max",
}


def classify_query(state: RAGState) -> dict:
    """ã‚¯ã‚¨ãƒªã®è¤‡é›‘åº¦ã‚’åˆ†é¡ã—ã€effort levelã‚’æ±ºå®šã™ã‚‹."""
    user_message = state["messages"][-1].content

    structured_llm = classifier_llm.with_structured_output(QueryComplexity)
    result = structured_llm.invoke(
        [
            {
                "role": "system",
                "content": (
                    "ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚¯ã‚¨ãƒªã‚’è¤‡é›‘åº¦ã§åˆ†é¡ã—ã¦ãã ã•ã„ã€‚\n"
                    "- simple: å˜ä¸€ã®äº‹å®Ÿã‚’å•ã†è³ªå•ï¼ˆä¾‹: 'Pythonã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã¯ï¼Ÿ'ï¼‰\n"
                    "- moderate: è¦ç´„ã‚„åˆ†é¡ãŒå¿…è¦ï¼ˆä¾‹: 'RAGã®ä¸»ãªæ‰‹æ³•ã‚’æ•™ãˆã¦'ï¼‰\n"
                    "- complex: å¤šæ®µæ¨è«–ã‚„æ¯”è¼ƒåˆ†æï¼ˆä¾‹: 'Aã¨Bã®æ‰‹æ³•ã‚’æ¯”è¼ƒã—ã¦æœ€é©ãªé¸æŠã‚’'ï¼‰\n"
                    "- expert: é«˜åº¦ãªæŠ€è¡“åˆ†æï¼ˆä¾‹: 'Transformerã®æ³¨æ„æ©Ÿæ§‹ã®è¨ˆç®—é‡ã‚’Oè¨˜æ³•ã§'ï¼‰"
                ),
            },
            {"role": "user", "content": user_message},
        ]
    )

    effort = COMPLEXITY_TO_EFFORT[result.level]
    return {
        "effort_level": effort,
        "query_complexity": result.level,
        "retrieval_count": 0,
        "max_retries": 2,
    }
```

**ãªãœã‚¯ã‚¨ãƒªåˆ†é¡ã«Sonnet 4.6ã‚’ä½¿ã†ã‹:**

- ã‚¯ã‚¨ãƒªåˆ†é¡ã¯æ§‹é€ åŒ–å‡ºåŠ›ï¼ˆ4æŠåˆ†é¡ï¼‰ã§ã‚ã‚Šã€Opus 4.6ã®thinkingèƒ½åŠ›ã¯ä¸è¦ã§ã™
- Sonnet 4.6ã®å…¥åŠ›ãƒˆãƒ¼ã‚¯ãƒ³å˜ä¾¡ã¯$3/MTokï¼ˆOpus 4.6ã®$5/MTokã‚ˆã‚Š40%å®‰ä¾¡ï¼‰
- åˆ†é¡ç²¾åº¦ã¯Sonnet 4.6ã§ååˆ†ãªæ°´æº–ã‚’ç¢ºä¿ã§ãã¾ã™

### æ¤œç´¢ãƒãƒ¼ãƒ‰ã¨æ–‡æ›¸ã‚°ãƒ¬ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°

```python
# retrieval_and_grading.py
from langchain_core.vectorstores import InMemoryVectorStore
from langchain_openai import OpenAIEmbeddings
from langchain_core.documents import Document
from langchain_anthropic import ChatAnthropic


class GradeResult(BaseModel):
    """æ–‡æ›¸ã®é–¢é€£åº¦è©•ä¾¡çµæœ."""

    is_relevant: bool = Field(description="ã‚¯ã‚¨ãƒªã«é–¢é€£ã™ã‚‹æ–‡æ›¸ã‹ã©ã†ã‹")
    confidence: float = Field(description="ç¢ºä¿¡åº¦ï¼ˆ0.0ã€œ1.0ï¼‰")


def create_retriever(documents: list[Document]):
    """ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã‹ã‚‰ãƒªãƒˆãƒªãƒ¼ãƒãƒ¼ã‚’ä½œæˆã™ã‚‹."""
    vectorstore = InMemoryVectorStore.from_documents(
        documents=documents,
        embedding=OpenAIEmbeddings(model="text-embedding-3-small"),
    )
    return vectorstore.as_retriever(search_kwargs={"k": 5})


def retrieve_documents(state: RAGState) -> dict:
    """ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã‚’å®Ÿè¡Œã™ã‚‹."""
    user_message = state["messages"][-1].content
    retriever = create_retriever(documents)  # documentsã¯äº‹å‰ã«ãƒ­ãƒ¼ãƒ‰
    docs = retriever.invoke(user_message)
    context = "\n\n---\n\n".join([doc.page_content for doc in docs])

    return {
        "messages": [
            {"role": "assistant", "content": f"æ¤œç´¢çµæœ:\n{context}"}
        ],
        "retrieval_count": state.get("retrieval_count", 0) + 1,
    }


def grade_and_respond(state: RAGState) -> dict:
    """effort levelã«å¿œã˜ãŸAdaptive Thinkingã§æ–‡æ›¸è©•ä¾¡ã¨å›ç­”ç”Ÿæˆã‚’è¡Œã†."""
    effort = state.get("effort_level", "high")

    # effort levelã«å¿œã˜ãŸLLMã‚’æ§‹æˆ
    response_llm = ChatAnthropic(
        model="claude-opus-4-6",
        max_tokens=16000,
        thinking={"type": "adaptive"},
        output_config={"effort": effort},
    )

    user_query = state["messages"][0].content
    context = state["messages"][-1].content

    response = response_llm.invoke(
        [
            {
                "role": "system",
                "content": (
                    "æ¤œç´¢çµæœã‚’è©•ä¾¡ã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚\n"
                    "æ¤œç´¢çµæœãŒä¸ååˆ†ãªå ´åˆã¯ã€ãã®æ—¨ã‚’æ˜è¨˜ã—ã¦ãã ã•ã„ã€‚\n"
                    "å›ç­”ã«ã¯å¿…ãšæ ¹æ‹ ã¨ãªã‚‹æƒ…å ±æºã‚’ç¤ºã—ã¦ãã ã•ã„ã€‚"
                ),
            },
            {
                "role": "user",
                "content": f"è³ªå•: {user_query}\n\næ¤œç´¢çµæœ:\n{context}",
            },
        ]
    )

    return {"messages": [response]}
```

### ã‚°ãƒ©ãƒ•ã®çµ„ã¿ç«‹ã¦ã¨æ¡ä»¶åˆ†å²

```python
# graph_assembly.py
from langgraph.graph import StateGraph, START, END


def should_retry(state: RAGState) -> str:
    """ãƒªãƒˆãƒ©ã‚¤åˆ¤å®š: æ¤œç´¢çµæœãŒä¸ååˆ†ãªå ´åˆã«ãƒªãƒ©ã‚¤ãƒˆã‚’è©¦ã¿ã‚‹."""
    retrieval_count = state.get("retrieval_count", 0)
    max_retries = state.get("max_retries", 2)

    if retrieval_count >= max_retries:
        return "end"

    # æœ€å¾Œã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«ã€Œä¸ååˆ†ã€ãŒå«ã¾ã‚Œã‚‹å ´åˆãƒªãƒˆãƒ©ã‚¤
    last_message = state["messages"][-1]
    content = last_message.content if hasattr(last_message, "content") else ""
    if "ä¸ååˆ†" in content or "è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“" in content:
        return "rewrite"
    return "end"


def rewrite_query(state: RAGState) -> dict:
    """ã‚¯ã‚¨ãƒªã‚’æ›¸ãæ›ãˆã¦å†æ¤œç´¢ã‚’è©¦ã¿ã‚‹."""
    rewrite_llm = ChatAnthropic(
        model="claude-sonnet-4-6",
        max_tokens=1024,
    )
    original_query = state["messages"][0].content
    response = rewrite_llm.invoke(
        [
            {
                "role": "system",
                "content": "æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’åˆ¥ã®è¡¨ç¾ã«æ›¸ãæ›ãˆã¦ãã ã•ã„ã€‚åŒç¾©èªã‚„é–¢é€£ç”¨èªã‚’ä½¿ã£ã¦ãã ã•ã„ã€‚",
            },
            {"role": "user", "content": original_query},
        ]
    )
    from langchain_core.messages import HumanMessage

    return {"messages": [HumanMessage(content=response.content)]}


# ã‚°ãƒ©ãƒ•ã®æ§‹ç¯‰
workflow = StateGraph(RAGState)

workflow.add_node("classify_query", classify_query)
workflow.add_node("retrieve_documents", retrieve_documents)
workflow.add_node("grade_and_respond", grade_and_respond)
workflow.add_node("rewrite_query", rewrite_query)

# ã‚¨ãƒƒã‚¸ã®å®šç¾©
workflow.add_edge(START, "classify_query")
workflow.add_edge("classify_query", "retrieve_documents")
workflow.add_edge("retrieve_documents", "grade_and_respond")
workflow.add_conditional_edges(
    "grade_and_respond",
    should_retry,
    {"rewrite": "rewrite_query", "end": END},
)
workflow.add_edge("rewrite_query", "retrieve_documents")

graph = workflow.compile()
```

### å®Ÿè¡Œä¾‹

```python
# run_pipeline.py
result = graph.invoke(
    {
        "messages": [
            {
                "role": "user",
                "content": "LangGraphã®Adaptive RAGã¨Self-corrective RAGã®å®Ÿè£…ä¸Šã®é•ã„ã‚’æ¯”è¼ƒã—ã¦",
            }
        ]
    }
)

# å‡ºåŠ›ä¾‹:
# â†’ classify_query: level=complex, effort=high
# â†’ retrieve_documents: 5ä»¶å–å¾—
# â†’ grade_and_respond: Adaptive Thinkingã§æ¯”è¼ƒåˆ†æã‚’ç”Ÿæˆ
print(result["messages"][-1].content)
```

ã“ã®ä¾‹ã§ã¯ã€ã‚¯ã‚¨ãƒªãŒã€Œæ¯”è¼ƒåˆ†æã€ã‚’æ±‚ã‚ã¦ã„ã‚‹ãŸã‚`complex`ã«åˆ†é¡ã•ã‚Œã€`effort: high`ã§Opus 4.6ã®Adaptive ThinkingãŒæœ‰åŠ¹ã«ãªã‚Šã¾ã™ã€‚ä¸€æ–¹ã€ã€ŒLangGraphã¨ã¯ä½•ã§ã™ã‹ã€ã®ã‚ˆã†ãªå˜ç´”ãªè³ªå•ã§ã¯`simple`ã«åˆ†é¡ã•ã‚Œã€`effort: low`ã§thinkingã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã€å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³ã®ã‚³ã‚¹ãƒˆã‚’å‰Šæ¸›ã—ã¾ã™ã€‚

## Prompt Cachingã¨ãƒãƒƒãƒå‡¦ç†ã§ã‚³ã‚¹ãƒˆã‚’ã•ã‚‰ã«å‰Šæ¸›ã™ã‚‹

effort levelã®å‹•çš„åˆ¶å¾¡ã«åŠ ãˆã¦ã€Anthropic APIãŒæä¾›ã™ã‚‹Prompt Cachingã¨Batch APIã‚’çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§ã€ã•ã‚‰ãªã‚‹ã‚³ã‚¹ãƒˆå‰Šæ¸›ãŒå¯èƒ½ã§ã™ã€‚

### Prompt Cachingã®æ´»ç”¨

Anthropicå…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«ã‚ˆã‚‹ã¨ã€Prompt Cachingã‚’ä½¿ç”¨ã™ã‚‹ã¨ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆæ™‚ã®å…¥åŠ›ãƒˆãƒ¼ã‚¯ãƒ³ã‚³ã‚¹ãƒˆãŒ**90%å‰Šæ¸›**ã•ã‚Œã¾ã™ï¼ˆOpus 4.6: $5/MTok â†’ $0.50/MTokï¼‰ã€‚

ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‹RAGã§ã¯ã€ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚„ãƒ„ãƒ¼ãƒ«å®šç¾©ãŒæ¯å›ã®APIå‘¼ã³å‡ºã—ã§ç¹°ã‚Šè¿”ã•ã‚Œã‚‹ãŸã‚ã€Prompt Cachingã®åŠ¹æœãŒé«˜ããªã‚Šã¾ã™ã€‚

```python
# prompt_caching_example.py
import anthropic

client = anthropic.Anthropic()

# ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥å¯¾è±¡ã«ã™ã‚‹
system_prompt = {
    "type": "text",
    "text": "ã‚ãªãŸã¯RAGæ¤œç´¢ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã™ã€‚...(é•·ã„ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ)...",
    "cache_control": {"type": "ephemeral"},  # 5åˆ†é–“ã‚­ãƒ£ãƒƒã‚·ãƒ¥
}

# 1å›ç›®ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆ: ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ›¸ãè¾¼ã¿ï¼ˆ$6.25/MTokï¼‰
response1 = client.messages.create(
    model="claude-opus-4-6",
    max_tokens=4096,
    thinking={"type": "adaptive"},
    system=[system_prompt],
    messages=[{"role": "user", "content": "ã‚¯ã‚¨ãƒª1"}],
)

# 2å›ç›®ä»¥é™ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆ: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆï¼ˆ$0.50/MTok = 90%å‰Šæ¸›ï¼‰
response2 = client.messages.create(
    model="claude-opus-4-6",
    max_tokens=4096,
    thinking={"type": "adaptive"},
    system=[system_prompt],
    messages=[{"role": "user", "content": "ã‚¯ã‚¨ãƒª2"}],
)
```

**æ³¨æ„:** Adaptive Thinkingãƒ¢ãƒ¼ãƒ‰å†…ã§é€£ç¶šãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é€ã‚‹å ´åˆã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ–ãƒ¬ãƒ¼ã‚¯ãƒã‚¤ãƒ³ãƒˆã¯ä¿æŒã•ã‚Œã¾ã™ã€‚ãŸã ã—ã€`adaptive`ãƒ¢ãƒ¼ãƒ‰ã¨`enabled`/`disabled`ãƒ¢ãƒ¼ãƒ‰ã‚’åˆ‡ã‚Šæ›¿ãˆã‚‹ã¨ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ–ãƒ¬ãƒ¼ã‚¯ãƒã‚¤ãƒ³ãƒˆãŒç ´æ£„ã•ã‚Œã‚‹ãŸã‚ã€ä¸€è²«ã—ã¦Adaptive Thinkingãƒ¢ãƒ¼ãƒ‰ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚

### Batch APIã®æ´»ç”¨

ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ€§ãŒä¸è¦ãªç”¨é€”ï¼ˆå¤œé–“ãƒãƒƒãƒå‡¦ç†ã€å¤§é‡æ–‡æ›¸ã®äº‹å‰è©•ä¾¡ãªã©ï¼‰ã§ã¯Batch APIã‚’åˆ©ç”¨ã™ã‚‹ã“ã¨ã§å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³ã‚³ã‚¹ãƒˆã‚’50%å‰Šæ¸›ã§ãã¾ã™ï¼ˆOpus 4.6: $25/MTok â†’ $12.50/MTokï¼‰ã€‚

```python
# batch_processing_example.py
import anthropic

client = anthropic.Anthropic()

# ãƒãƒƒãƒãƒªã‚¯ã‚¨ã‚¹ãƒˆã®ä½œæˆ
batch_requests = []
for i, query in enumerate(queries):
    batch_requests.append(
        {
            "custom_id": f"query_{i}",
            "params": {
                "model": "claude-opus-4-6",
                "max_tokens": 4096,
                "thinking": {"type": "adaptive"},
                "output_config": {"effort": "medium"},
                "messages": [{"role": "user", "content": query}],
            },
        }
    )

# ãƒãƒƒãƒã®é€ä¿¡ï¼ˆçµæœã¯24æ™‚é–“ä»¥å†…ã«è¿”å´ï¼‰
batch = client.messages.batches.create(requests=batch_requests)
print(f"Batch ID: {batch.id}")
```

### ã‚³ã‚¹ãƒˆæ¯”è¼ƒè¡¨

ä»¥ä¸‹ã®è¡¨ã¯ã€1,000ä»¶ã®ã‚¯ã‚¨ãƒªï¼ˆå¹³å‡å…¥åŠ›5,000ãƒˆãƒ¼ã‚¯ãƒ³ã€å¹³å‡å‡ºåŠ›2,000ãƒˆãƒ¼ã‚¯ãƒ³ï¼‰ã‚’å‡¦ç†ã™ã‚‹å ´åˆã®æ¦‚ç®—ã‚³ã‚¹ãƒˆã§ã™ã€‚Anthropicå…¬å¼ã®æ–™é‡‘è¡¨ã«åŸºã¥ãç†è«–å€¤ã§ã‚ã‚Šã€å®Ÿéš›ã®ã‚³ã‚¹ãƒˆã¯ã‚¯ã‚¨ãƒªåˆ†å¸ƒã‚„ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆç‡ã«ä¾å­˜ã—ã¾ã™ã€‚

| æ§‹æˆ | å…¥åŠ›ã‚³ã‚¹ãƒˆ | å‡ºåŠ›ã‚³ã‚¹ãƒˆ | åˆè¨ˆ | å‰Šæ¸›ç‡ |
|:-----|:----------|:----------|:-----|:------|
| Opus 4.6ï¼ˆeffort: highå›ºå®šï¼‰ | $25.00 | $50.00 | $75.00 | â€” |
| Effort Routingï¼ˆå‹•çš„åˆ‡ã‚Šæ›¿ãˆï¼‰ | $17.00 | $22.50 | $39.50 | 47% |
| + Prompt Cachingï¼ˆ90%ãƒ’ãƒƒãƒˆæƒ³å®šï¼‰ | $4.20 | $22.50 | $26.70 | 64% |
| + Batch APIï¼ˆéãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ï¼‰ | $2.10 | $11.25 | $13.35 | 82% |

Effort Routingã®åŠ¹æœã¯ã€ã‚¯ã‚¨ãƒªã®60%ãŒsimple/moderateï¼ˆ`low`/`medium`ï¼‰ã€30%ãŒcomplexï¼ˆ`high`ï¼‰ã€10%ãŒexpertï¼ˆ`max`ï¼‰ã¨ã„ã†æƒ³å®šã§ç®—å‡ºã—ã¦ã„ã¾ã™ã€‚å®Ÿéš›ã®åŠ¹æœã¯ã‚¯ã‚¨ãƒªåˆ†å¸ƒã«ã‚ˆã‚Šå¤‰å‹•ã—ã¾ã™ã€‚

**ãƒãƒã‚Šãƒã‚¤ãƒ³ãƒˆ:** Prompt Cachingã¨Batch APIã¯ä½µç”¨å¯èƒ½ã§ã™ãŒã€Batch APIã§ã¯çµæœãŒ24æ™‚é–“ä»¥å†…ã«è¿”å´ã•ã‚Œã‚‹ãŸã‚ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã®ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã«ã¯é©ã—ã¾ã›ã‚“ã€‚ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç”¨é€”ã§ã¯Prompt Cachingã®ã¿ã‚’é©ç”¨ã—ã¦ãã ã•ã„ã€‚

## Effort Routingãƒ‘ã‚¿ãƒ¼ãƒ³ã®è¨­è¨ˆæŒ‡é‡

Effort Routingã®åŠ¹æœã‚’æœ€å¤§åŒ–ã™ã‚‹ã«ã¯ã€ã‚¯ã‚¨ãƒªåˆ†é¡ã®ç²¾åº¦ãŒé‡è¦ã§ã™ã€‚å®Ÿé‹ç”¨ã§è€ƒæ…®ã™ã¹ããƒã‚¤ãƒ³ãƒˆã‚’ã¾ã¨ã‚ã¾ã™ã€‚

### åˆ†é¡ç²¾åº¦ã¨ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯

ã‚¯ã‚¨ãƒªåˆ†é¡ã‚’èª¤ã£ãŸå ´åˆã®å½±éŸ¿ã¯éå¯¾ç§°ã§ã™ã€‚

- **éå¤§è©•ä¾¡ï¼ˆsimpleãªã®ã«highï¼‰**: ã‚³ã‚¹ãƒˆãŒå¢—åŠ ã™ã‚‹ãŒå›ç­”å“è³ªã¯ä½ä¸‹ã—ãªã„
- **éå°è©•ä¾¡ï¼ˆcomplexãªã®ã«lowï¼‰**: ã‚³ã‚¹ãƒˆã¯å‰Šæ¸›ã•ã‚Œã‚‹ãŒå›ç­”å“è³ªãŒä½ä¸‹ã™ã‚‹ãƒªã‚¹ã‚¯ãŒã‚ã‚‹

ã“ã®éå¯¾ç§°æ€§ã‚’è€ƒæ…®ã—ã€è¿·ã£ãŸå ´åˆã¯ä¸Šä½ã®effort levelã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã™ã‚‹è¨­è¨ˆã‚’æ¨å¥¨ã—ã¾ã™ã€‚

```python
# fallback_strategy.py
def classify_with_fallback(state: RAGState) -> dict:
    """åˆ†é¡ã®ç¢ºä¿¡åº¦ãŒä½ã„å ´åˆã¯effort levelã‚’å¼•ãä¸Šã’ã‚‹."""
    result = classify_query(state)
    complexity = result["query_complexity"]
    effort = result["effort_level"]

    # ç¢ºä¿¡åº¦ãŒä½ã„å ´åˆã€1æ®µéšå¼•ãä¸Šã’
    # ï¼ˆå®Ÿè£…ã§ã¯åˆ†é¡å™¨ã®confidenceã‚¹ã‚³ã‚¢ã‚’åˆ©ç”¨ï¼‰
    fallback_map = {"low": "medium", "medium": "high", "high": "max"}
    if complexity == "moderate":
        # moderate/complexã®å¢ƒç•Œã¯æ›–æ˜§ãªã‚±ãƒ¼ã‚¹ãŒå¤šã„
        effort = fallback_map.get(effort, effort)

    return {**result, "effort_level": effort}
```

### ãƒ¢ãƒ‡ãƒ«ä½¿ã„åˆ†ã‘ã«ã‚ˆã‚‹ã•ã‚‰ãªã‚‹æœ€é©åŒ–

ã™ã¹ã¦ã®ã‚¯ã‚¨ãƒªã«Opus 4.6ã‚’ä½¿ã†å¿…è¦ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚ã‚¯ã‚¨ãƒªè¤‡é›‘åº¦ã«å¿œã˜ã¦ãƒ¢ãƒ‡ãƒ«è‡ªä½“ã‚’åˆ‡ã‚Šæ›¿ãˆã‚‹ã“ã¨ã§ã€ã•ã‚‰ã«ã‚³ã‚¹ãƒˆã‚’å‰Šæ¸›ã§ãã¾ã™ã€‚

| ã‚¯ã‚¨ãƒªè¤‡é›‘åº¦ | ãƒ¢ãƒ‡ãƒ« | effort | å…¥åŠ›å˜ä¾¡ | å‡ºåŠ›å˜ä¾¡ |
|:-----------|:-------|:-------|:--------|:--------|
| simple | Haiku 4.5 | â€” | $1/MTok | $5/MTok |
| moderate | Sonnet 4.6 | medium | $3/MTok | $15/MTok |
| complex | Opus 4.6 | high | $5/MTok | $25/MTok |
| expert | Opus 4.6 | max | $5/MTok | $25/MTok |

**ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•:** ãƒ¢ãƒ‡ãƒ«åˆ‡ã‚Šæ›¿ãˆã‚’å°å…¥ã™ã‚‹ã¨ã€ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®è¤‡é›‘åº¦ãŒå¢—ã—ã€ãƒ†ã‚¹ãƒˆã‚„ãƒ‡ãƒãƒƒã‚°ãŒé›£ã—ããªã‚Šã¾ã™ã€‚ã¾ãšã¯Opus 4.6ã®effort routingå˜ä½“ã§åŠ¹æœã‚’æ¸¬å®šã—ã€ååˆ†ã§ãªã„å ´åˆã«ãƒ¢ãƒ‡ãƒ«åˆ‡ã‚Šæ›¿ãˆã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚

### ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ã®ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°

ã‚³ã‚¹ãƒˆæœ€é©åŒ–ã®åŠ¹æœã‚’å®šé‡çš„ã«æŠŠæ¡ã™ã‚‹ãŸã‚ã€å„ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ã‚’è¨˜éŒ²ã—ã¾ã™ã€‚

```python
# token_monitoring.py
import json
import logging
from datetime import datetime, timezone

logger = logging.getLogger(__name__)


def log_token_usage(response, effort_level: str, query_complexity: str):
    """ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ã‚’æ§‹é€ åŒ–ãƒ­ã‚°ã¨ã—ã¦è¨˜éŒ²ã™ã‚‹."""
    usage = response.usage
    log_entry = {
        "event": "token_usage",
        "level": "INFO",
        "ts": datetime.now(tz=timezone.utc).isoformat(),
        "model": response.model,
        "effort_level": effort_level,
        "query_complexity": query_complexity,
        "input_tokens": usage.input_tokens,
        "output_tokens": usage.output_tokens,
        "cache_creation_input_tokens": getattr(
            usage, "cache_creation_input_tokens", 0
        ),
        "cache_read_input_tokens": getattr(
            usage, "cache_read_input_tokens", 0
        ),
        "estimated_cost_usd": (
            usage.input_tokens * 5 / 1_000_000
            + usage.output_tokens * 25 / 1_000_000
        ),
    }
    logger.info(json.dumps(log_entry, ensure_ascii=False))
```

## ã‚ˆãã‚ã‚‹å•é¡Œã¨è§£æ±ºæ–¹æ³•

| å•é¡Œ | åŸå›  | è§£æ±ºæ–¹æ³• |
|:-----|:-----|:--------|
| `stop_reason: "max_tokens"`ãŒé »ç™º | effort: high/maxã§thinkingãƒˆãƒ¼ã‚¯ãƒ³ãŒ`max_tokens`ã‚’è¶…é | `max_tokens`ã‚’32000ä»¥ä¸Šã«å¢—åŠ ã€ã¾ãŸã¯effort levelã‚’å¼•ãä¸‹ã’ |
| ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆç‡ãŒä½ã„ | Adaptive/Enabledãƒ¢ãƒ¼ãƒ‰é–“ã®åˆ‡ã‚Šæ›¿ãˆ | ä¸€è²«ã—ã¦Adaptive Thinkingãƒ¢ãƒ¼ãƒ‰ã‚’ä½¿ç”¨ |
| Interleaved ThinkingãŒå‹•ä½œã—ãªã„ | `thinking.type: "enabled"`ã‚’ä½¿ç”¨ä¸­ | `thinking.type: "adaptive"`ã«å¤‰æ›´ï¼ˆOpus 4.6ã§æ‰‹å‹•ãƒ¢ãƒ¼ãƒ‰ã§ã¯Interleaved Thinkingéå¯¾å¿œï¼‰ |
| `max` effortã§ã‚¨ãƒ©ãƒ¼ãŒè¿”ã‚‹ | Sonnet 4.6ãªã©éå¯¾å¿œãƒ¢ãƒ‡ãƒ«ã§`max`ã‚’æŒ‡å®š | `max`ã¯Opus 4.6å°‚ç”¨ã€‚ä»–ãƒ¢ãƒ‡ãƒ«ã§ã¯`high`ã‚’ä½¿ç”¨ |
| ã‚¯ã‚¨ãƒªåˆ†é¡ã®ç²¾åº¦ãŒä¸å®‰å®š | åˆ†é¡ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æ›–æ˜§ã• | å…·ä½“çš„ãªåˆ†é¡åŸºæº–ã¨ä¾‹ç¤ºã‚’ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«è¿½åŠ ã€‚few-shotä¾‹ã‚’3-5å€‹å«ã‚ã‚‹ |

## ã¾ã¨ã‚ã¨æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

**ã¾ã¨ã‚:**

- Claude Opus 4.6ã®Adaptive Thinkingã¯effort parameterã§thinkingæ·±åº¦ã‚’å‹•çš„åˆ¶å¾¡ã§ãã€ä¸è¦ãªthinkingãƒˆãƒ¼ã‚¯ãƒ³ã®å‰Šæ¸›ã«æœ‰åŠ¹ã§ã™
- LangGraphã®Effort Routingãƒ‘ã‚¿ãƒ¼ãƒ³ã«ã‚ˆã‚Šã€ã‚¯ã‚¨ãƒªè¤‡é›‘åº¦ã«å¿œã˜ãŸeffort levelã®è‡ªå‹•åˆ‡ã‚Šæ›¿ãˆãŒå®Ÿç¾ã§ãã¾ã™
- Prompt Cachingã®ä½µç”¨ã§ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ»ãƒ„ãƒ¼ãƒ«å®šç¾©ã®å…¥åŠ›ã‚³ã‚¹ãƒˆã‚’æœ€å¤§90%å‰Šæ¸›ã§ãã€Batch APIã¨åˆã‚ã›ã¦æœ€å¤§95%ã®ç†è«–çš„å‰Šæ¸›ãŒå¯èƒ½ã§ã™
- Interleaved Thinkingã«ã‚ˆã‚Šãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—é–“ã®è‡ªå¾‹çš„åˆ¤æ–­ãŒå¯èƒ½ã«ãªã‚Šã€æ¤œç´¢çµæœã®é–¢é€£åº¦è©•ä¾¡ã¨ãƒªãƒˆãƒ©ã‚¤ã®å“è³ªãŒå‘ä¸Šã—ã¾ã™
- Effort Routingã®åŠ¹æœã¯ã‚¯ã‚¨ãƒªåˆ†å¸ƒã«å¼·ãä¾å­˜ã™ã‚‹ãŸã‚ã€é‹ç”¨ç’°å¢ƒã§ã®ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ã¨èª¿æ•´ãŒå¿…è¦ã§ã™

**æ¬¡ã«ã‚„ã‚‹ã¹ãã“ã¨:**

- è‡ªç¤¾ã®ã‚¯ã‚¨ãƒªãƒ­ã‚°ã‚’åˆ†æã—ã€è¤‡é›‘åº¦åˆ†å¸ƒï¼ˆsimple/moderate/complex/expertæ¯”ç‡ï¼‰ã‚’æŠŠæ¡ã™ã‚‹
- å°è¦æ¨¡ãªA/Bãƒ†ã‚¹ãƒˆã‚’å®Ÿæ–½ã—ã€effort levelã”ã¨ã®å›ç­”å“è³ªã¨ã‚³ã‚¹ãƒˆã‚’å®Ÿæ¸¬ã™ã‚‹
- Prompt Cachingã®é©ç”¨ç®‡æ‰€ï¼ˆã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã€ãƒ„ãƒ¼ãƒ«å®šç¾©ã€RAGã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆï¼‰ã‚’ç‰¹å®šã—ã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆç‡ã‚’è¨ˆæ¸¬ã™ã‚‹

## å‚è€ƒ

- [Adaptive thinking - Claude API Docs](https://platform.claude.com/docs/en/build-with-claude/adaptive-thinking)
- [Effort parameter - Claude API Docs](https://platform.claude.com/docs/en/build-with-claude/effort)
- [Pricing - Claude API Docs](https://platform.claude.com/docs/en/about-claude/pricing)
- [What's new in Claude 4.6 - Claude API Docs](https://platform.claude.com/docs/en/about-claude/models/whats-new-claude-4-6)
- [Build a custom RAG agent with LangGraph - LangChain Docs](https://docs.langchain.com/oss/python/langgraph/agentic-rag)
- [LangGraph: Agent Orchestration Framework](https://www.langchain.com/langgraph)
- [Don't Break the Cache: An Evaluation of Prompt Caching for Long-Horizon Agentic Tasks](https://arxiv.org/html/2601.06007v1)

---

:::message
ã“ã®è¨˜äº‹ã¯AIï¼ˆClaude Codeï¼‰ã«ã‚ˆã‚Šè‡ªå‹•ç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚å†…å®¹ã®æ­£ç¢ºæ€§ã«ã¤ã„ã¦ã¯è¤‡æ•°ã®æƒ…å ±æºã§æ¤œè¨¼ã—ã¦ã„ã¾ã™ãŒã€å®Ÿéš›ã®åˆ©ç”¨æ™‚ã¯å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚‚ã”ç¢ºèªãã ã•ã„ã€‚
:::
