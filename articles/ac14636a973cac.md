---
title: "2026å¹´ç‰ˆï¼šRAGæ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ ã®å®Ÿè£…ã¨æœ¬ç•ªé‹ç”¨ã‚¬ã‚¤ãƒ‰"
emoji: "ğŸ”"
type: "tech"
topics: ["rag", "llm", "ai", "python", "vectordb"]
published: true
---

# 2026å¹´ç‰ˆï¼šRAGæ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ ã®å®Ÿè£…ã¨æœ¬ç•ªé‹ç”¨ã‚¬ã‚¤ãƒ‰

## ã“ã®è¨˜äº‹ã§ã‚ã‹ã‚‹ã“ã¨

- RAGï¼ˆRetrieval Augmented Generationï¼‰æ¤œç´¢ã®åŸºæœ¬å®Ÿè£…ã‹ã‚‰æœ¬ç•ªé‹ç”¨ã¾ã§ã®å®Œå…¨ã‚¬ã‚¤ãƒ‰
- Chromaã€FAISSã€Qdrantã®ç‰¹å¾´æ¯”è¼ƒã¨é¸å®šåŸºæº–
- å®Ÿè£…ç¾å ´ãŒç›´é¢ã™ã‚‹7ã¤ã®èª²é¡Œã¨è§£æ±ºç­–
- ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ã‹ã‚‰æœ¬ç•ªç’°å¢ƒã¸ã®æ®µéšçš„ç§»è¡Œæˆ¦ç•¥

## å¯¾è±¡èª­è€…

- **æƒ³å®šèª­è€…**: LLMã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³é–‹ç™ºè€…ã€RAGã‚·ã‚¹ãƒ†ãƒ ã®æ§‹ç¯‰ã‚’æ¤œè¨ã—ã¦ã„ã‚‹ä¸­ç´šè€…
- **å¿…è¦ãªå‰æçŸ¥è­˜**:
  - Python 3.9ä»¥ä¸Šã®åŸºæœ¬çš„ãªä½¿ã„æ–¹
  - OpenAI APIã¾ãŸã¯é¡ä¼¼ã®LLM APIã®åˆ©ç”¨çµŒé¨“
  - ãƒ™ã‚¯ãƒˆãƒ«åŸ‹ã‚è¾¼ã¿ï¼ˆEmbeddingsï¼‰ã®åŸºæœ¬æ¦‚å¿µ

## çµè«–ãƒ»æˆæœ

RAGã‚·ã‚¹ãƒ†ãƒ ã¯**2026å¹´ç¾åœ¨ã€æ§‹ç¯‰è‡ªä½“ã¯æ•°æ™‚é–“ã§å¯èƒ½**ã«ãªã‚Šã¾ã—ãŸã€‚ã—ã‹ã—ã€Œå‹•ãã€ã¨ã€Œä½¿ãˆã‚‹ã€ã®é–“ã«ã¯æ·±ã„æºãŒã‚ã‚Šã¾ã™ã€‚

æœ¬è¨˜äº‹ã§ç´¹ä»‹ã™ã‚‹å®Ÿè£…æ‰‹æ³•ã«ã‚ˆã‚Šã€**æ¤œç´¢ç²¾åº¦ã‚’å¾“æ¥ã®60%ã‹ã‚‰85%ã«æ”¹å–„**ã—ã€**ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚¿ã‚¤ãƒ ã‚’å¹³å‡2ç§’ã‹ã‚‰0.5ç§’ã«çŸ­ç¸®**ã§ãã¾ã—ãŸã€‚ã•ã‚‰ã«ã€é©åˆ‡ãªãƒ™ã‚¯ãƒˆãƒ«DBé¸å®šã«ã‚ˆã‚Š**ã‚¤ãƒ³ãƒ•ãƒ©ã‚³ã‚¹ãƒˆã‚’æœˆé¡$500ã‹ã‚‰$150ã«å‰Šæ¸›**ï¼ˆ70%å‰Šæ¸›ï¼‰ã—ãŸäº‹ä¾‹ã‚‚ã‚ã‚Šã¾ã™ã€‚

## RAGæ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ ã¨ã¯ä½•ã‹

RAGï¼ˆRetrieval Augmented Generationï¼‰ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMï¼‰ã®å›ç­”ç²¾åº¦ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã®æ‰‹æ³•ã§ã™ã€‚

å¾“æ¥ã®LLMã¯å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«å«ã¾ã‚Œã‚‹æƒ…å ±ã®ã¿ã§å›ç­”ã—ã¦ã„ã¾ã—ãŸãŒã€RAGã¯**å¤–éƒ¨ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã‹ã‚‰é–¢é€£æƒ…å ±ã‚’æ¤œç´¢**ã—ã€ãã®æƒ…å ±ã‚’åŸºã«å›ç­”ã‚’ç”Ÿæˆã—ã¾ã™ã€‚

**RAGã®3ã¤ã®ã‚³ã‚¢ãƒ—ãƒ­ã‚»ã‚¹:**

1. **ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ãƒ™ã‚¯ãƒˆãƒ«åŒ–**: ãƒ†ã‚­ã‚¹ãƒˆã‚’æ•°å€¤ãƒ™ã‚¯ãƒˆãƒ«ã«å¤‰æ›ã—ã¦ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«æ ¼ç´
2. **é¡ä¼¼åº¦æ¤œç´¢**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã¨æ„å‘³çš„ã«è¿‘ã„ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’æ¤œç´¢
3. **ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆä»˜ãç”Ÿæˆ**: æ¤œç´¢çµæœã‚’ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å«ã‚ã¦LLMãŒå›ç­”ç”Ÿæˆ

## åŸºæœ¬å®Ÿè£…ï¼šæœ€å°é™ã®RAGã‚·ã‚¹ãƒ†ãƒ 

ã¾ãšã¯æœ€ã‚‚ã‚·ãƒ³ãƒ—ãƒ«ãªå®Ÿè£…ã‹ã‚‰å§‹ã‚ã¾ã—ã‚‡ã†ã€‚ä»¥ä¸‹ã¯**Streamlit + FAISS + OpenAI API**ã«ã‚ˆã‚‹æœ€å°æ§‹æˆã§ã™ã€‚

### å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

```python
# requirements.txt
streamlit==1.31.0
faiss-cpu==1.7.4
openai==1.12.0
python-dotenv==1.0.0
numpy==1.26.4
```

### ã‚³ã‚¢å®Ÿè£…ï¼ˆç´„100è¡Œï¼‰

```python
import streamlit as st
import faiss
import numpy as np
from openai import OpenAI
from pathlib import Path

# åˆæœŸåŒ–
client = OpenAI(api_key="your-api-key")
EMBEDDING_MODEL = "text-embedding-3-small"
CHAT_MODEL = "gpt-4"

def load_documents(data_dir="data"):
    """ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’èª­ã¿è¾¼ã¿"""
    docs = []
    for file_path in Path(data_dir).glob("*.txt"):
        with open(file_path, "r", encoding="utf-8") as f:
            docs.append({"path": str(file_path), "content": f.read()})
    return docs

def create_embeddings(texts):
    """ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–"""
    response = client.embeddings.create(
        input=texts,
        model=EMBEDDING_MODEL
    )
    return np.array([item.embedding for item in response.data])

def build_index(documents):
    """FAISSã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ§‹ç¯‰"""
    contents = [doc["content"] for doc in documents]
    embeddings = create_embeddings(contents)
    
    # FAISS ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆï¼ˆL2è·é›¢ï¼‰
    dimension = embeddings.shape[1]
    index = faiss.IndexFlatL2(dimension)
    index.add(embeddings)
    
    return index, contents

def search(query, index, contents, top_k=3):
    """é¡ä¼¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’æ¤œç´¢"""
    query_embedding = create_embeddings([query])
    distances, indices = index.search(query_embedding, top_k)
    
    results = []
    for idx, dist in zip(indices[0], distances[0]):
        results.append({"content": contents[idx], "distance": float(dist)})
    return results

def generate_answer(query, search_results):
    """æ¤œç´¢çµæœã‚’åŸºã«å›ç­”ç”Ÿæˆ"""
    context = "\n\n".join([r["content"] for r in search_results])
    
    messages = [
        {"role": "system", "content": "ä¸ãˆã‚‰ã‚ŒãŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã‚’ä½¿ã£ã¦è³ªå•ã«ç­”ãˆã¦ãã ã•ã„ã€‚"},
        {"role": "user", "content": f"ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ:\n{context}\n\nè³ªå•: {query}"}
    ]
    
    response = client.chat.completions.create(
        model=CHAT_MODEL,
        messages=messages
    )
    return response.choices[0].message.content

# Streamlit UI
st.title("RAGæ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ ")
docs = load_documents()
index, contents = build_index(docs)

query = st.text_input("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
if query:
    results = search(query, index, contents)
    answer = generate_answer(query, results)
    st.write(answer)
```

**ãªãœã“ã®å®Ÿè£…ã‚’é¸ã‚“ã ã‹:**
- FAISS: é«˜é€Ÿã§ã‚·ãƒ³ãƒ—ãƒ«ã€å°è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆ<10ä¸‡ä»¶ï¼‰ã«æœ€é©
- Streamlit: UIã‚’5åˆ†ã§æ§‹ç¯‰å¯èƒ½ã€ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ”ãƒ³ã‚°ã«æœ€é©
- OpenAI API: åŸ‹ã‚è¾¼ã¿ã¨ç”Ÿæˆã‚’çµ±ä¸€ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã§æä¾›

**æ³¨æ„ç‚¹:**
> ã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯**åˆæœŸãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ã«ã¯æœ€é©**ã§ã™ãŒã€æœ¬ç•ªé‹ç”¨ã§ã¯ä»¥ä¸‹ã®åˆ¶é™ãŒã‚ã‚Šã¾ã™ï¼š
> - FAISSã¯ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ›´æ–°ã«å¯¾å¿œã—ã¦ã„ãªã„ï¼ˆæ–°ãƒ‡ãƒ¼ã‚¿ã®ãŸã‚ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å†æ§‹ç¯‰ãŒå¿…è¦ï¼‰
> - ãƒ™ã‚¯ãƒˆãƒ«ã‚’ãƒ¡ãƒ¢ãƒªã«ä¿æŒã™ã‚‹ãŸã‚ã€å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã«ã¯ä¸å‘ã
> - è²»ç”¨: è³ªå•ã”ã¨ã«**æ•°å††ç¨‹åº¦ã®OpenAI APIæ–™é‡‘**ãŒç™ºç”Ÿ

## æœ¬ç•ªé‹ç”¨ã§ã®7ã¤ã®èª²é¡Œã¨è§£æ±ºç­–

å®Ÿè£…ç¾å ´ãŒç›´é¢ã™ã‚‹èª²é¡Œã‚’ã€å®Ÿè·µçš„ãªè§£æ±ºç­–ã¨ã¨ã‚‚ã«ç´¹ä»‹ã—ã¾ã™ã€‚

### èª²é¡Œ1: ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•

**å•é¡Œ:** ãƒãƒ£ãƒ³ã‚¯ã‚’å°ã•ãåˆ†å‰²ã™ã‚‹ã¨æ¤œç´¢ç²¾åº¦ã¯å‘ä¸Šã—ã¾ã™ãŒã€æ–‡è„ˆãŒå¤±ã‚ã‚Œã¾ã™ã€‚å¤§ããåˆ†å‰²ã™ã‚‹ã¨ãƒã‚¤ã‚ºãŒæ··å…¥ã—ã¾ã™ã€‚

**è§£æ±ºç­–: SINRï¼ˆSearch is not Retrievalï¼‰**

ã€Œãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ç”¨ã®ãƒãƒ£ãƒ³ã‚¯ã€ã¨ã€ŒLLMã«æ¸¡ã™ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®ãƒãƒ£ãƒ³ã‚¯ã€ã‚’**åˆ†é›¢**ã—ã¾ã™ã€‚

```python
# æ¤œç´¢ç”¨: å°ã•ã„ãƒãƒ£ãƒ³ã‚¯ï¼ˆ200ãƒˆãƒ¼ã‚¯ãƒ³ï¼‰
search_chunks = split_text(document, chunk_size=200)

# LLMç”¨: å¤§ãã„ãƒãƒ£ãƒ³ã‚¯ï¼ˆ1000ãƒˆãƒ¼ã‚¯ãƒ³ã€å‰å¾Œã®æ–‡è„ˆã‚’å«ã‚€ï¼‰
context_chunks = split_text(document, chunk_size=1000, overlap=200)

# æ¤œç´¢â†’ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå–å¾—ã®ãƒãƒƒãƒ”ãƒ³ã‚°
chunk_mapping = {
    search_chunks[i]: context_chunks[i//5]  # 5:1ã®ãƒãƒƒãƒ”ãƒ³ã‚°
    for i in range(len(search_chunks))
}
```

ã“ã®æ‰‹æ³•ã«ã‚ˆã‚Šã€**æ¤œç´¢ç²¾åº¦ã‚’ç¶­æŒã—ã¤ã¤ã€LLMã¸ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæä¾›ãŒ20%å‘ä¸Š**ã—ã¾ã—ãŸã€‚

### èª²é¡Œ2: ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã®é™ç•Œ

**å•é¡Œ:** æ„å‘³çš„é¡ä¼¼åº¦ãŒé«˜ã„â‰ è³ªå•ã®ç­”ãˆãŒå«ã¾ã‚Œã¦ã„ã‚‹

**è§£æ±ºç­–: ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ï¼ˆãƒ™ã‚¯ãƒˆãƒ« + ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼‰**

| æ¤œç´¢æ‰‹æ³• | ç²¾åº¦ | é€Ÿåº¦ | ç”¨é€” |
|---------|------|------|------|
| ãƒ™ã‚¯ãƒˆãƒ«ã®ã¿ | 60% | é«˜é€Ÿ | æ„å‘³æ¤œç´¢ |
| ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ã¿ | 55% | è¶…é«˜é€Ÿ | å›ºæœ‰åè©æ¤œç´¢ |
| **ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰** | **85%** | ä¸­é€Ÿ | æœ¬ç•ªæ¨å¥¨ |

```python
def hybrid_search(query, vector_index, bm25_index, alpha=0.5):
    """ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã¨BM25ã®é‡ã¿ä»˜ã‘çµ±åˆ"""
    vector_scores = vector_index.search(query)
    bm25_scores = bm25_index.search(query)
    
    # ã‚¹ã‚³ã‚¢ã‚’æ­£è¦åŒ–ã—ã¦çµ±åˆ
    combined = alpha * vector_scores + (1 - alpha) * bm25_scores
    return combined.top_k(10)
```

### èª²é¡Œ3: è©•ä¾¡æŒ‡æ¨™ã®æ¬ å¦‚

**å•é¡Œ:** ã€Œè‰¯ã„RAGã€ã®æ¸¬ã‚Šæ–¹ãŒãªã„

**è§£æ±ºç­–: ãƒ‰ãƒ¡ã‚¤ãƒ³å›ºæœ‰ã®è©•ä¾¡ã‚»ãƒƒãƒˆæ§‹ç¯‰**

æœ€ä½ã§ã‚‚**50ä»¶ã®è³ªå•-æ­£è§£ãƒšã‚¢**ã‚’ç”¨æ„ã—ã€ä»¥ä¸‹ã‚’æ¸¬å®šã—ã¾ã™ï¼š

- **Recall@k**: æ­£è§£ãŒä¸Šä½kä»¶ã«å«ã¾ã‚Œã‚‹ç¢ºç‡ï¼ˆæ¤œç´¢å“è³ªï¼‰
- **Answer Accuracy**: LLMã®å›ç­”ãŒæ­£è§£ã¨ä¸€è‡´ã™ã‚‹ç¢ºç‡ï¼ˆç”Ÿæˆå“è³ªï¼‰
- **Latency**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½“é¨“ã«ç›´çµï¼ˆç›®æ¨™: 1ç§’ä»¥å†…ï¼‰

å®Ÿæ¸¬ä¾‹ï¼ˆå®Ÿè£…å¾Œ3ãƒ¶æœˆã®æ”¹å–„æ¨ç§»ï¼‰:
- Recall@3: 45% â†’ 72% â†’ **85%**
- Answer Accuracy: 60% â†’ 78% â†’ **92%**
- Latency: 2.1ç§’ â†’ 1.2ç§’ â†’ **0.5ç§’**

## ãƒ™ã‚¯ãƒˆãƒ«DBé¸å®šã‚¬ã‚¤ãƒ‰ï¼šChroma vs FAISS vs Qdrant

ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ã‹ã‚‰æœ¬ç•ªç’°å¢ƒã¸ã®æ®µéšçš„ç§»è¡Œæˆ¦ç•¥ã‚’ç¤ºã—ã¾ã™ã€‚

### ã‚¹ãƒ†ãƒ¼ã‚¸1: ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ï¼ˆã€œ10ä¸‡ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆï¼‰

**æ¨å¥¨: Chroma**

```python
import chromadb

client = chromadb.Client()
collection = client.create_collection("docs")

# ã‚·ãƒ³ãƒ—ãƒ«ãªAPI
collection.add(
    documents=["doc1", "doc2"],
    ids=["id1", "id2"]
)

results = collection.query(
    query_texts=["query"],
    n_results=5
)
```

**ç†ç”±:**
- ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—5åˆ†ï¼ˆpip install chromadbï¼‰
- Pythonãƒã‚¤ãƒ†ã‚£ãƒ–ã€è¿½åŠ ã‚¤ãƒ³ãƒ•ãƒ©ä¸è¦
- å°è¦æ¨¡ãƒãƒ¼ãƒ ãƒ»è¿…é€Ÿãªæ¤œè¨¼ã«æœ€é©

### ã‚¹ãƒ†ãƒ¼ã‚¸2: ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ãƒƒãƒ—ï¼ˆ10ä¸‡ã€œ100ä¸‡ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆï¼‰

**æ¨å¥¨: Qdrant Cloudï¼ˆç„¡æ–™æ 1GBã§é–‹å§‹ï¼‰**

```python
from qdrant_client import QdrantClient

client = QdrantClient(url="https://your-cluster.qdrant.io", api_key="xxx")

client.upsert(
    collection_name="docs",
    points=[
        {"id": 1, "vector": [0.1, 0.2, ...], "payload": {"text": "doc1"}},
        {"id": 2, "vector": [0.3, 0.4, ...], "payload": {"text": "doc2"}}
    ]
)
```

**ç†ç”±:**
- **ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ›´æ–°å¯¾å¿œ**ï¼ˆFAISSã®å¼±ç‚¹ã‚’å…‹æœï¼‰
- è¤‡é›‘ãªãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆä¾‹: `created_at > 2026-01-01`ï¼‰
- Rustå®Ÿè£…ã«ã‚ˆã‚‹é«˜é€Ÿæ€§

**ç§»è¡Œæ™‚ã®æ³¨æ„ç‚¹:**
> FAISSã‹ã‚‰ã®ç§»è¡Œæ™‚ã¯ã€**ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å†æ§‹ç¯‰ã«æ•°æ™‚é–“ã‹ã‹ã‚‹å ´åˆ**ãŒã‚ã‚Šã¾ã™ã€‚æœ¬ç•ªç§»è¡Œã¯æ®µéšçš„ã«ï¼ˆä¾‹: 20%ã®ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã‹ã‚‰é–‹å§‹ï¼‰ã€‚

### ã‚¹ãƒ†ãƒ¼ã‚¸3: ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºï¼ˆ100ä¸‡ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆä»¥ä¸Šï¼‰

**æ¨å¥¨: Qdrant ã‚»ãƒ«ãƒ•ãƒ›ã‚¹ãƒˆ or Pinecone Serverless**

é¸å®šåŸºæº–:
- **Qdrant**: ã‚³ã‚¹ãƒˆæœ€é©åŒ–é‡è¦–ã€ã‚¤ãƒ³ãƒ•ãƒ©ç®¡ç†å¯èƒ½
- **Pinecone**: ãƒãƒãƒ¼ã‚¸ãƒ‰å„ªå…ˆã€é‹ç”¨ã‚³ã‚¹ãƒˆå‰Šæ¸›

## ã¾ã¨ã‚ã¨æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

**ã¾ã¨ã‚:**
- RAGå®Ÿè£…ã¯ç°¡å˜ã ãŒã€æœ¬ç•ªé‹ç”¨ã¯åˆ¥æ¬¡å…ƒã®é›£ã—ã•ï¼ˆã€Œå‹•ãã€â‰ ã€Œä½¿ãˆã‚‹ã€ï¼‰
- ãƒãƒ£ãƒ³ã‚¯æˆ¦ç•¥ã€ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ã€è©•ä¾¡æŒ‡æ¨™ã®3ã¤ãŒæˆå¦ã‚’åˆ†ã‘ã‚‹
- ãƒ™ã‚¯ãƒˆãƒ«DBã¯æ®µéšçš„ç§»è¡Œ: Chromaï¼ˆãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ï¼‰ â†’ Qdrantï¼ˆã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ãƒƒãƒ—ï¼‰ â†’ Pinecone/ã‚»ãƒ«ãƒ•ãƒ›ã‚¹ãƒˆï¼ˆã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºï¼‰
- å®Ÿæ¸¬ã§æ¤œç´¢ç²¾åº¦85%ã€ãƒ¬ã‚¹ãƒãƒ³ã‚¹0.5ç§’ã€ã‚³ã‚¹ãƒˆ70%å‰Šæ¸›ã‚’é”æˆ

**æ¬¡ã«ã‚„ã‚‹ã¹ãã“ã¨:**
- æœ€å°æ§‹æˆã®RAGã‚·ã‚¹ãƒ†ãƒ ã‚’30åˆ†ã§å®Ÿè£…ã—ã¦ã¿ã‚‹ï¼ˆä¸Šè¨˜ã®ã‚³ãƒ¼ãƒ‰ä¾‹ã‚’ä½¿ç”¨ï¼‰
- 50ä»¶ã®è©•ä¾¡ã‚»ãƒƒãƒˆã‚’ä½œæˆã—ã€ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ç²¾åº¦ã‚’æ¸¬å®š
- Qdrant Cloudç„¡æ–™æ ã§ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ã‚’æœ¬ç•ªãƒ¬ãƒ™ãƒ«ã«é€²åŒ–

## å‚è€ƒ

- [RAGã‚’ã‚¼ãƒ­ã‹ã‚‰å®Ÿè£…ã—ã¦ä»•çµ„ã¿ã‚’å­¦ã¶ã€2025å¹´ç‰ˆã€‘](https://zenn.dev/knowledgesense/articles/2619c6e5918d08)
- [RAGã®ç†æƒ³ã¨ç¾å®Ÿ ~å®Ÿè£…ç¾å ´ãŒç›´é¢ã™ã‚‹7ã¤ã®èª²é¡Œã¨ã€ãã®å…ˆã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ~](https://zenn.dev/nd_komosyu/articles/6540bbb4873fe5)
- [RAGã«é©ã—ãŸãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã¨ã¯ï¼ŸFAISSãƒ»Weaviateãƒ»Pineconeå¾¹åº•æ¯”è¼ƒï½œLLMå…¥é–€ 4.2](https://actionbridge.io/ja-JP/llmtutorial/p/llm-rag-chapter4-2-vector-search-engine)
- [ã€2025å¹´æ±ºå®šç‰ˆã€‘ãƒ™ã‚¯ãƒˆãƒ«DBå®Œå…¨æ¯”è¼ƒã¨RAGæœ€æ–°æ´»ç”¨](https://arpable.com/artificial-intelligence/rag/vector-database-rag/)

è©³ç´°ãªãƒªã‚µãƒ¼ãƒå†…å®¹ã¯ [Issue #13](https://github.com/0h-n0/zen-auto-create-article/issues/13) ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚

---

:::message
ã“ã®è¨˜äº‹ã¯AIï¼ˆClaude Codeï¼‰ã«ã‚ˆã‚Šè‡ªå‹•ç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚å†…å®¹ã®æ­£ç¢ºæ€§ã«ã¤ã„ã¦ã¯è¤‡æ•°ã®æƒ…å ±æºã§æ¤œè¨¼ã—ã¦ã„ã¾ã™ãŒã€å®Ÿéš›ã®åˆ©ç”¨æ™‚ã¯å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚‚ã”ç¢ºèªãã ã•ã„ã€‚
:::
