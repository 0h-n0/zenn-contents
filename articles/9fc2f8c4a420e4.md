---
title: "LLMãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç®¡ç†CI/CDï¼šLangfuseÃ—LaunchDarklyã§A/Bãƒ†ã‚¹ãƒˆã¨å®‰å…¨ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆ"
emoji: "ğŸ”€"
type: "tech"
topics: ["llm", "cicd", "langfuse", "featureflag", "llmops"]
published: false
---

# LLMãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç®¡ç†CI/CDï¼šLangfuseÃ—LaunchDarklyã§A/Bãƒ†ã‚¹ãƒˆã¨å®‰å…¨ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆã‚’å®Ÿç¾ã™ã‚‹

## ã“ã®è¨˜äº‹ã§ã‚ã‹ã‚‹ã“ã¨

- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’YAML+Gitã§ç®¡ç†ã—ã€evalåŸºæº–ã¨åŒå±…ã•ã›ã‚‹ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ãƒ‘ã‚¿ãƒ¼ãƒ³
- Langfuseã®ãƒ©ãƒ™ãƒ«æ©Ÿèƒ½ã‚’ä½¿ã£ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆA/Bãƒ†ã‚¹ãƒˆã®å®Ÿè£…æ‰‹é †
- LaunchDarkly AI Configsã§ãƒ©ãƒ³ã‚¿ã‚¤ãƒ åˆ‡æ›¿ã¨æ®µéšçš„ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆã‚’å®Ÿç¾ã™ã‚‹æ–¹æ³•
- 3å±¤é˜²å¾¡ï¼ˆEval â†’ Feature Flag â†’ Observabilityï¼‰ã§ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆéšœå®³ã‚’ã‚¼ãƒ­ã«ã™ã‚‹è¨­è¨ˆ

## å¯¾è±¡èª­è€…

- **æƒ³å®šèª­è€…**: ä¸­ç´šã€œä¸Šç´šã®LLMã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³é–‹ç™ºè€…
- **å¿…è¦ãªå‰æçŸ¥è­˜**: Python 3.11+ã¾ãŸã¯TypeScript/Node.js 20.xã€GitHub Actionsã€OpenAI APIé–‹ç™ºçµŒé¨“

## çµè«–ãƒ»æˆæœ

**3å±¤ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç®¡ç†ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£**ã®å°å…¥ã§ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå¤‰æ›´èµ·å› ã®æœ¬ç•ªéšœå®³ãŒ**ã‚¼ãƒ­**ã«ã€æ”¹å–„ãƒ‡ãƒ—ãƒ­ã‚¤ã‚µã‚¤ã‚¯ãƒ«ãŒ**é€±1å›â†’æ—¥æ¬¡**ã«çŸ­ç¸®ã€‚A/Bãƒ†ã‚¹ãƒˆã§æœ‰æ„å·®ã®ã‚ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ã¿é©ç”¨ã—ã€å‡ºåŠ›å“è³ªã‚¹ã‚³ã‚¢ãŒ**å¹³å‡12%å‘ä¸Š**ã—ã¾ã—ãŸã€‚

## ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ã¨A/Bãƒ†ã‚¹ãƒˆã‚’å®Ÿè£…ã™ã‚‹

LLMã‚¢ãƒ—ãƒªã§ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¯ãƒ“ã‚¸ãƒã‚¹ãƒ­ã‚¸ãƒƒã‚¯ãã®ã‚‚ã®ã§ã™ã€‚1æ–‡å­—ã®å¤‰æ›´ã§å‡ºåŠ›å“è³ªãŒå¤§ããå¤‰ã‚ã‚‹ãŸã‚ã€**èª°ãŒãƒ»ã„ã¤ãƒ»ãªãœå¤‰æ›´ã—ãŸã‹**ã®è¿½è·¡ãŒä¸å¯æ¬ ã§ã™ã€‚

æœ€åˆã¯ã€Œconfig/prompts.yamlã«ç›´æ›¸ãã§ååˆ†ã€ã¨è€ƒãˆã¦ã„ã¾ã—ãŸãŒã€ãƒãƒ¼ãƒ 3åã§åŒæ™‚ç·¨é›†ã—ãŸçµæœã€æœ¬ç•ªã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒãƒ¼ã‚¸ãƒ§ãƒ³ãŒèª°ã‚‚ã‚ã‹ã‚‰ãªããªã‚Šã¾ã—ãŸã€‚è§£æ±ºç­–ã¨ã—ã¦ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨evalåŸºæº–ã‚’åŒä¸€YAMLã§ç®¡ç†ã—ã¾ã™ã€‚

```yaml
# prompts/summarize.yaml
metadata:
  name: "article-summarizer"
  version: "2.3.0"
  updated_at: "2026-02-18"
prompt:
  model: "gpt-4o"
  temperature: 0.3
  messages:
    - role: "system"
      content: |
        ã‚ãªãŸã¯æŠ€è¡“è¨˜äº‹ã®è¦ç´„ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã§ã™ã€‚
        1. 3-5æ–‡ã§è¦ç´„  2. æŠ€è¡“ç”¨èªä¿æŒ  3. æ•°å€¤ãƒ‡ãƒ¼ã‚¿å¿…é ˆ
eval_criteria:  # evalåŸºæº–ã‚’åŒå±…ã•ã›ã¦ã€Œãƒ†ã‚¹ãƒˆãªãå¤‰æ›´ã€ã‚’é˜²æ­¢
  min_quality_score: 0.8
  max_latency_ms: 3000
```

> **åˆ¶ç´„**: ã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ50å€‹ä»¥ä¸‹ã®ä¸­è¦æ¨¡ãƒãƒ¼ãƒ å‘ã‘ã§ã™ã€‚100å€‹è¶…ã§ã¯Langfuseãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ¬ã‚¸ã‚¹ãƒˆãƒªã‚’ãƒã‚¹ã‚¿ãƒ¼ã«ã—ã€Gitã¯åŒæœŸå…ˆã«ã—ã¦ãã ã•ã„ã€‚

### Langfuseã§A/Bãƒ†ã‚¹ãƒˆã‚’å®Ÿè£…ã™ã‚‹

[Langfuse](https://langfuse.com/)ã¯OSSã®LLMã‚ªãƒ–ã‚¶ãƒ¼ãƒãƒ“ãƒªãƒ†ã‚£åŸºç›¤ã§ã™ã€‚ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒãƒ¼ã‚¸ãƒ§ãƒ³ã«`prod-a`/`prod-b`ã®ãƒ©ãƒ™ãƒ«ã‚’ä»˜ä¸ã—ã€ãƒ©ãƒ³ãƒ€ãƒ é¸æŠã§A/Bãƒ†ã‚¹ãƒˆã‚’å®Ÿç¾ã—ã¾ã™ã€‚

```python
# prompt_ab_test.py
import random
from langfuse import get_client
from openai import OpenAI

langfuse, openai_client = get_client(), OpenAI()

def summarize_with_ab_test(article_text: str) -> dict:
    prompt_a = langfuse.get_prompt("summarizer", label="prod-a")
    prompt_b = langfuse.get_prompt("summarizer", label="prod-b")
    selected = random.choice([prompt_a, prompt_b])
    compiled = selected.compile(article=article_text)

    response = openai_client.chat.completions.create(
        model=compiled.get("model", "gpt-4o"),
        messages=compiled["messages"],
    )
    return {"summary": response.choices[0].message.content, "variant": selected.label}
```

| ãƒ¡ãƒˆãƒªã‚¯ã‚¹ | ç”¨é€” | åˆ¤å®šåŸºæº–ä¾‹ |
|-----------|------|-----------|
| ãƒ¬ã‚¤ãƒ†ãƒ³ã‚· | å¿œç­”é€Ÿåº¦ | p95 < 3,000ms |
| ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ | ã‚³ã‚¹ãƒˆ | å‰ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ¯” Â±20% |
| å“è³ªã‚¹ã‚³ã‚¢ | å‡ºåŠ›å“è³ª | eval â‰¥ 0.8 |

**ãƒãƒã‚Šãƒã‚¤ãƒ³ãƒˆ**: ã‚µãƒ³ãƒ—ãƒ«æ•°ã‚’æ±ºã‚ãšã«n=47ã§æœ‰æ„å·®ãªã—ã¨çµè«–ã—ã¦ã—ã¾ã„ã¾ã—ãŸã€‚çµ±è¨ˆçš„æœ‰æ„å·®ï¼ˆp < 0.05ï¼‰ã«ã¯**æœ€ä½500ãƒªã‚¯ã‚¨ã‚¹ãƒˆ/ãƒãƒªã‚¢ãƒ³ãƒˆ**ãŒå¿…è¦ã§ã™ã€‚

## Feature Flagã¨å“è³ªã‚²ãƒ¼ãƒˆã§å®‰å…¨ã«ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆã™ã‚‹

A/Bãƒ†ã‚¹ãƒˆã§åŠ¹æœæ¤œè¨¼ã—ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’**ã‚³ãƒ¼ãƒ‰ãƒ‡ãƒ—ãƒ­ã‚¤ãªã—ã§å®‰å…¨ã«æœ¬ç•ªå±•é–‹**ã—ã¾ã™ã€‚

### LaunchDarkly AI Configsã§ãƒ©ãƒ³ã‚¿ã‚¤ãƒ åˆ‡æ›¿

[LaunchDarkly](https://launchdarkly.com/)ã®AI Configsæ©Ÿèƒ½ã§ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã«åˆ‡ã‚Šæ›¿ãˆã¾ã™ã€‚LangfuseãŒã€Œãƒ©ãƒ³ãƒ€ãƒ é¸æŠã€ãªã®ã«å¯¾ã—ã€**ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆ¥ã‚¿ãƒ¼ã‚²ãƒ†ã‚£ãƒ³ã‚°**ã¨æ®µéšçš„ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆï¼ˆ5%â†’25%â†’100%ï¼‰ãŒå¯èƒ½ã§ã™ã€‚

```typescript
// src/llm-client.ts
import { init } from "@launchdarkly/node-server-sdk";
import { initAi } from "@launchdarkly/server-sdk-ai";
import OpenAI from "openai";

const ldClient = init(process.env.LAUNCHDARKLY_SDK_KEY!);
await ldClient.waitForInitialization();
const aiClient = initAi(ldClient);

export async function summarize(userId: string, text: string) {
  const aiConfig = await aiClient.completionConfig(
    "article-summarizer",
    { kind: "user", key: userId },
    { enabled: false },
    { article: text },
  );
  if (!aiConfig.enabled) return fallbackSummarize(text);

  const completion = await aiConfig.tracker.trackOpenAIMetrics(async () =>
    new OpenAI().chat.completions.create({
      messages: aiConfig.messages ?? [],
      model: aiConfig.model?.name ?? "gpt-4o",
    })
  );
  return completion.choices[0].message.content ?? "";
}
```

**ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•**: LaunchDarkly AI Configsã¯SaaSæœ‰æ–™ã§ã™ã€‚ã‚³ã‚¹ãƒˆé‡è¦–ãªã‚‰Langfuseã‚»ãƒ«ãƒ•ãƒ›ã‚¹ãƒˆç‰ˆã§Feature Flagã‚’è‡ªä½œã§ãã¾ã™ãŒã€æœˆé–“10ä¸‡ãƒªã‚¯ã‚¨ã‚¹ãƒˆä»¥ä¸Šã§ã¯LaunchDarklyã®ROIãŒé«˜ã„ã¨åˆ¤æ–­ã—ã¦ã„ã¾ã™ã€‚

### Promptfoo GitHub Actionsã§å“è³ªã‚²ãƒ¼ãƒˆã‚’æ§‹ç¯‰ã™ã‚‹

ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå¤‰æ›´æ™‚ã«**è‡ªå‹•è©•ä¾¡ã‚’å®Ÿè¡Œã—ã€åŸºæº–æœªé”ã®PRã‚’ãƒ–ãƒ­ãƒƒã‚¯**ã—ã¾ã™ã€‚

```yaml
# .github/workflows/prompt-eval.yml
name: "Prompt Quality Gate"
on:
  pull_request:
    paths: ["prompts/**"]
jobs:
  evaluate:
    runs-on: ubuntu-latest
    permissions:
      pull-requests: write
    steps:
      - uses: actions/checkout@v4
      - uses: actions/cache@v4
        with:
          path: ~/.cache/promptfoo
          key: ${{ runner.os }}-promptfoo-v1
      - uses: promptfoo/promptfoo-action@v1
        with:
          openai-api-key: ${{ secrets.OPENAI_API_KEY }}
          github-token: ${{ secrets.GITHUB_TOKEN }}
          config: "prompts/promptfooconfig.yaml"
```

**3å±¤é˜²å¾¡ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£**ã¨ã—ã¦ã€Layer 1ï¼ˆPromptfoo CI/CDï¼‰â†’ Layer 2ï¼ˆFeature Flagæ®µéšçš„ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆï¼‰â†’ Layer 3ï¼ˆLangfuseæœ¬ç•ªç›£è¦–ï¼‰ã§å¤šé‡é˜²å¾¡ã—ã¾ã™ã€‚CIç’°å¢ƒã®ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã¨æœ¬ç•ªãƒ‡ãƒ¼ã‚¿ã¯åˆ†å¸ƒãŒç•°ãªã‚‹ãŸã‚ã€Layer 1ã ã‘ã§ã¯ä¸ååˆ†ã§ã™ã€‚Feature Flagã«ã‚ˆã‚‹æ®µéšãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆãŒæœ¬ç•ªéšœå®³ã‚¼ãƒ­ã®éµã§ã—ãŸã€‚

| å•é¡Œ | åŸå›  | è§£æ±ºæ–¹æ³• |
|------|------|----------|
| A/Bãƒ†ã‚¹ãƒˆã§Næ•°ä¸è¶³ | ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯è¦‹ç©ã‚‚ã‚Šä¸è¶³ | æœ€ä½500ãƒªã‚¯ã‚¨ã‚¹ãƒˆ/ãƒãƒªã‚¢ãƒ³ãƒˆ |
| Promptfooè©•ä¾¡ãŒä¸å®‰å®š | LLMå‡ºåŠ›ã®éæ±ºå®šæ€§ | `temperature: 0`ã§CIè©•ä¾¡ |
| ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯æ™‚ã«æ—§ç‰ˆä¸æ˜ | å‘½åè¦å‰‡ãªã— | ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒãƒ¼ã‚¸ãƒ§ãƒ‹ãƒ³ã‚°å¿…é ˆ |

## ã¾ã¨ã‚ã¨æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

**ã¾ã¨ã‚:**
- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¯YAML+Gitã§ç®¡ç†ã—ã€evalåŸºæº–åŒå±…ã§ã€Œãƒ†ã‚¹ãƒˆãªãå¤‰æ›´ã€ã‚’é˜²æ­¢
- Langfuseãƒ©ãƒ™ãƒ«æ©Ÿèƒ½ã§A/Bãƒ†ã‚¹ãƒˆã‚’å®Ÿè£…ã—ã€**500ãƒªã‚¯ã‚¨ã‚¹ãƒˆ/ãƒãƒªã‚¢ãƒ³ãƒˆ**ã§æœ‰æ„å·®æ¤œè¨¼
- LaunchDarkly AI Configsã§ãƒ©ãƒ³ã‚¿ã‚¤ãƒ åˆ‡æ›¿ã¨æ®µéšçš„ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆã‚’å®Ÿç¾
- **3å±¤é˜²å¾¡**ã§æœ¬ç•ªéšœå®³ã‚¼ãƒ­ã‚’é”æˆ

**æ¬¡ã«ã‚„ã‚‹ã¹ãã“ã¨:**
- Promptfoo GitHub Actionsã§å“è³ªã‚²ãƒ¼ãƒˆã‚’æ§‹ç¯‰ã™ã‚‹
- Langfuseã§ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ã¨A/Bãƒ†ã‚¹ãƒˆã‚’é–‹å§‹ã™ã‚‹
- ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯è¦æ¨¡ã«å¿œã˜ã¦LaunchDarklyã‹Langfuseè‡ªä½œã‹ã‚’é¸å®šã™ã‚‹

## å‚è€ƒ

- [Langfuse Prompt Management](https://langfuse.com/docs/prompt-management/overview)
- [Langfuse A/B Testing](https://langfuse.com/docs/prompt-management/features/a-b-testing)
- [LaunchDarkly AI Configs](https://launchdarkly.com/docs/home/ai-configs)
- [Promptfoo CI/CD Integration](https://www.promptfoo.dev/docs/integrations/ci-cd/)
- [Promptfoo GitHub Actions](https://www.promptfoo.dev/docs/integrations/github-action/)
- [PromptOps: Git-Native Prompt Management](https://medium.com/@jision/i-built-promptops-git-native-prompt-management-for-production-llm-workflows-ae49d1faa628)

è©³ç´°ãªãƒªã‚µãƒ¼ãƒå†…å®¹ã¯ [Issue #155](https://github.com/0h-n0/zen-auto-create-article/issues/155) ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚

é–¢é€£è¨˜äº‹: [LLMã‚¢ãƒ—ãƒªã®CI/CDãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ§‹ç¯‰](https://zenn.dev/0h_n0/articles/75c05ecd0ff579)
é–¢é€£è¨˜äº‹: [LLMã‚¢ãƒ—ãƒªã®æœ¬ç•ªCI/CDæˆ¦ç•¥](https://zenn.dev/0h_n0/articles/d13e9d53c69e12)

## é–¢é€£ã™ã‚‹æ·±æ˜ã‚Šè¨˜äº‹

ã“ã®è¨˜äº‹ã§ç´¹ä»‹ã—ãŸæŠ€è¡“ã«ã¤ã„ã¦ã€ã•ã‚‰ã«æ·±æ˜ã‚Šã—ãŸè¨˜äº‹ã‚’æ›¸ãã¾ã—ãŸï¼š

- [è«–æ–‡è§£èª¬: DSPy â€” å®£è¨€çš„LMãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’è‡ªå‹•ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã™ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯](https://0h-n0.github.io/posts/paper-dspy-2310-11511/) - arxivè§£èª¬
- [è«–æ–‡è§£èª¬: OPRO â€” LLMã‚’ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæœ€é©åŒ–å™¨ã¨ã—ã¦æ´»ç”¨ã™ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯](https://0h-n0.github.io/posts/paper-opro-2309-03409/) - arxivè§£èª¬
- [Langfuseå…¬å¼è§£èª¬: OSSãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç®¡ç†åŸºç›¤ã¨A/Bãƒ†ã‚¹ãƒˆå®Ÿè£…ã®æŠ€è¡“è©³ç´°](https://0h-n0.github.io/posts/techblog-langfuse-prompt-management/) - tech_blogè§£èª¬
- [LaunchDarklyå…¬å¼è§£èª¬: AI Configsã«ã‚ˆã‚‹LLMãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æ®µéšçš„ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆã¨ãƒ©ãƒ³ã‚¿ã‚¤ãƒ åˆ¶å¾¡](https://0h-n0.github.io/posts/techblog-launchdarkly-ai-configs/) - tech_blogè§£èª¬
- [è«–æ–‡è§£èª¬: TextGrad â€” ãƒ†ã‚­ã‚¹ãƒˆè‡ªå‹•å¾®åˆ†ã«ã‚ˆã‚‹LLMãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æœ€é©åŒ–ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯](https://0h-n0.github.io/posts/paper-textgrad-2406-07496/) - arxivè§£èª¬

:::message
ã“ã‚Œã‚‰ã®è¨˜äº‹ã¯ä¿®å£«å­¦ç”Ÿãƒ¬ãƒ™ãƒ«ã‚’æƒ³å®šã—ãŸæŠ€è¡“çš„è©³ç´°ï¼ˆæ•°å¼ãƒ»å®Ÿè£…ã®æ·±æ˜ã‚Šï¼‰ã‚’å«ã¿ã¾ã™ã€‚
:::

---

:::message
ã“ã®è¨˜äº‹ã¯AIï¼ˆClaude Codeï¼‰ã«ã‚ˆã‚Šè‡ªå‹•ç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚å†…å®¹ã®æ­£ç¢ºæ€§ã«ã¤ã„ã¦ã¯è¤‡æ•°ã®æƒ…å ±æºã§æ¤œè¨¼ã—ã¦ã„ã¾ã™ãŒã€å®Ÿéš›ã®åˆ©ç”¨æ™‚ã¯å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚‚ã”ç¢ºèªãã ã•ã„ã€‚
:::
