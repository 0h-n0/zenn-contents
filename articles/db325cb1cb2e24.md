---
title: "è‡ªç¤¾ãƒ‡ãƒ¼ã‚¿ã§å®Ÿè·µã™ã‚‹Embeddingãƒ¢ãƒ‡ãƒ«ç²¾åº¦è©•ä¾¡ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ§‹ç¯‰"
emoji: "ğŸ“Š"
type: "tech"
topics: ["embedding", "rag", "python", "nlp", "evaluation"]
published: false
---

# è‡ªç¤¾ãƒ‡ãƒ¼ã‚¿ã§å®Ÿè·µã™ã‚‹Embeddingãƒ¢ãƒ‡ãƒ«ç²¾åº¦è©•ä¾¡ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ§‹ç¯‰

## ã“ã®è¨˜äº‹ã§ã‚ã‹ã‚‹ã“ã¨

- å…¬é–‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ï¼ˆMTEB/JMTEBï¼‰ã®ã‚¹ã‚³ã‚¢ã ã‘ã§ã¯åˆ¤æ–­ã§ããªã„ç†ç”±ã¨ã€è‡ªç¤¾ãƒ‡ãƒ¼ã‚¿è©•ä¾¡ã®å¿…è¦æ€§
- sentence-transformers ã® `InformationRetrievalEvaluator` ã‚’ä½¿ã£ãŸã‚«ã‚¹ã‚¿ãƒ è©•ä¾¡ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®å®Ÿè£…æ–¹æ³•
- NDCG@10ãƒ»MRR@10ãƒ»Recall@5 ãªã©ä¸»è¦æ¤œç´¢æŒ‡æ¨™ã®è¨ˆç®—ã¨çµæœã®èª­ã¿è§£ãæ–¹
- RAGAS ã® Context Precision / Context Recall ã‚’ç”¨ã„ãŸ RAG å…¨ä½“ã®æ¤œç´¢å“è³ªè©•ä¾¡
- 2026å¹´æ™‚ç‚¹ã®ä¸»è¦ãƒ¢ãƒ‡ãƒ«ï¼ˆVoyage 4ãƒ»Qwen3-Embedding-8Bãƒ»PLaMo-Embedding-1Bï¼‰ã‚’è‡ªç¤¾ãƒ‡ãƒ¼ã‚¿ã§æ¯”è¼ƒã™ã‚‹æ‰‹é †

## å¯¾è±¡èª­è€…

- **æƒ³å®šèª­è€…**: ä¸­ç´šè€…ã€œä¸Šç´šè€…ã®MLã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒ»ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢
- **å¿…è¦ãªå‰æçŸ¥è­˜**:
  - Python 3.11+ ã®åŸºæœ¬æ“ä½œ
  - ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ãƒ»ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã®åŸºç¤æ¦‚å¿µ
  - RAGï¼ˆRetrieval-Augmented Generationï¼‰ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®åŸºæœ¬æ§‹æˆ

## çµè«–ãƒ»æˆæœ

å…¬é–‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯MTEBã§ä¸Šä½ã®ãƒ¢ãƒ‡ãƒ«ãŒã€è‡ªç¤¾ãƒ‰ãƒ¡ã‚¤ãƒ³ã®æ¤œç´¢ã‚¿ã‚¹ã‚¯ã§ã‚‚ä¸Šä½ã¨ã¯é™ã‚Šã¾ã›ã‚“ã€‚Databricksã®ãƒ¬ãƒãƒ¼ãƒˆã«ã‚ˆã‚‹ã¨ã€ãƒ‰ãƒ¡ã‚¤ãƒ³ç‰¹åŒ–ãƒ‡ãƒ¼ã‚¿ã§ã®Fine-tuningã«ã‚ˆã‚Šæ¤œç´¢ç²¾åº¦ï¼ˆNDCG@10ï¼‰ãŒ10ã€œ30%å‘ä¸Šã™ã‚‹äº‹ä¾‹ãŒå ±å‘Šã•ã‚Œã¦ã„ã¾ã™ã€‚æœ¬è¨˜äº‹ã§ç´¹ä»‹ã™ã‚‹è©•ä¾¡ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ä½¿ãˆã°ã€**3ã¤ã®ãƒ¢ãƒ‡ãƒ«ã®æ¯”è¼ƒè©•ä¾¡ã‚’ç´„2æ™‚é–“ã§å®Œäº†**ã§ãã€è‡ªç¤¾ãƒ‡ãƒ¼ã‚¿ã«é©ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’å®¢è¦³çš„ã«é¸å®šã§ãã¾ã™ã€‚

é–¢é€£è¨˜äº‹: [MTEBÃ—JMTEBã§é¸ã¶Embeddingãƒ¢ãƒ‡ãƒ«ï¼šç²¾åº¦è©•ä¾¡ã®å®Ÿè·µã‚¬ã‚¤ãƒ‰](https://zenn.dev/0h_n0/articles/6388d71c6bcb23)ï¼ˆãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®èª­ã¿æ–¹ãƒ»è©•ä¾¡æŒ‡æ¨™ã®åŸºç¤ã¯ã“ã¡ã‚‰ã‚’å‚ç…§ï¼‰

## å…¬é–‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®é™ç•Œã‚’ç†è§£ã™ã‚‹

Embeddingãƒ¢ãƒ‡ãƒ«ã®é¸å®šã§æœ€åˆã«å‚ç…§ã™ã‚‹ã®ã¯ã€MTEBï¼ˆMassive Text Embedding Benchmarkï¼‰ã‚„JMTEBãªã©ã®å…¬é–‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã™ã€‚ã—ã‹ã—ã€ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚¹ã‚³ã‚¢ã‚’ãã®ã¾ã¾ä¿¡ã˜ã‚‹ã¨ã€å®Ÿé‹ç”¨ã§æœŸå¾…ã©ãŠã‚Šã®ç²¾åº¦ãŒå‡ºãªã„ã‚±ãƒ¼ã‚¹ãŒã‚ã‚Šã¾ã™ã€‚

### ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¨å®Ÿãƒ‡ãƒ¼ã‚¿ã®ã‚®ãƒ£ãƒƒãƒ—ãŒç”Ÿã˜ã‚‹3ã¤ã®ç†ç”±

**1. ãƒ‰ãƒ¡ã‚¤ãƒ³ã®èªå½™åˆ†å¸ƒãŒç•°ãªã‚‹**

MTEBã®è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯Wikipediaãƒ»Webã‚³ãƒ¼ãƒ‘ã‚¹ãªã©ä¸€èˆ¬ãƒ‰ãƒ¡ã‚¤ãƒ³ãŒä¸­å¿ƒã§ã™ã€‚åŒ»ç™‚ã€æ³•å‹™ã€è£½é€ æ¥­ã®ãƒãƒ‹ãƒ¥ã‚¢ãƒ«ãªã©å°‚é–€ç”¨èªãŒå¤šã„ãƒ‰ãƒ¡ã‚¤ãƒ³ã§ã¯ã€ä¸€èˆ¬ãƒ‰ãƒ¡ã‚¤ãƒ³ã§ã®å­¦ç¿’ãŒååˆ†ã«æ´»ã‹ã•ã‚Œã¾ã›ã‚“ã€‚BES4RAGï¼ˆACL 2025 CLiC-itï¼‰ã®åˆ†æã§ã‚‚ã€QAãƒ™ãƒ¼ã‚¹ã®è©•ä¾¡ã¨MTEBã‚¹ã‚³ã‚¢ã®é †ä½ãŒé€†è»¢ã™ã‚‹ã‚±ãƒ¼ã‚¹ãŒç¢ºèªã•ã‚Œã¦ã„ã¾ã™ã€‚

**2. æ–‡æ›¸ã®é•·ã•ãƒ»æ§‹é€ ãŒç•°ãªã‚‹**

ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®æ–‡æ›¸ã¯æ¯”è¼ƒçš„çŸ­ã„æ®µè½ãŒä¸­å¿ƒã§ã™ãŒã€å®Ÿå‹™ã§ã¯æ•°åƒæ–‡å­—ã®æŠ€è¡“ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚„FAQãªã©æ§‹é€ ãŒå¤šæ§˜ã§ã™ã€‚ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²æˆ¦ç•¥ã«ã‚ˆã£ã¦Embeddingã®å“è³ªãŒå¤§ããå¤‰ã‚ã‚‹ãŸã‚ã€ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®æ¡ä»¶ã¨è‡ªç¤¾ã®æ¡ä»¶ã¯ä¸€è‡´ã—ã¾ã›ã‚“ã€‚

**3. ã‚¯ã‚¨ãƒªã®æ€§è³ªãŒç•°ãªã‚‹**

ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã¯æ•´å½¢ã•ã‚ŒãŸè³ªå•æ–‡ãŒä½¿ã‚ã‚Œã¾ã™ãŒã€å®Ÿéš›ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¯ã‚¨ãƒªã¯ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ç¾…åˆ—ã‚„å£èªçš„ãªè¡¨ç¾ãŒå¤šãã€Embeddingãƒ¢ãƒ‡ãƒ«ã®å¾—æ„ãƒ»ä¸å¾—æ„ãŒå¤‰ã‚ã‚Šã¾ã™ã€‚

> **åˆ¶ç´„æ¡ä»¶**: ä»¥é™ã®è©•ä¾¡ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã¯æ¤œç´¢ï¼ˆRetrievalï¼‰ã‚¿ã‚¹ã‚¯ã«ç‰¹åŒ–ã—ã¦ã„ã¾ã™ã€‚åˆ†é¡ã‚„ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã®è©•ä¾¡ã«ã¯ç•°ãªã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒãŒå¿…è¦ã§ã™ã€‚

### 2026å¹´æ™‚ç‚¹ã®ä¸»è¦Embeddingãƒ¢ãƒ‡ãƒ«

è©•ä¾¡å¯¾è±¡ã¨ã—ã¦ã€ä»¥ä¸‹ã®3ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚ã„ãšã‚Œã‚‚2025ã€œ2026å¹´ã«ãƒªãƒªãƒ¼ã‚¹ã•ã‚ŒãŸæœ€æ–°ãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚

| ãƒ¢ãƒ‡ãƒ« | ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•° | æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³ | æ¬¡å…ƒæ•° | MTEB Retrieval | ç‰¹å¾´ |
|--------|------------|------------|--------|---------------|------|
| **Voyage 4-large** | éå…¬é–‹ï¼ˆMoEï¼‰ | 32,000 | 2048 | RTEB 29ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ1ä½ | å…±æœ‰Embeddingç©ºé–“ã€Matryoshkaå¯¾å¿œ |
| **Qwen3-Embedding-8B** | 8B | 8,192 | 4096 | MTEBå¤šè¨€èª1ä½ï¼ˆ70.58ï¼‰ | 100+è¨€èªå¯¾å¿œã€instruction-aware |
| **PLaMo-Embedding-1B** | 1B | 4,096 | 2048 | JMTEB 76.10ï¼ˆæ—¥æœ¬èª1ä½ï¼‰ | LLM2Vecå¤‰æ›ã€Apache 2.0 |

Voyage 4-largeã¯MoEï¼ˆMixture of Expertsï¼‰ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’æ¡ç”¨ã—ã€åŒç­‰å“è³ªã®å¯†ãªãƒ¢ãƒ‡ãƒ«ã¨æ¯”è¼ƒã—ã¦ã‚µãƒ¼ãƒ“ãƒ³ã‚°ã‚³ã‚¹ãƒˆãŒ40%ä½ã„ã¨Voyage AIãŒå ±å‘Šã—ã¦ã„ã¾ã™ã€‚Qwen3-Embedding-8Bã¯3æ®µéšå­¦ç¿’ï¼ˆå¼±æ•™å¸«ã‚ã‚Šäº‹å‰å­¦ç¿’â†’æ•™å¸«ã‚ã‚Šå¾®èª¿æ•´â†’ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ï¼‰ã§å¤šè¨€èªæ€§èƒ½ã‚’å®Ÿç¾ã—ã¦ã„ã¾ã™ã€‚PLaMo-Embedding-1Bã¯1Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãªãŒã‚‰OpenAI text-embedding-3-largeï¼ˆJMTEB 74.05ï¼‰ã‚’ä¸Šå›ã‚‹JMTEB 76.10ã‚’è¨˜éŒ²ã—ã€Preferred NetworksãŒé–‹ç™ºãƒ»Apache 2.0ã§å…¬é–‹ã—ã¦ã„ã¾ã™ã€‚

## è©•ä¾¡ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æº–å‚™ã™ã‚‹

è‡ªç¤¾ãƒ‡ãƒ¼ã‚¿ã§ã®è©•ä¾¡ã«ã¯ã€**ã‚¯ã‚¨ãƒªãƒ»ã‚³ãƒ¼ãƒ‘ã‚¹ãƒ»æ­£è§£ãƒ©ãƒ™ãƒ«**ã®3è¦ç´ ãŒå¿…è¦ã§ã™ã€‚ã“ã“ã§ã¯ã€å®Ÿéš›ã®RAGã‚·ã‚¹ãƒ†ãƒ ã§è“„ç©ã•ã‚Œã‚‹ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰è©•ä¾¡ã‚»ãƒƒãƒˆã‚’æ§‹ç¯‰ã™ã‚‹æ–¹æ³•ã‚’ç´¹ä»‹ã—ã¾ã™ã€‚

### è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æ§‹é€ 

sentence-transformers ã® `InformationRetrievalEvaluator` ãŒæœŸå¾…ã™ã‚‹ãƒ‡ãƒ¼ã‚¿å½¢å¼ã«åˆã‚ã›ã¦æº–å‚™ã—ã¾ã™ã€‚

```python
# eval_dataset.py
from dataclasses import dataclass

@dataclass
class IREvalDataset:
    """æƒ…å ±æ¤œç´¢è©•ä¾¡ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ"""
    queries: dict[str, str]       # {query_id: query_text}
    corpus: dict[str, str]        # {doc_id: doc_text}
    relevant_docs: dict[str, set[str]]  # {query_id: {relevant_doc_ids}}
```

å®Ÿéš›ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã¯ã€ä»¥ä¸‹ã®3ã¤ã®æ–¹æ³•ã§è©•ä¾¡ã‚»ãƒƒãƒˆã‚’æ§‹ç¯‰ã§ãã¾ã™ã€‚

### æ–¹æ³•1: æ—¢å­˜ã®QAãƒ­ã‚°ã‹ã‚‰æ§‹ç¯‰ã™ã‚‹

RAGã‚·ã‚¹ãƒ†ãƒ ã®ãƒ­ã‚°ã«ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¯ã‚¨ãƒªã¨å‚ç…§ã•ã‚ŒãŸæ–‡æ›¸IDãŒè¨˜éŒ²ã•ã‚Œã¦ã„ã‚‹å ´åˆã€ãã‚Œã‚’ãã®ã¾ã¾è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã«å¤‰æ›ã§ãã¾ã™ã€‚

```python
# build_eval_from_logs.py
import json
from pathlib import Path

def build_eval_dataset_from_logs(
    log_path: Path,
    corpus_path: Path,
    min_relevance_score: float = 0.7,
) -> IREvalDataset:
    """QAãƒ­ã‚°ã‹ã‚‰è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ§‹ç¯‰ã™ã‚‹

    Args:
        log_path: QAãƒ­ã‚°ã®JSONLãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        corpus_path: ã‚³ãƒ¼ãƒ‘ã‚¹ã®JSONLãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        min_relevance_score: æ­£è§£ã¨ã¿ãªã™ã‚¹ã‚³ã‚¢ã®é–¾å€¤
    """
    # ã‚³ãƒ¼ãƒ‘ã‚¹èª­ã¿è¾¼ã¿
    corpus: dict[str, str] = {}
    with open(corpus_path) as f:
        for line in f:
            doc = json.loads(line)
            corpus[doc["doc_id"]] = doc["text"]

    # QAãƒ­ã‚°ã‹ã‚‰æ­£è§£ãƒšã‚¢ã‚’æŠ½å‡º
    queries: dict[str, str] = {}
    relevant_docs: dict[str, set[str]] = {}

    with open(log_path) as f:
        for line in f:
            entry = json.loads(line)
            qid = entry["query_id"]
            queries[qid] = entry["query_text"]
            relevant_docs[qid] = {
                ref["doc_id"]
                for ref in entry["references"]
                if ref.get("relevance_score", 0) >= min_relevance_score
            }

    # æ­£è§£ãŒ0ä»¶ã®ã‚¯ã‚¨ãƒªã‚’é™¤å¤–
    queries = {qid: q for qid, q in queries.items() if relevant_docs.get(qid)}
    relevant_docs = {qid: docs for qid, docs in relevant_docs.items() if docs}

    return IREvalDataset(
        queries=queries,
        corpus=corpus,
        relevant_docs=relevant_docs,
    )
```

**æ³¨æ„ç‚¹:**
> QAãƒ­ã‚°ãƒ™ãƒ¼ã‚¹ã®è©•ä¾¡ã‚»ãƒƒãƒˆã¯ã€Œéå»ã®ã‚·ã‚¹ãƒ†ãƒ ãŒæ¤œç´¢ã§ããŸæ–‡æ›¸ã€ã«åã‚Šã¾ã™ã€‚æœªæ¤œç´¢ã®æ­£è§£æ–‡æ›¸ãŒå«ã¾ã‚Œãªã„ãŸã‚ã€Recall ã®æ•°å€¤ã¯éå¤§è©•ä¾¡ã«ãªã‚ŠãŒã¡ã§ã™ã€‚ã“ã®åã‚Šã‚’ç·©å’Œã™ã‚‹ã«ã¯ã€æ–¹æ³•2ã®äººæ‰‹ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã¨ä½µç”¨ã—ã¦ãã ã•ã„ã€‚

### æ–¹æ³•2: LLMã‚’ä½¿ã£ãŸåˆæˆã‚¯ã‚¨ãƒªç”Ÿæˆ

ã‚³ãƒ¼ãƒ‘ã‚¹ã¯ã‚ã‚‹ãŒã‚¯ã‚¨ãƒªã¨æ­£è§£ãƒ©ãƒ™ãƒ«ãŒãªã„å ´åˆã€LLMã§åˆæˆã‚¯ã‚¨ãƒªã‚’ç”Ÿæˆã§ãã¾ã™ã€‚

```python
# generate_synthetic_queries.py
import anthropic

def generate_queries_for_document(
    doc_id: str,
    doc_text: str,
    n_queries: int = 3,
) -> list[dict[str, str]]:
    """æ–‡æ›¸ã‹ã‚‰LLMã§æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’åˆæˆã™ã‚‹"""
    client = anthropic.Anthropic()
    prompt = (
        f"ä»¥ä¸‹ã®æ–‡æ›¸ã‚’æ¤œç´¢ã™ã‚‹ãŸã‚ã«ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒå…¥åŠ›ã—ãã†ãªã‚¯ã‚¨ãƒªã‚’"
        f"{n_queries}å€‹ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚"
        f"ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ç¾…åˆ—å‹ã¨è‡ªç„¶æ–‡å‹ã‚’æ··ãœã¦ãã ã•ã„ã€‚\n\n"
        f"æ–‡æ›¸:\n{doc_text[:2000]}\n\nå„ã‚¯ã‚¨ãƒªã‚’1è¡Œãšã¤å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚"
    )
    response = client.messages.create(
        model="claude-sonnet-4-6",
        max_tokens=500,
        messages=[{"role": "user", "content": prompt}],
    )
    lines = response.content[0].text.strip().split("\n")
    return [
        {"query_text": line.strip().lstrip("0123456789.-) "), "doc_id": doc_id}
        for line in lines
        if line.strip()
    ]
```

**ãªãœåˆæˆã‚¯ã‚¨ãƒªç”Ÿæˆã‚’é¸ã¶ã®ã‹:**
- äººæ‰‹ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã®ã‚³ã‚¹ãƒˆãŒé«˜ã„å ´åˆã«æœ‰åŠ¹ï¼ˆæ•°ç™¾ã‚¯ã‚¨ãƒªã‚’æ•°åˆ†ã§ç”Ÿæˆå¯èƒ½ï¼‰
- Philipp Schmidã®ã‚¬ã‚¤ãƒ‰ï¼ˆHugging Faceï¼‰ã§ã‚‚Fine-tuningè©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦æ¨å¥¨ã•ã‚Œã¦ã„ã‚‹

**ãƒãƒã‚Šãƒã‚¤ãƒ³ãƒˆ:**
> åˆæˆã‚¯ã‚¨ãƒªã¯LLMã®ç”Ÿæˆå‚¾å‘ã«ä¾å­˜ã™ã‚‹ãŸã‚ã€å®Ÿéš›ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¯ã‚¨ãƒªã®åˆ†å¸ƒã¨ã‚ºãƒ¬ãŒç”Ÿã˜ã¾ã™ã€‚æœ¬ç•ªé‹ç”¨å‰ã«ã¯å®Ÿéš›ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ­ã‚°ã‹ã‚‰50ã€œ100ä»¶ã‚’è¿½åŠ æ§‹ç¯‰ã—ã€ç²¾åº¦å·®ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚

### è©•ä¾¡ã‚»ãƒƒãƒˆã®ã‚µã‚¤ã‚ºç›®å®‰

| ç”¨é€” | ã‚¯ã‚¨ãƒªæ•° | ã‚³ãƒ¼ãƒ‘ã‚¹ã‚µã‚¤ã‚º | æ‰€è¦æ™‚é–“ï¼ˆäººæ‰‹ï¼‰ |
|------|---------|-------------|----------------|
| åˆæœŸã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚° | 50-100 | 1,000-5,000 | åˆæˆã‚¯ã‚¨ãƒªã§1æ™‚é–“ |
| æœ¬æ ¼è©•ä¾¡ | 200-500 | å…¨ã‚³ãƒ¼ãƒ‘ã‚¹ | ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã§1-2æ—¥ |
| ç¶™ç¶šãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚° | 50-100ï¼ˆå›ºå®šï¼‰ | å…¨ã‚³ãƒ¼ãƒ‘ã‚¹ | åˆå›ã®ã¿ |

## è©•ä¾¡ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å®Ÿè£…ã™ã‚‹

ã“ã“ã‹ã‚‰ã€sentence-transformers ã® `InformationRetrievalEvaluator` ã‚’ä½¿ã£ãŸè©•ä¾¡ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å®Ÿè£…ã—ã¾ã™ã€‚

### ç’°å¢ƒæ§‹ç¯‰

```bash
# Python 3.11+ æ¨å¥¨
uv init embedding-eval && cd embedding-eval
uv add sentence-transformers==5.2.0 voyageai anthropic torch numpy pandas
```

sentence-transformers 5.2.0ï¼ˆ2025å¹´ãƒªãƒªãƒ¼ã‚¹ï¼‰ã§ã¯ã€å¤šè¨€èªNanoBEIRè©•ä¾¡å™¨ãŒè¿½åŠ ã•ã‚Œã€ã‚«ã‚¹ã‚¿ãƒ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã®è©•ä¾¡APIã‚‚æ•´ç†ã•ã‚Œã¦ã„ã¾ã™ã€‚

### åŸºæœ¬ã®è©•ä¾¡ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

```python
# evaluate_models.py
"""Embeddingãƒ¢ãƒ‡ãƒ«ã®æ¤œç´¢ç²¾åº¦ã‚’è‡ªç¤¾ãƒ‡ãƒ¼ã‚¿ã§æ¯”è¼ƒè©•ä¾¡ã™ã‚‹"""
import json
import time
from pathlib import Path

import numpy as np
import pandas as pd
from sentence_transformers import SentenceTransformer
from sentence_transformers.evaluation import InformationRetrievalEvaluator


def load_eval_dataset(dataset_dir: Path) -> tuple[dict, dict, dict]:
    """è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’èª­ã¿è¾¼ã‚€"""
    with open(dataset_dir / "queries.json") as f:
        queries = json.load(f)
    with open(dataset_dir / "corpus.json") as f:
        corpus = json.load(f)
    with open(dataset_dir / "relevant_docs.json") as f:
        raw = json.load(f)
        relevant_docs = {k: set(v) for k, v in raw.items()}
    return queries, corpus, relevant_docs


def evaluate_single_model(
    model_name: str,
    queries: dict[str, str],
    corpus: dict[str, str],
    relevant_docs: dict[str, set[str]],
    query_prompt: str | None = None,
    batch_size: int = 32,
) -> dict[str, float]:
    """å˜ä¸€ãƒ¢ãƒ‡ãƒ«ã®æ¤œç´¢ç²¾åº¦ã‚’è©•ä¾¡ã™ã‚‹"""
    model = SentenceTransformer(model_name, trust_remote_code=True)

    evaluator = InformationRetrievalEvaluator(
        queries=queries,
        corpus=corpus,
        relevant_docs=relevant_docs,
        ndcg_at_k=[5, 10],
        mrr_at_k=[10],
        accuracy_at_k=[1, 5, 10],
        precision_recall_at_k=[5, 10],
        map_at_k=[100],
        batch_size=batch_size,
        query_prompt=query_prompt,
        name=model_name.replace("/", "_"),
    )

    start = time.time()
    results = evaluator(model)
    elapsed = time.time() - start

    results["evaluation_time_sec"] = elapsed
    return results
```

**ãªãœ `InformationRetrievalEvaluator` ã‚’ä½¿ã†ã®ã‹:**
- sentence-transformers ã«çµ±åˆã•ã‚Œã¦ãŠã‚Šè¿½åŠ ä¾å­˜ãŒä¸è¦
- NDCGãƒ»MRRãƒ»Recallãƒ»MAPãƒ»Precisionã‚’ä¸€æ‹¬è¨ˆç®—ã§ãã‚‹
- ä»£æ›¿æ¡ˆã®æ‰‹å‹•å®Ÿè£…ã¨æ¯”è¼ƒã—ã¦ã€ãƒã‚°æ··å…¥ãƒªã‚¹ã‚¯ãŒä½ã„

### è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã®ä¸€æ‹¬æ¯”è¼ƒ

```python
# compare_models.py
"""è¤‡æ•°Embeddingãƒ¢ãƒ‡ãƒ«ã‚’ä¸€æ‹¬æ¯”è¼ƒã™ã‚‹"""

# Voyage 4ã¯sentence-transformersã«æœªå¯¾å¿œã®ãŸã‚APIçµŒç”±ã§è©•ä¾¡
# ã“ã“ã§ã¯sentence-transformerså¯¾å¿œãƒ¢ãƒ‡ãƒ«ã®æ¯”è¼ƒä¾‹
MODEL_CONFIGS = [
    {
        "name": "pfnet/plamo-embedding-1b",
        "query_prompt": "æ¬¡ã®æ–‡ç« ã«å¯¾ã—ã¦ã€é–¢é€£ã™ã‚‹æ–‡ç« ã‚’æ¤œç´¢ã—ã¦ãã ã•ã„: ",
    },
    {
        "name": "Qwen/Qwen3-Embedding-0.6B",
        "query_prompt": "Instruct: é–¢é€£ã™ã‚‹ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’æ¤œç´¢ã—ã¦ãã ã•ã„\nQuery: ",
    },
    {
        "name": "intfloat/multilingual-e5-large-instruct",
        "query_prompt": "query: ",
    },
]


def compare_models(dataset_dir: Path) -> pd.DataFrame:
    """è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡çµæœã‚’æ¯”è¼ƒãƒ†ãƒ¼ãƒ–ãƒ«ã«ã¾ã¨ã‚ã‚‹"""
    queries, corpus, relevant_docs = load_eval_dataset(dataset_dir)
    all_results = []

    for config in MODEL_CONFIGS:
        print(f"Evaluating: {config['name']}")
        results = evaluate_single_model(
            model_name=config["name"],
            queries=queries,
            corpus=corpus,
            relevant_docs=relevant_docs,
            query_prompt=config.get("query_prompt"),
        )
        results["model"] = config["name"]
        all_results.append(results)

    df = pd.DataFrame(all_results)
    # ä¸»è¦æŒ‡æ¨™ã®ã¿æŠ½å‡ºã—ã¦è¦‹ã‚„ã™ãã™ã‚‹
    key_cols = ["model", "ndcg_at_10", "mrr_at_10", "recall_at_10",
                "precision_at_10", "map_at_100", "evaluation_time_sec"]
    display_cols = [c for c in key_cols if c in df.columns]
    return df[display_cols].sort_values("ndcg_at_10", ascending=False)


if __name__ == "__main__":
    dataset_dir = Path("eval_data")
    result_df = compare_models(dataset_dir)
    print("\n=== è©•ä¾¡çµæœ ===")
    print(result_df.to_markdown(index=False))
    result_df.to_csv("eval_results.csv", index=False)
```

### Voyage 4ã‚’APIçµŒç”±ã§è©•ä¾¡ã™ã‚‹

Voyage 4ã¯sentence-transformersã«ç›´æ¥å¯¾å¿œã—ã¦ã„ãªã„ãŸã‚ã€APIçµŒç”±ã§Embeddingã‚’å–å¾—ã—ã€æ‰‹å‹•ã§æ¤œç´¢è©•ä¾¡ã‚’è¡Œã„ã¾ã™ã€‚

```python
# evaluate_voyage.py
"""Voyage 4 APIã‚’ä½¿ã£ãŸæ¤œç´¢ç²¾åº¦è©•ä¾¡"""
import voyageai
import numpy as np

def evaluate_voyage_retrieval(
    queries: dict[str, str],
    corpus: dict[str, str],
    relevant_docs: dict[str, set[str]],
    model: str = "voyage-4",
    top_k: int = 10,
) -> dict[str, float]:
    """Voyage Embeddingã§ã®æ¤œç´¢ç²¾åº¦ã‚’è©•ä¾¡ã™ã‚‹"""
    client = voyageai.Client()
    query_ids = list(queries.keys())
    doc_ids = list(corpus.keys())

    # Embeddingå–å¾—ï¼ˆinput_typeã§ã‚¯ã‚¨ãƒªã¨æ–‡æ›¸ã‚’åŒºåˆ¥ï¼‰
    query_embs = np.array(
        client.embed([queries[q] for q in query_ids],
                     model=model, input_type="query").embeddings
    )
    doc_embs = np.array(
        client.embed([corpus[d] for d in doc_ids],
                     model=model, input_type="document").embeddings
    )

    # ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã§æ¤œç´¢
    query_norms = query_embs / np.linalg.norm(query_embs, axis=1, keepdims=True)
    doc_norms = doc_embs / np.linalg.norm(doc_embs, axis=1, keepdims=True)
    sim_matrix = query_norms @ doc_norms.T

    ndcg_scores, mrr_scores, recall_scores = [], [], []
    for i, qid in enumerate(query_ids):
        gold = relevant_docs.get(qid, set())
        if not gold:
            continue
        ranked = [doc_ids[idx] for idx in np.argsort(-sim_matrix[i])[:top_k]]

        # NDCG@K
        dcg = sum(1.0 / np.log2(r + 2) for r, d in enumerate(ranked) if d in gold)
        idcg = sum(1.0 / np.log2(r + 2) for r in range(min(len(gold), top_k)))
        ndcg_scores.append(dcg / idcg if idcg > 0 else 0.0)
        # MRR@K
        mrr = next((1.0 / (r + 1) for r, d in enumerate(ranked) if d in gold), 0.0)
        mrr_scores.append(mrr)
        # Recall@K
        recall_scores.append(sum(1 for d in ranked if d in gold) / len(gold))

    return {
        "model": model,
        f"ndcg_at_{top_k}": float(np.mean(ndcg_scores)),
        f"mrr_at_{top_k}": float(np.mean(mrr_scores)),
        f"recall_at_{top_k}": float(np.mean(recall_scores)),
    }
```

**ã‚ˆãã‚ã‚‹é–“é•ã„:**
> Voyage 4ã§ã¯ `input_type` ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã‚¯ã‚¨ãƒªã¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’åŒºåˆ¥ã™ã‚‹è¨­è¨ˆã«ãªã£ã¦ã„ã¾ã™ã€‚ä¸¡æ–¹ã¨ã‚‚ `"document"` ã§åŸ‹ã‚è¾¼ã‚€ã¨ã€éå¯¾ç§°æ¤œç´¢ã®åˆ©ç‚¹ãŒå¤±ã‚ã‚Œç²¾åº¦ãŒä½ä¸‹ã—ã¾ã™ã€‚å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«å¾“ã„ã€å¿…ãšã‚¯ã‚¨ãƒªã«ã¯ `"query"`ã€æ–‡æ›¸ã«ã¯ `"document"` ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚

## RAGASã§æ¤œç´¢å“è³ªã‚’ã‚¨ãƒ³ãƒ‰ãƒ»ãƒ„ãƒ¼ãƒ»ã‚¨ãƒ³ãƒ‰è©•ä¾¡ã™ã‚‹

Embeddingãƒ¢ãƒ‡ãƒ«å˜ä½“ã®è©•ä¾¡ã«åŠ ãˆã¦ã€RAGãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å…¨ä½“ã§ã®æ¤œç´¢å“è³ªã‚‚ç¢ºèªã—ã¾ã—ã‚‡ã†ã€‚RAGASãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã®Context Precision / Context Recallã‚’ä½¿ã†ã¨ã€ã€Œæ¤œç´¢ã•ã‚ŒãŸæ–‡è„ˆãŒå›ç­”ã«å½¹ç«‹ã¤ã‹ã€ã‚’è©•ä¾¡ã§ãã¾ã™ã€‚

### RAGASã«ã‚ˆã‚‹è©•ä¾¡ã®ä½ç½®ã¥ã‘

```mermaid
graph LR
    A[ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¯ã‚¨ãƒª] --> B[Embeddingæ¤œç´¢]
    B --> C[æ¤œç´¢çµæœ<br/>Context]
    C --> D[LLMç”Ÿæˆ<br/>å›ç­”]

    B -.->|InformationRetrievalEvaluator| E[æ¤œç´¢ç²¾åº¦<br/>NDCG/MRR/Recall]
    C -.->|RAGAS Context Precision| F[æ–‡è„ˆã®ç²¾åº¦]
    C -.->|RAGAS Context Recall| G[æ–‡è„ˆã®ç¶²ç¾…æ€§]
    D -.->|RAGAS Faithfulness| H[å›ç­”ã®å¿ å®Ÿæ€§]

    style E fill:#e8f5e9
    style F fill:#fff3e0
    style G fill:#fff3e0
    style H fill:#fce4ec
```

`InformationRetrievalEvaluator` ã¯Embeddingãƒ¢ãƒ‡ãƒ«ã®æ¤œç´¢èƒ½åŠ›ã‚’ç›´æ¥æ¸¬å®šã—ã¾ã™ã€‚ä¸€æ–¹RAGASã¯ã€æ¤œç´¢çµæœãŒLLMã®å›ç­”ã«ã©ã†å½±éŸ¿ã™ã‚‹ã‹ã¾ã§å«ã‚ãŸè©•ä¾¡ã§ã™ã€‚ä¸¡è€…ã‚’çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§ã€ã€Œæ¤œç´¢ã¯æ­£ç¢ºã ãŒå›ç­”ã«æ´»ç”¨ã•ã‚Œã¦ã„ãªã„ã€ãªã©ã®å•é¡Œã‚‚æ¤œå‡ºã§ãã¾ã™ã€‚

### RAGASè©•ä¾¡ã®å®Ÿè£…

```python
# ragas_eval.py
"""RAGASã«ã‚ˆã‚‹Context Precision/Recallè©•ä¾¡"""
from ragas import EvaluationDataset, SingleTurnSample, evaluate
from ragas.metrics import LLMContextPrecisionWithoutReference, LLMContextRecall


def build_ragas_dataset(
    questions: list[str],
    retrieved_contexts: list[list[str]],
    reference_answers: list[str],
    llm_responses: list[str],
) -> EvaluationDataset:
    """RAGASè©•ä¾¡ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ§‹ç¯‰ã™ã‚‹"""
    samples = []
    for q, ctx, ref, resp in zip(
        questions, retrieved_contexts, reference_answers, llm_responses
    ):
        samples.append(
            SingleTurnSample(
                user_input=q,
                retrieved_contexts=ctx,
                reference=ref,
                response=resp,
            )
        )
    return EvaluationDataset(samples=samples)


def evaluate_context_quality(
    dataset: EvaluationDataset,
) -> dict[str, float]:
    """æ¤œç´¢ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®å“è³ªã‚’è©•ä¾¡ã™ã‚‹"""
    metrics = [
        LLMContextPrecisionWithoutReference(),
        LLMContextRecall(),
    ]
    result = evaluate(dataset=dataset, metrics=metrics)
    return {
        "context_precision": float(result["llm_context_precision_without_reference"]),
        "context_recall": float(result["llm_context_recall"]),
    }
```

**ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•:**
RAGASè©•ä¾¡ã¯LLMã®åˆ¤æ–­ã«ä¾å­˜ã™ã‚‹ãŸã‚ã€è©•ä¾¡è‡ªä½“ã«ã‚³ã‚¹ãƒˆãŒã‹ã‹ã‚Šã¾ã™ã€‚100ã‚¯ã‚¨ãƒªã®è©•ä¾¡ã§Claude Sonnet 4.6ã‚’ä½¿ã†å ´åˆã€APIã‚³ã‚¹ãƒˆã¯ç´„$2ã€œ5ç¨‹åº¦ã§ã™ã€‚å¤§è¦æ¨¡ãªè©•ä¾¡ã«ã¯ `InformationRetrievalEvaluator` ã‚’ä¸»è»¸ã¨ã—ã€RAGASã¯é‡è¦ãªã‚µãƒ³ãƒ—ãƒ«50ã€œ100ä»¶ã«çµã£ã¦å®Ÿè¡Œã™ã‚‹ã®ãŒå®Ÿç”¨çš„ã§ã™ã€‚

## è©•ä¾¡çµæœã‚’åˆ†æã—ã¦åˆ¤æ–­ã™ã‚‹

è©•ä¾¡ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®å‡ºåŠ›ã‹ã‚‰ã€ã©ã®ãƒ¢ãƒ‡ãƒ«ã‚’æ¡ç”¨ã™ã‚‹ã‹åˆ¤æ–­ã™ã‚‹ãŸã‚ã®åˆ†ææ‰‹é †ã‚’è§£èª¬ã—ã¾ã™ã€‚

### çµæœã®èª­ã¿è§£ãæ–¹

è©•ä¾¡çµæœãŒä»¥ä¸‹ã®ã‚ˆã†ã«ãªã£ãŸã¨ã—ã¾ã™ï¼ˆæ¶ç©ºã®ãƒ‰ãƒ¡ã‚¤ãƒ³ç‰¹åŒ–ãƒ‡ãƒ¼ã‚¿ã§ã®ä¾‹ï¼‰ã€‚

| ãƒ¢ãƒ‡ãƒ« | NDCG@10 | MRR@10 | Recall@10 | è©•ä¾¡æ™‚é–“(ç§’) |
|--------|---------|--------|-----------|------------|
| PLaMo-Embedding-1B | 0.72 | 0.68 | 0.85 | 45 |
| Qwen3-Embedding-0.6B | 0.69 | 0.65 | 0.82 | 38 |
| multilingual-e5-large-instruct | 0.65 | 0.61 | 0.78 | 52 |

ã“ã®çµæœã‚’è¦‹ã‚‹éš›ã®ãƒã‚¤ãƒ³ãƒˆã¯ä»¥ä¸‹ã®ã¨ãŠã‚Šã§ã™ã€‚

**NDCG@10**: æ¤œç´¢çµæœã®ä¸Šä½ã«æ­£è§£æ–‡æ›¸ãŒé›†ã¾ã£ã¦ã„ã‚‹ã‹ã‚’ç¤ºã—ã¾ã™ã€‚å€¤ãŒé«˜ã„ã»ã©ã€Œæ­£è§£ãŒä¸Šä½ã«æ¥ã¦ã„ã‚‹ã€ã“ã¨ã‚’æ„å‘³ã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½“é¨“ã«ç›´çµã—ã¾ã™ã€‚

**MRR@10**: æœ€åˆã®æ­£è§£æ–‡æ›¸ãŒä½•ä½ã«æ¥ã‚‹ã‹ã®é€†æ•°å¹³å‡ã§ã™ã€‚ã€Œ1ä»¶ç›®ã®æ­£è§£ãŒè¦‹ã¤ã‹ã‚‹ã¾ã§ã®é€Ÿã•ã€ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæœ€åˆã®çµæœã ã‘ã‚’è¦‹ã‚‹UIã§ã¯ç‰¹ã«é‡è¦ã§ã™ã€‚

**Recall@10**: ä¸Šä½10ä»¶ã«æ­£è§£æ–‡æ›¸ãŒã©ã‚Œã ã‘å«ã¾ã‚Œã‚‹ã‹ã‚’ç¤ºã—ã¾ã™ã€‚RAGã§è¤‡æ•°ã®æ–‡è„ˆã‚’å‚ç…§ã™ã‚‹å ´åˆã€RecallãŒé«˜ã„ãƒ¢ãƒ‡ãƒ«ã®æ–¹ãŒLLMã«é©åˆ‡ãªæƒ…å ±ã‚’æ¸¡ã›ã¾ã™ã€‚

### ã‚¨ãƒ©ãƒ¼åˆ†æã®å®Ÿè£…

æ•°å€¤ã ã‘ã§ãªãã€ã©ã®ã‚¯ã‚¨ãƒªã§å¤±æ•—ã—ã¦ã„ã‚‹ã‹ã‚’åˆ†æã™ã‚‹ã“ã¨ãŒæ”¹å–„ã®éµã§ã™ã€‚

```python
# error_analysis.py
"""æ¤œç´¢å¤±æ•—ã‚¯ã‚¨ãƒªã®åˆ†æ"""

def find_failure_queries(
    queries: dict[str, str],
    corpus: dict[str, str],
    relevant_docs: dict[str, set[str]],
    ranked_results: dict[str, list[str]],
    threshold_recall: float = 0.5,
    top_k: int = 10,
) -> list[dict]:
    """Recall@KãŒé–¾å€¤ä»¥ä¸‹ã®ã‚¯ã‚¨ãƒªã‚’æŠ½å‡ºã™ã‚‹"""
    failures = []
    for qid, gold in relevant_docs.items():
        if not gold:
            continue
        retrieved = set(ranked_results.get(qid, [])[:top_k])
        recall = len(retrieved & gold) / len(gold)
        if recall < threshold_recall:
            missed = gold - retrieved
            failures.append({
                "query_id": qid,
                "query_text": queries[qid],
                "recall": recall,
                "missed_doc_previews": [corpus[d][:100] for d in missed if d in corpus],
            })
    return sorted(failures, key=lambda x: x["recall"])
```

**æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã«ã¤ãªã’ã‚‹:**

å¤±æ•—ãƒ‘ã‚¿ãƒ¼ãƒ³ã®åˆ†æçµæœã¯ã€æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã«ç›´çµã—ã¾ã™ã€‚

| å¤±æ•—ãƒ‘ã‚¿ãƒ¼ãƒ³ | å¯¾å‡¦æ³• |
|------------|-------|
| ç”¨èªã®ãƒŸã‚¹ãƒãƒƒãƒ | åŒç¾©èªè¾æ›¸ã®æ§‹ç¯‰ã€ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ï¼ˆBM25ä½µç”¨ï¼‰ã®å°å…¥ |
| é•·æ–‡æ›¸ã®åˆ†æ•£ | ãƒãƒ£ãƒ³ã‚¯æˆ¦ç•¥ã®è¦‹ç›´ã—ï¼ˆã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—å¢—åŠ ã€è¦ªå­ãƒãƒ£ãƒ³ã‚¯ï¼‰ |
| æ›–æ˜§ãªã‚¯ã‚¨ãƒª | ã‚¯ã‚¨ãƒªæ‹¡å¼µï¼ˆQuery Expansionï¼‰ã®å°å…¥ |
| å°‚é–€ç”¨èªã®æœªå¯¾å¿œ | ãƒ‰ãƒ¡ã‚¤ãƒ³ç‰¹åŒ–Fine-tuningã®æ¤œè¨ |

## Fine-tuningå‰å¾Œã®ç²¾åº¦æ¯”è¼ƒã‚’è¨­è¨ˆã™ã‚‹

ã‚¨ãƒ©ãƒ¼åˆ†æã®çµæœã€ãƒ‰ãƒ¡ã‚¤ãƒ³ç‰¹åŒ–Fine-tuningãŒæœ‰åŠ¹ã¨åˆ¤æ–­ã—ãŸå ´åˆã®è©•ä¾¡è¨­è¨ˆã«ã¤ã„ã¦è§£èª¬ã—ã¾ã™ã€‚

### è©•ä¾¡è¨­è¨ˆã®åŸå‰‡

Fine-tuningã®åŠ¹æœã‚’æ­£ã—ãæ¸¬å®šã™ã‚‹ã«ã¯ã€**å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã®å³å¯†ãªåˆ†é›¢**ãŒä¸å¯æ¬ ã§ã™ã€‚

```mermaid
graph TD
    A[è‡ªç¤¾ãƒ‡ãƒ¼ã‚¿å…¨ä½“] --> B[å­¦ç¿’ç”¨ 70%]
    A --> C[æ¤œè¨¼ç”¨ 15%]
    A --> D[ãƒ†ã‚¹ãƒˆç”¨ 15%]
    B --> E[Fine-tuning]
    C --> F[ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´]
    D --> G[æœ€çµ‚è©•ä¾¡<br/>ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ vs Fine-tuned]

    style D fill:#ffcdd2
    style G fill:#ffcdd2
```

**ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã¯æœ€çµ‚è©•ä¾¡ã§ã®ã¿ä½¿ç”¨ã—ã¾ã™ã€‚** æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã§ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’èª¿æ•´ã—ãŸå¾Œã€ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§1å›ã ã‘è©•ä¾¡ã™ã‚‹è¨­è¨ˆã«ã—ã¦ãã ã•ã„ã€‚ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’ç¹°ã‚Šè¿”ã—å‚ç…§ã™ã‚‹ã¨ã€éå­¦ç¿’ã®æ¤œå‡ºãŒã§ããªããªã‚Šã¾ã™ã€‚

### Fine-tuningå‰å¾Œã®æ¯”è¼ƒã‚¹ã‚¯ãƒªãƒ—ãƒˆ

```python
# finetune_comparison.py
"""Fine-tuningå‰å¾Œã®ç²¾åº¦æ¯”è¼ƒï¼ˆå‰è¿°ã®evaluate_single_modelé–¢æ•°ã‚’å†åˆ©ç”¨ï¼‰"""
from pathlib import Path

def compare_baseline_vs_finetuned(
    baseline_model: str,
    finetuned_model_path: str,
    test_dataset_dir: Path,
    query_prompt: str | None = None,
) -> None:
    """ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã¨Fine-tunedãƒ¢ãƒ‡ãƒ«ã®NDCG@10ã‚’æ¯”è¼ƒã™ã‚‹"""
    queries, corpus, relevant_docs = load_eval_dataset(test_dataset_dir)

    base_result = evaluate_single_model(
        baseline_model, queries, corpus, relevant_docs, query_prompt)
    ft_result = evaluate_single_model(
        finetuned_model_path, queries, corpus, relevant_docs, query_prompt)

    base_ndcg = base_result["ndcg_at_10"]
    ft_ndcg = ft_result["ndcg_at_10"]
    improvement = (ft_ndcg - base_ndcg) / base_ndcg * 100
    print(f"Baseline NDCG@10: {base_ndcg:.4f}")
    print(f"Fine-tuned NDCG@10: {ft_ndcg:.4f}")
    print(f"æ”¹å–„ç‡: {improvement:+.1f}%")
```

Databricksã®ãƒ–ãƒ­ã‚°ã«ã‚ˆã‚‹ã¨ã€ãƒ‰ãƒ¡ã‚¤ãƒ³ç‰¹åŒ–ãƒ‡ãƒ¼ã‚¿ã§ã®Fine-tuningã«ã‚ˆã‚Šã€æ¤œç´¢ç²¾åº¦ï¼ˆNDCG@10ï¼‰ãŒ10ã€œ30%å‘ä¸Šã™ã‚‹äº‹ä¾‹ãŒå ±å‘Šã•ã‚Œã¦ã„ã¾ã™ã€‚ãŸã ã—ã€ã“ã®æ”¹å–„å¹…ã¯ãƒ‰ãƒ¡ã‚¤ãƒ³ã®ç‰¹æ®Šæ€§ã‚„ãƒ‡ãƒ¼ã‚¿é‡ã«ä¾å­˜ã—ã€ä¸€èˆ¬çš„ãªWebãƒ†ã‚­ã‚¹ãƒˆã«è¿‘ã„ãƒ‰ãƒ¡ã‚¤ãƒ³ã§ã¯æ”¹å–„å¹…ãŒå°ã•ããªã‚‹å‚¾å‘ãŒã‚ã‚Šã¾ã™ã€‚

## ã‚ˆãã‚ã‚‹å•é¡Œã¨è§£æ±ºæ–¹æ³•

| å•é¡Œ | åŸå›  | è§£æ±ºæ–¹æ³• |
|------|------|----------|
| è©•ä¾¡ã‚¹ã‚³ã‚¢ãŒç•°å¸¸ã«é«˜ã„ï¼ˆNDCG@10 > 0.95ï¼‰ | è©•ä¾¡ã‚»ãƒƒãƒˆãŒç°¡å˜ã™ãã‚‹ï¼ˆã‚¯ã‚¨ãƒªã¨æ–‡æ›¸ãŒã»ã¼åŒä¸€æ–‡ï¼‰ | Hard Negativesã‚’è¿½åŠ ã—ã€é¡ä¼¼ã ãŒä¸æ­£è§£ã®æ–‡æ›¸ã‚’å«ã‚ã‚‹ |
| ãƒ¢ãƒ‡ãƒ«é–“ã®ã‚¹ã‚³ã‚¢å·®ãŒã»ã¼ãªã„ | ã‚³ãƒ¼ãƒ‘ã‚¹ãŒå°ã•ãå·®ãŒå‡ºã«ãã„ | ã‚³ãƒ¼ãƒ‘ã‚¹ã‚’5,000ä»¶ä»¥ä¸Šã«æ‹¡å¤§ã™ã‚‹ |
| GPU OOMã‚¨ãƒ©ãƒ¼ | ãƒãƒƒãƒã‚µã‚¤ã‚ºãŒå¤§ãã™ãã‚‹ | `batch_size=8` ã«ç¸®å°ã€ã¾ãŸã¯CPUè©•ä¾¡ã«åˆ‡ã‚Šæ›¿ãˆ |
| Voyage APIã®ãƒ¬ãƒ¼ãƒˆåˆ¶é™ | çŸ­æ™‚é–“ã«å¤§é‡ãƒªã‚¯ã‚¨ã‚¹ãƒˆ | `time.sleep(0.5)` ã§ãƒªã‚¯ã‚¨ã‚¹ãƒˆé–“éš”ã‚’èª¿æ•´ |
| æ—¥æœ¬èªã®è©•ä¾¡ã‚¹ã‚³ã‚¢ãŒä½ã„ | ãƒ¢ãƒ‡ãƒ«ã®æ—¥æœ¬èªå¯¾å¿œãŒä¸ååˆ† | PLaMo-Embedding-1Bãªã©JMTEBä¸Šä½ãƒ¢ãƒ‡ãƒ«ã‚’å„ªå…ˆ |
| Fine-tuningå¾Œã«RecallãŒä½ä¸‹ | ã‚«ã‚¿ã‚¹ãƒˆãƒ­ãƒ•ã‚£ãƒƒã‚¯ãƒ»ãƒ•ã‚©ãƒ¼ã‚²ãƒƒãƒ†ã‚£ãƒ³ã‚° | å­¦ç¿’ç‡ã‚’ä¸‹ã’ã‚‹ï¼ˆ1e-6ã€œ5e-6ï¼‰ã€å…ƒãƒ‡ãƒ¼ã‚¿ã®ä¸€éƒ¨ã‚’æ··ãœã¦å­¦ç¿’ |

## ã¾ã¨ã‚ã¨æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

**ã¾ã¨ã‚:**
- å…¬é–‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ï¼ˆMTEB/JMTEBï¼‰ã®ã‚¹ã‚³ã‚¢ã¯å‚è€ƒå€¤ã§ã‚ã‚Šã€è‡ªç¤¾ãƒ‡ãƒ¼ã‚¿ã§ã®å®Ÿæ¸¬ãŒä¸å¯æ¬ 
- sentence-transformers ã® `InformationRetrievalEvaluator` ã§ã€NDCGãƒ»MRRãƒ»Recallã‚’ä¸€æ‹¬è©•ä¾¡å¯èƒ½
- RAGASã® Context Precision / Recall ã§RAGãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å…¨ä½“ã®æ¤œç´¢å“è³ªã‚’è©•ä¾¡ã§ãã‚‹
- ã‚¨ãƒ©ãƒ¼åˆ†æã§å¤±æ•—ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç‰¹å®šã—ã€ãƒãƒ£ãƒ³ã‚¯æˆ¦ç•¥ã‚„Fine-tuningãªã©ã®å¯¾ç­–ã«ã¤ãªã’ã‚‹
- Fine-tuningè©•ä¾¡ã§ã¯å­¦ç¿’ãƒ»æ¤œè¨¼ãƒ»ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®å³å¯†ãªåˆ†é›¢ãŒå¿…é ˆ

**æ¬¡ã«ã‚„ã‚‹ã¹ãã“ã¨:**
- è‡ªç¤¾ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰50ã€œ100ä»¶ã®è©•ä¾¡ã‚»ãƒƒãƒˆï¼ˆã‚¯ã‚¨ãƒªãƒ»æ­£è§£æ–‡æ›¸ãƒšã‚¢ï¼‰ã‚’æ§‹ç¯‰ã™ã‚‹
- æœ¬è¨˜äº‹ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã§å€™è£œãƒ¢ãƒ‡ãƒ«2ã€œ3å€‹ã‚’æ¯”è¼ƒè©•ä¾¡ã™ã‚‹
- ã‚¨ãƒ©ãƒ¼åˆ†æçµæœã«åŸºã¥ã„ã¦ã€ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ã‚„Fine-tuningã®å°å…¥ã‚’æ¤œè¨ã™ã‚‹

## å‚è€ƒ

- [MTEB: Massive Text Embedding Benchmarkï¼ˆGitHubï¼‰](https://github.com/embeddings-benchmark/mteb)
- [MMTEB: Massive Multilingual Text Embedding Benchmarkï¼ˆarxiv:2502.13595ï¼‰](https://arxiv.org/abs/2502.13595)
- [sentence-transformers Evaluationï¼ˆå…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆï¼‰](https://sbert.net/docs/package_reference/sentence_transformer/evaluation.html)
- [Voyage 4 Model Familyï¼ˆVoyage AI Blogï¼‰](https://blog.voyageai.com/2026/01/15/voyage-4/)
- [PLaMo-Embedding-1Bã®é–‹ç™ºï¼ˆPreferred Networks Tech Blogï¼‰](https://tech.preferred.jp/ja/blog/plamo-embedding-1b/)
- [Qwen3 Embeddingï¼ˆQwenå…¬å¼ãƒ–ãƒ­ã‚°ï¼‰](https://qwenlm.github.io/blog/qwen3-embedding/)
- [RAGAS: Automated Evaluation of RAGï¼ˆå…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆï¼‰](https://docs.ragas.io/en/stable/)
- [Improving Retrieval and RAG with Embedding Model Finetuningï¼ˆDatabricks Blogï¼‰](https://www.databricks.com/blog/improving-retrieval-and-rag-embedding-model-finetuning)
- [Fine-tune Embedding models for RAGï¼ˆPhilipp Schmidï¼‰](https://www.philschmid.de/fine-tune-embedding-model-for-rag)

---

## é–¢é€£ã™ã‚‹æ·±æ˜ã‚Šè¨˜äº‹

ã“ã®è¨˜äº‹ã§ç´¹ä»‹ã—ãŸæŠ€è¡“ã«ã¤ã„ã¦ã€ã•ã‚‰ã«æ·±æ˜ã‚Šã—ãŸè¨˜äº‹ã‚’æ›¸ãã¾ã—ãŸï¼š

- [è«–æ–‡è§£èª¬: MMTEB â€” 500+ã‚¿ã‚¹ã‚¯Ã—250+è¨€èªã®å¤§è¦æ¨¡å¤šè¨€èªãƒ†ã‚­ã‚¹ãƒˆåŸ‹ã‚è¾¼ã¿ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯](https://0h-n0.github.io/posts/paper-mmteb-2502-13595/) - arXivè§£èª¬
- [Databricksè§£èª¬: Embeddingãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã§æ¤œç´¢ãƒ»RAGç²¾åº¦ã‚’å‘ä¸Šã•ã›ã‚‹](https://0h-n0.github.io/posts/techblog-databricks-embedding-finetuning-rag/) - tech_blogè§£èª¬
- [Voyage AIè§£èª¬: Voyage 4 â€” MoEã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¨å…±æœ‰Embeddingç©ºé–“](https://0h-n0.github.io/posts/techblog-voyage-4-moe-embedding/) - tech_blogè§£èª¬
- [PFNè§£èª¬: PLaMo-Embedding-1B â€” LLM2Vecã§å®Ÿç¾ã—ãŸæ—¥æœ¬èªJMTEBãƒˆãƒƒãƒ—ã‚¯ãƒ©ã‚¹ã®åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«](https://0h-n0.github.io/posts/techblog-plamo-embedding-1b/) - tech_blogè§£èª¬
- [è«–æ–‡è§£èª¬: Qwen3 Embedding â€” 3æ®µéšå­¦ç¿’ã¨ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ã§å®Ÿç¾ã—ãŸå¤šè¨€èªãƒ†ã‚­ã‚¹ãƒˆåŸ‹ã‚è¾¼ã¿](https://0h-n0.github.io/posts/paper-qwen3-embedding/) - arXivè§£èª¬

:::message
ã“ã‚Œã‚‰ã®è¨˜äº‹ã¯ä¿®å£«å­¦ç”Ÿãƒ¬ãƒ™ãƒ«ã‚’æƒ³å®šã—ãŸæŠ€è¡“çš„è©³ç´°ï¼ˆæ•°å¼ãƒ»å®Ÿè£…ã®æ·±æ˜ã‚Šï¼‰ã‚’å«ã¿ã¾ã™ã€‚
:::

---

:::message
ã“ã®è¨˜äº‹ã¯AIï¼ˆClaude Codeï¼‰ã«ã‚ˆã‚Šè‡ªå‹•ç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚å†…å®¹ã®æ­£ç¢ºæ€§ã«ã¤ã„ã¦ã¯è¤‡æ•°ã®æƒ…å ±æºã§æ¤œè¨¼ã—ã¦ã„ã¾ã™ãŒã€å®Ÿéš›ã®åˆ©ç”¨æ™‚ã¯å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚‚ã”ç¢ºèªãã ã•ã„ã€‚
:::
